{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, time, copy\n",
    "import math\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from word2number import w2n\n",
    "import string, re\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\",\"textcat\",\"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*|\\(|\\)|-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectNum(l):\n",
    "    result = []\n",
    "    for w in l:\n",
    "        try: result.append(str(int(w)))\n",
    "        except: pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toNum(word):\n",
    "    if word == 'point': return word\n",
    "    try: return w2n.word_to_num(word)\n",
    "    except:\n",
    "        return word\n",
    "\n",
    "def normalize_text(s):\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text): # additional: converting numbers to digit form\n",
    "        return \" \".join([str(toNum(w)) for w in text.split()])\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation) - set(['.'])\n",
    "        text1 = \"\".join(ch for ch in text if ch not in exclude)\n",
    "        return re.sub(r\"\\.(?!\\d)\", \"\", text1) # remove '.' if it's not a decimal point\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    def lemmatization(text):\n",
    "        return \" \".join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "    if len(s.strip()) == 1:\n",
    "        # accept article and punc if input is a single char\n",
    "        return white_space_fix(lower(s))\n",
    "    elif len(s.strip().split()) == 1: \n",
    "        # accept article if input is a single word\n",
    "        return lemmatization(white_space_fix(remove_punc(lower(s))))\n",
    "\n",
    "    return lemmatization(white_space_fix(remove_articles(remove_punc(lower(s)))))\n",
    "\n",
    "# Language eval with Caption metrics\n",
    "class Evaluate(object):\n",
    "    def __init__(self):\n",
    "        self.scorers = [\n",
    "            (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
    "            #(Meteor(), \"METEOR\"),\n",
    "            (Rouge(), \"ROUGE_L\"),\n",
    "            #(Cider(), \"CIDEr\"),\n",
    "            #(Spice(), \"Spice\")\n",
    "        ]\n",
    "    \n",
    "    def score(self, ref, hypo):\n",
    "        final_scores = {}\n",
    "        for scorer, method in self.scorers:\n",
    "            if type(method) == list: score, scores = scorer.compute_score(ref, hypo, verbose=0)\n",
    "            else: score, scores = scorer.compute_score(ref, hypo)\n",
    "            if type(score) == list:\n",
    "                for m, s in zip(method, score):\n",
    "                    #print(m)\n",
    "                    final_scores[m] = s\n",
    "            else:\n",
    "                #print(method)\n",
    "                final_scores[method] = score\n",
    "        return final_scores\n",
    "\n",
    "    def evaluate(self, return_scores=False, **kwargs):\n",
    "        ans = kwargs.pop('ref', {}) # support a list of references\n",
    "        cand = kwargs.pop('cand', {}) # only support one cand per sample, but the input cand has size batch_size x K\n",
    "\n",
    "        hypo = {}\n",
    "        ref = {}\n",
    "        i = 0\n",
    "        for i in range(len(cand)):\n",
    "            hypo[i] = cand[i]\n",
    "            ref[i] = ans[i]\n",
    "        \n",
    "        final_scores = self.score(ref, hypo)\n",
    "        #print ('Bleu_1:\\t', final_scores['Bleu_1'])\n",
    "        #print ('Bleu_2:\\t', final_scores['Bleu_2'])\n",
    "        #print ('Bleu_3:\\t', final_scores['Bleu_3'])\n",
    "        #print ('Bleu_4:\\t', final_scores['Bleu_4'])\n",
    "        #print ('METEOR:\\t', final_scores['METEOR'])\n",
    "        #print ('ROUGE_L:', final_scores['ROUGE_L'])\n",
    "        #print ('CIDEr:\\t', final_scores['CIDEr'])\n",
    "        #print ('Spice:\\t', final_scores['Spice'])\n",
    "\n",
    "        if return_scores:\n",
    "            return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VQA Eval (SQuAD style EM, F1)\n",
    "def compute_vqa_metrics(cands, a, exclude=\"\", domain=None):\n",
    "    if len(cands) == 0: return (0,0,0)\n",
    "    bow_a = normalize_text(a).split()\n",
    "    F1 = []\n",
    "    EM = 0\n",
    "    RE = []\n",
    "    PR = []\n",
    "    e = normalize_text(exclude).split()\n",
    "    for c in cands:\n",
    "        bow_c = [w for w in normalize_text(c).split() if not w in e]\n",
    "        if domain == {\"NUMBER\"}: bow_c = detectNum(bow_c)\n",
    "        elif domain is not None: \n",
    "            bow_c = list(domain.intersection(bow_c))\n",
    "            bow_a = list(domain.intersection(bow_a))\n",
    "        \n",
    "        #print(bow_c)\n",
    "        #print(bow_a)\n",
    "        if bow_c == bow_a:\n",
    "            EM = 1\n",
    "        common = Counter(bow_a) & Counter(bow_c)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            return (0,0,0,0,0)\n",
    "        precision = 1.0 * num_same / len(bow_c)\n",
    "        recall = 1.0 * num_same / len(bow_a)\n",
    "        RE.append(recall)\n",
    "        PR.append(precision)\n",
    "\n",
    "        f1 = 2*precision*recall / (precision + recall + 1e-5)\n",
    "        F1.append(f1)\n",
    "    \n",
    "    PR_avg = np.mean(PR)\n",
    "    RE_avg = np.mean(RE)\n",
    "    F1_avg = np.mean(F1)\n",
    "    F1_max = np.max(F1)\n",
    "    return (F1_avg, F1_max, EM, RE_avg, PR_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'train': 17812, 'test': 4695, 'val': 2455})\n",
      "24962\n",
      "Counter({'train': 16448, 'ood_test': 3948, 'val': 2511, 'ind_test': 2485})\n",
      "Counter({'YesNo': 8410, 'Others': 6689, 'choose': 5226, 'number': 2337, 'color': 2068, 'shape': 662})\n",
      "Counter({'Others': 1284, 'YesNo': 1098, 'choose': 1010, 'color': 239, 'number': 220, 'shape': 97})\n",
      "25392\n"
     ]
    }
   ],
   "source": [
    "txt_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0820_addKA.json\", \"r\"))\n",
    "img_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0819_16neg.json\", \"r\"))\n",
    "\n",
    "print(Counter([txt_dataset[k]['split'] for k in txt_dataset]))\n",
    "print(len(set([txt_dataset[k]['Guid'] for k in txt_dataset])))\n",
    "\n",
    "print(Counter([img_dataset[k]['split'] for k in img_dataset]))\n",
    "print(Counter([img_dataset[k]['Qcate'] for k in img_dataset]))\n",
    "print(Counter([img_dataset[k]['Qcate'] for k in img_dataset if img_dataset[k]['split'] == 'ood_test']))\n",
    "print(len(set([img_dataset[k]['Guid'] for k in img_dataset])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 2476, 5: 1500, 4: 527, 3: 167, 2: 25})\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for k in txt_dataset:\n",
    "    if txt_dataset[k]['split'] == 'test':\n",
    "        x.append(len(txt_dataset[k]['A']))\n",
    "print(Counter(x))\n",
    "x = []\n",
    "for k in img_dataset:\n",
    "    if 'test' in img_dataset[k]['split']:\n",
    "        x.append(len(img_dataset[k]['A']))\n",
    "print(Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 6242, 5: 139, 4: 36, 3: 15, 2: 1})\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38338\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Q = []\n",
    "A_list = []\n",
    "C = []\n",
    "Keywords_A = []\n",
    "for k in img_dataset:\n",
    "    if not 'test' in img_dataset[k]['split']: continue\n",
    "    datum = img_dataset[k]\n",
    "    all_A = [a.replace('\"', \"\") for a in datum['A']]\n",
    "    for i in range(len(all_A)):\n",
    "        Q.append(datum['Q'].replace('\"', \"\"))\n",
    "        C.append([all_A[i]])\n",
    "        A_list.append(all_A[:i] + all_A[i+1:])\n",
    "        Keywords_A.append(datum['Keywords_A'].replace('\"', \"\"))\n",
    "assert len(C) == len(Q) == len(A_list) == len(Keywords_A)\n",
    "print(len(Q))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7076\n",
      "[1.0, 0.42857142857142855, 0.42857142857142855, 0.2857142857142857, 0.2857142857142857, 0.42857142857142855]\n",
      "[0.7739321540095442, 0.2863070881368244, 0.7561289225233876, 0.6687403048963458, 5.233846518568202e-05, 0.5114432342517753]\n",
      "\n",
      "7986\n",
      "[1.0, 0, 0.2, 0.4, 0, 0]\n",
      "[0.4692470063653536, 0.5410822689681074, 0.47987820661783703, 0.32466791540375595, 0.5329462626443542, 0.5372849657937071]\n",
      "\n",
      "3774\n",
      "[1.0, 0, 0.25, 0, 0.5, 0.25]\n",
      "[0.7138957846600729, 0.8313539763197327, 0.7765453554362727, 0.36336981878206925, 0.7307717332985799, 4.887406509299109e-05]\n",
      "\n",
      "4418\n",
      "[0.3333333333333333, 0.3333333333333333, 0, 1.0, 0.6666666666666666, 0.6666666666666666]\n",
      "[0.38141656158453924, 1.0294994182935423e-08, 0.8817122475196995, 1.5352597835010118e-12, 0.4952330115902502, 0.904431377538006]\n",
      "\n",
      "5173\n",
      "[0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666]\n",
      "[0.7473021918305992, 3.137143608036445e-05, 0.7138099644123547, 0.7598356855903131, 5.406149860844445e-09, 0.32885804547866293]\n",
      "\n",
      "5911\n",
      "[1.0, 0.6, 0.3, 0.6, 0.6, 0.2]\n",
      "[0.4792365811093905, 0.3869431775754755, 0.4760116547320126, 0.21446539595604802, 0.6505339954086, 0.7311104455702009]\n",
      "\n",
      "66\n",
      "[1.0, 0.75, 0, 0.5, 0.25, 1.0]\n",
      "[0.5452469119105582, 0.7856293016283906, 0.5169731538105412, 0.5988059641008373, 0.9036020033535557, 0.5109955810746272]\n",
      "\n",
      "336\n",
      "[1.0, 0.2, 0.6, 0.6, 0.6, 0.2]\n",
      "[0.8531413605907252, 0.9574533679820988, 0.8971148504200592, 0.8524094630119715, 0.06614057939049886, 0.7349031579858321]\n",
      "\n",
      "1353\n",
      "[1.0, 0, 0.3333333333333333, 0, 1.0, 0]\n",
      "[0.7479996328179238, 0.5898019930403656, 0.8289657838931372, 0.8524419935996841, 0.5035337886952919, 0.8694417437520626]\n",
      "\n",
      "1624\n",
      "[1.0, 0.25, 0.25, 0, 0, 0.25]\n",
      "[5.39059484752114e-09, 8.025716722742473e-09, 0.32523403427534525, 0.5329462626443542, 1.0445522729063402e-12, 0.48109772904027326]\n",
      "\n",
      "15135\n",
      "[1.0, 1.0, 1.0, 0.375, 1.0, 1.0]\n",
      "[0.9999999998957473, 0.8656030551684151, 0.9457416089045797, 0.30960799209910794, 0.8137489370168771, 0.9999999998957473]\n",
      "\n",
      "15587\n",
      "[1.0, 0.3333333333333333, 0, 0.3333333333333333, 0.3333333333333333, 0]\n",
      "[0.37991784278030427, 0.7476743904255464, 0.5169731538105413, 0.9036020033861858, 0.6147881527990924, 0.6914415690877681]\n",
      "\n",
      "12091\n",
      "[0.8888888888888888, 0.5555555555555556, 0.4444444444444444, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111]\n",
      "[0.5008718428095981, 0.6100034456009603, 0.4958271734289548, 0.5109955810746272, 0.2061477352038093, 0.6156286978237718]\n",
      "\n",
      "14044\n",
      "[1.0, 0, 0, 0.2, 0.2, 0.2]\n",
      "[0.7703484635762631, 0.5698363773141187, 0.8230724649295764, 0.935133483563592, 0.5101544332697462, 0.8694417437520626]\n",
      "\n",
      "10151\n",
      "[1.0, 0.6, 0.4, 0.2, 0.2, 0.2]\n",
      "[0.5844356470186963, 7.001843276184207e-13, 0.6591827715423145, 0.48245960455907727, 0.5169731539213033, 2.89785676216564e-05]\n",
      "\n",
      "10524\n",
      "[1.0, 0.5, 0.75, 1.0, 1.0, 0.25]\n",
      "[0.9999999998635914, 0.44683107169538017, 0.8938651487919365, 0.5475235664703343, 0.999999999883558, 2.235208016311594e-05]\n",
      "\n",
      "19579\n",
      "[1.0, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.42857142857142855, 0.42857142857142855]\n",
      "[2.839730284068095e-05, 0.6446561883292008, 0.6168005796387003, 0.6792310722130407, 0.740637500749382, 0.82053222162547]\n",
      "\n",
      "19898\n",
      "[0.75, 0.25, 0.25, 0.16666666666666666, 0.16666666666666666, 0.25]\n",
      "[0.4212246619015133, 0.6899302125135413, 0.6590955739181753, 9.19322715022905e-09, 7.3860999543075715e-09, 0.7348889200398049]\n",
      "\n",
      "19960\n",
      "[0.5714285714285714, 0.42857142857142855, 0.14285714285714285, 0.42857142857142855, 0.2857142857142857, 0.2857142857142857]\n",
      "[0.6389431041697643, 0.7419446626572949, 0.5462757643294353, 0.4887164515321722, 0.4408231875199723, 7.730551755471572e-09]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in RE:\n",
    "    for i in RE[k]:\n",
    "        if i<0.5 and i>0.0:\n",
    "            if random.random()>0.05: break\n",
    "            print(k)\n",
    "            print(RE[k])\n",
    "            #print(sorted(mul[k], reverse=True))\n",
    "            print(bleu4[k])\n",
    "            print()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_dataset_0820_addKA = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0820_addKA.json\", \"r\"))\n",
    "img_dataset_0819_16neg = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0819_16neg.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'orangebrown', 'spot', 'yellow', 'blue', 'rainbow', 'ivory', 'brown', 'gray', 'teal', 'bluewhite', 'orangepurple', 'black', 'white', 'gold', 'redorange', 'pink', 'blonde', 'tan', 'turquoise', 'grey', 'beige', 'golden', 'orange', 'bronze', 'maroon', 'purple', 'bluere', 'red', 'rust', 'violet', 'transparent', 'yes', 'silver', 'chrome', 'green', 'aqua'}\n"
     ]
    }
   ],
   "source": [
    "color_counter = Counter([normalize_text(img_dataset_0819_16neg[k]['Keywords_A'].replace('\"', '')) for k in img_dataset_0819_16neg if img_dataset_0819_16neg[k]['Qcate'] == 'color'])\n",
    "#print(color_counter)\n",
    "d = defaultdict(lambda: [])\n",
    "for a in color_counter.keys():\n",
    "    if len(a.split()) == 1:\n",
    "        d[a].append(a)\n",
    "'''\n",
    "for a in color_counter.keys():\n",
    "    if len(a.split()) > 1:\n",
    "        assigned = False\n",
    "        for w in a.split():\n",
    "            for single_color in d:\n",
    "                if single_color in w:\n",
    "                    d[single_color].append(a)\n",
    "                    assigned = True\n",
    "        if not assigned:\n",
    "            print(a)\n",
    "for single_color in d:\n",
    "    print(single_color, len(d[single_color]))\n",
    "#pprint(d)\n",
    "'''\n",
    "color_set = set(d.keys())\n",
    "print(color_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'globular', 'octogon', 'ring', 'hoop', 'octagon', 'concave', 'flat', 'wavy', 'shamrock', 'cross', 'cylinder', 'cylindrical', 'pentagon', 'point', 'pyramidal', 'crescent', 'rectangular', 'hook', 'tube', 'cone', 'bell', 'spiral', 'ball', 'convex', 'square', 'arch', 'h', 'cuboid', 'step', 'rectangle', 'dot', 'oval', 'circle', 'star', 'crosse', 'crest', 'octagonal', 'cube', 'triangle', 'semicircle', 'domeshape', 'obelisk', 'corkscrew', 'curve', 'circular', 'xs', 'slope', 'pyramid', 'round', 'bow', 'straight', 'triangular', 'heart', 'fork', 'teardrop', 'fold', 'curl', 'spherical', 'diamond', 'keyhole', 'conical', 'dome', 'sphere', 'bellshaped', 'rounded', 'hexagon', 'flower', 'globe', 'torus'}\n"
     ]
    }
   ],
   "source": [
    "shape_counter = Counter([normalize_text(img_dataset_0819_16neg[k]['Keywords_A'].replace('\"', '')) for k in img_dataset_0819_16neg if img_dataset_0819_16neg[k]['Qcate'] == 'shape'])\n",
    "#print(color_counter)\n",
    "d = defaultdict(lambda: [])\n",
    "for a in shape_counter.keys():\n",
    "    if len(a.split()) == 1:\n",
    "        d[a].append(a)\n",
    "\n",
    "shape_set = set(d.keys())\n",
    "shape_set = set(sum([normalize_text(c).split() for c in shape_set], []))\n",
    "print(shape_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'19', '20', 'twice', '25', '1', '4', '50', '13', '6', '11', '16', '5', '17', 'oneway', '28', '10', '15', '2', '30', 'twentysix', '26', 'twentytwo', '8', '36', '12', '3', '14', '0', '22', '9', 'none', 'once', '7', '18', 'thirtynine', 'thirtythree'}\n"
     ]
    }
   ],
   "source": [
    "number_counter = Counter([normalize_text(img_dataset[k]['Keywords_A'].replace('\"', '')) for k in img_dataset if img_dataset[k]['Qcate'] == 'number'])\n",
    "#print(color_counter)\n",
    "d = defaultdict(lambda: [])\n",
    "for a in number_counter.keys():\n",
    "    if len(a.split()) == 1:\n",
    "        d[a].append(a)\n",
    "\n",
    "number_set = set(d.keys())\n",
    "print(number_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesno_set = set(['yes', 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.22072766465871999,\n",
       "  0.18997212650349526,\n",
       "  0.17075451058950142,\n",
       "  0.1512476051989217],\n",
       " [[0.22072766465871999],\n",
       "  [0.18997212650349526],\n",
       "  [0.17075451058950142],\n",
       "  [0.1512476051989217]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = Bleu(4)\n",
    "scorer.compute_score({1: ['She was the goddess of fortune, luck, and fate, and could have bestowed either good or bad luck onto them.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto people.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto them.']},\n",
    "                    {1: ['she could bestow good or bad luck onto people .']},\n",
    "                     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.28298418547295817,\n",
       " 'Bleu_2': 0.23829400937956186,\n",
       " 'Bleu_3': 0.21017598089731462,\n",
       " 'Bleu_4': 0.17674481437878237,\n",
       " 'ROUGE_L': 0.3018725297808242}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_f.evaluate(cand=[[\"She could bestow good or bad luck onto people .\"], ['The Secret Series']], \n",
    "                ref=[['She was the goddess of fortune, luck, and fate, and could have bestowed either good or bad luck onto them.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto people.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto them.'],\n",
    "                     [\"This Isn't What It Looks Like\", \"This Isn't What It Looks Like is the fourth book in The Secret Series, and Bosh was four years old when he started learning to dribble a basketball.\", \"This Isn't What It Looks Like is the same number position in the pentalogy  The Secret Series  as Bosh was years old when he started learning to dribble a basketball.\", \"This Isn't What It Looks Like is the same number position in the pentalogy The Secret Series as the age of Bosh when he started learning to dribble a basketball.\", \"This Isn't What It Looks Like is the same number in the pentalogy  The Secret Series  as Bosh's age when he started learning to dribble a basketball.\", \"This isn't What it Looks Like is the fourth book in the pentalogy The Secret Series which is the amount of years old that Bosh was when he started to learn to dribble a basketball.\"]], \n",
    "                return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bleu_1': 0.22072766465871999, 'Bleu_2': 0.18997212650349526, 'Bleu_3': 0.17075451058950142, 'Bleu_4': 0.1512476051989217, 'ROUGE_L': 0.37731958762886597}\n",
      "{'Bleu_1': 0.49307260724963853, 'Bleu_2': 0.4252304590327199, 'Bleu_3': 0.36968266900993085, 'Bleu_4': 0.3086455873605777, 'ROUGE_L': 0.5327510917030567}\n"
     ]
    }
   ],
   "source": [
    "print(eval_f.evaluate(cand=[['she could bestow good or bad luck onto people .', 'she was the goddess of fortune so she could bestow good or bad luck onto people .']], \n",
    "                ref=[['She was the goddess of fortune, luck, and fate, and could have bestowed either good or bad luck onto them.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto people.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto them.']],\n",
    "                return_scores=True))\n",
    "print(eval_f.evaluate(cand=[['she was the goddess of fortune so she could bestow good or bad luck onto people .']], \n",
    "                ref=[['She was the goddess of fortune, luck, and fate, and could have bestowed either good or bad luck onto them.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto people.', 'Fortuna, a Roman god, would have influenced the lives of Romulus and Remus as they argued over where the exact position of Rome should be by bestowing good or bad luck onto them.']],\n",
    "                return_scores=True))\n",
    "#print(eval_f.evaluate(cand=[['The Secret Series']],\n",
    "                #ref=[[\"This Isn't What It Looks Like\", \"The Secret Series basketball.\", \"This Isn't What It Looks Like is the same number position in the pentalogy  The Secret Series  as Bosh was years old when he started learning to dribble a basketball.\", \"This Isn't What It Looks Like is the same number position in the pentalogy The Secret Series as the age of Bosh when he started learning to dribble a basketball.\", \"This Isn't What It Looks Like is the same number in the pentalogy  The Secret Series  as Bosh's age when he started learning to dribble a basketball.\", \"This isn't What it Looks Like is the fourth book in the pentalogy The Secret Series which is the amount of years old that Bosh was when he started to learn to dribble a basketball.\"]], \n",
    "                #return_scores=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "3464\n",
      "defaultdict(<class 'int'>, {'Others': 226, 'YesNo': 163, 'shape': 35, 'color': 11, 'choose': 29, 'number': 20})\n",
      "484\n"
     ]
    }
   ],
   "source": [
    "## 同一个sample单独，最后取avg/max，RE<0.3的 full sentence 忽略\n",
    "eval_f = Evaluate()\n",
    "bleu4_img_clean = {}\n",
    "RE_img_clean = {}\n",
    "F1_img_clean = {}\n",
    "mul_img_clean = {}\n",
    "keep_A_list = {}\n",
    "drop = defaultdict(int)\n",
    "for k in img_dataset:\n",
    "    if not 'ood_test' in img_dataset[k]['split']: continue\n",
    "    bleu4_img_clean[k] = []\n",
    "    RE_img_clean[k] = []\n",
    "    mul_img_clean[k] = []\n",
    "    F1_img_clean[k] = []\n",
    "    keep_A_list[k] = []\n",
    "    datum = img_dataset[k]\n",
    "    Keywords_A = datum['Keywords_A'].replace('\"', \"\")\n",
    "    all_A = [a.replace('\"', \"\") for a in datum['A']]\n",
    "    Qcate = img_dataset[k]['Qcate']\n",
    "    for i in range(len(all_A)):\n",
    "        Q = datum['Q'].replace('\"', \"\")\n",
    "        C = [all_A[i]]\n",
    "        A_list = all_A[:i] + all_A[i+1:]\n",
    "        scores = eval_f.evaluate(cand=[C], ref=[A_list], return_scores=True)\n",
    "        \n",
    "        if Qcate == 'color': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", color_set)\n",
    "        elif Qcate == 'shape': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", shape_set)\n",
    "        elif Qcate == 'YesNo': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", yesno_set)\n",
    "        elif Qcate == 'number': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", {\"NUMBER\"})\n",
    "        else: F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A)\n",
    "        if RE_avg<0.3: continue\n",
    "        if not Qcate in ['choose', 'Others'] and F1_avg<0.3: continue\n",
    "        keep_A_list[k].append(datum['A'][i])\n",
    "        bleu4_img_clean[k].append(scores['Bleu_4'])\n",
    "        RE_img_clean[k].append(RE_avg)\n",
    "        F1_img_clean[k].append(F1_avg)\n",
    "        if Qcate in ['choose', 'Others']: mul_img_clean[k].append(RE_avg * scores['Bleu_4'])\n",
    "        else: mul_img_clean[k].append(F1_avg * scores['Bleu_4'])\n",
    "    if len(RE_img_clean[k]) < 3: \n",
    "        drop[Qcate] += 1\n",
    "        del RE_img_clean[k]\n",
    "        del mul_img_clean[k]\n",
    "        del bleu4_img_clean[k]\n",
    "        del F1_img_clean[k]\n",
    "        \n",
    "    if len(RE_img_clean) % 500 == 499: print(len(RE_img_clean))\n",
    "assert len(RE_img_clean) == len(mul_img_clean) == len(bleu4_img_clean) == len(F1_img_clean)\n",
    "print(len(RE_img_clean))\n",
    "print(drop)\n",
    "print(np.sum(list(drop.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter({'Others': 1284, 'YesNo': 1098, 'choose': 1010, 'color': 239, 'number': 220, 'shape': 97})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 1579, 5: 780, 4: 703, 3: 402})\n",
      "mean RE:  0.9544662625724938\n",
      "mean F1:  0.5658698487995043\n",
      "mean bleu4:  0.6479121336748872\n",
      "mean mul:  0.6188026913526662\n",
      "\n",
      " choose\n",
      "mean RE:  0.9746595876568294\n",
      "mean F1:  0.3082771627038374\n",
      "mean bleu4:  0.672719762202811\n",
      "mean mul:  0.6598229305976057\n",
      "\n",
      " YesNo\n",
      "mean RE:  1.0\n",
      "mean F1:  0.9996384943803229\n",
      "mean bleu4:  0.6230182064208344\n",
      "mean mul:  0.622805048916689\n",
      "\n",
      " Others\n",
      "mean RE:  0.8799223590146941\n",
      "mean F1:  0.24272256117956434\n",
      "mean bleu4:  0.6551779675671641\n",
      "mean mul:  0.5859068924615922\n",
      "\n",
      " color\n",
      "mean RE:  0.9836866471734893\n",
      "mean F1:  0.958286424484597\n",
      "mean bleu4:  0.6194411349556342\n",
      "mean mul:  0.5973031286096661\n",
      "\n",
      " shape\n",
      "mean RE:  0.9821236559139784\n",
      "mean F1:  0.9421993814777573\n",
      "mean bleu4:  0.625958507539576\n",
      "mean mul:  0.5892321497132155\n",
      "\n",
      " number\n",
      "mean RE:  0.995\n",
      "mean F1:  0.9469256561066419\n",
      "mean bleu4:  0.6434361270098679\n",
      "mean mul:  0.6065825418134638\n"
     ]
    }
   ],
   "source": [
    "print(Counter([len(RE_img_clean[k]) for k in RE_img_clean]))\n",
    "Qcate = ['choose', 'YesNo', 'Others', 'color', 'shape', 'number']\n",
    "print(\"mean RE: \", np.mean([np.mean(RE_img_clean[k]) for k in RE_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "print(\"mean F1: \", np.mean([np.mean(F1_img_clean[k]) for k in F1_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "print(\"mean bleu4: \", np.mean([np.mean(bleu4_img_clean[k]) for k in bleu4_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "print(\"mean mul: \", np.mean([np.mean(mul_img_clean[k]) for k in mul_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "\n",
    "Qcate = ['choose', 'YesNo', 'Others', 'color', 'shape', 'number']\n",
    "for cate in Qcate:\n",
    "    print(\"\\n\", cate)\n",
    "    print(\"mean RE: \", np.mean([np.mean(RE_img_clean[k]) for k in RE_img_clean if img_dataset[k]['Qcate'] == cate]))\n",
    "    print(\"mean F1: \", np.mean([np.mean(F1_img_clean[k]) for k in F1_img_clean if img_dataset[k]['Qcate'] == cate]))\n",
    "    print(\"mean bleu4: \", np.mean([np.mean(bleu4_img_clean[k]) for k in bleu4_img_clean if img_dataset[k]['Qcate'] == cate]))\n",
    "    print(\"mean mul: \", np.mean([np.mean(mul_img_clean[k]) for k in mul_img_clean if img_dataset[k]['Qcate'] == cate]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25392\n",
      "before cleaning, #test =  3948\n",
      "after cleaning, #test =  3464\n",
      "22423\n",
      "after cleaning, #test =  3464\n",
      "Counter({'train': 16448, 'test': 3464, 'val': 2511})\n"
     ]
    }
   ],
   "source": [
    "### Save img_dataset with a cleaner testing set\n",
    "img_dataset_0823_clean_te = copy.deepcopy(img_dataset)\n",
    "print(len(img_dataset_0823_clean_te))\n",
    "print(\"before cleaning, #test = \", len([k for k in img_dataset_0823_clean_te if img_dataset_0823_clean_te[k]['split'] == 'ood_test']))\n",
    "print(\"after cleaning, #test = \", len(RE_img_clean))\n",
    "for k in img_dataset:\n",
    "    if img_dataset_0823_clean_te[k]['split'] in ['val', 'train']: continue\n",
    "    elif img_dataset_0823_clean_te[k]['split'] == 'ind_test':\n",
    "        del img_dataset_0823_clean_te[k]\n",
    "    elif not k in RE_img_clean:\n",
    "        del img_dataset_0823_clean_te[k]\n",
    "    else:\n",
    "        img_dataset_0823_clean_te[k]['A'] = keep_A_list[k]\n",
    "        img_dataset_0823_clean_te[k]['split'] = 'test'\n",
    "print(len(img_dataset_0823_clean_te))\n",
    "print(\"after cleaning, #test = \", len([k for k in img_dataset_0823_clean_te if img_dataset_0823_clean_te[k]['split'] == 'test']))\n",
    "print(Counter([img_dataset_0823_clean_te[k]['split'] for k in img_dataset_0823_clean_te]))\n",
    "json.dump(img_dataset_0823_clean_te, open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0823_clean_te.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.0, 1.0, 1.0]\n",
      "[0.6666622222518517, 0.9999950000249999, 0.6666622222518517]\n",
      "[0.7753470828296695, 0.17388520871679017, 0.9920942415543661]\n",
      "[0.516894609255718, 0.1738843392950937, 0.661391751757899]\n",
      "('\"Is the Champion logo on the side of both the Bobby Isaac\\'s No. 71 Dodge at '\n",
      " \"the NASCAR Hall of Fame and the replica of Wendell Scott's No. 34 1962 \"\n",
      " 'Chevrolet?\"')\n",
      "['\"Yes both the Bobby Isaac\\'s No. 71 Dodge at the NASCAR Hall of Fame and the '\n",
      " \"replica of Wendell Scott's No. 34 1962 Chevrolet has the Champion logo on \"\n",
      " 'its side.\"',\n",
      " '\"Yes, the Champion logo is on the side of both vehicles.\"',\n",
      " '\"The Champion logo on is not on the side of both the Bobby Isaac\\'s No. 71 '\n",
      " \"Dodge at the NASCAR Hall of Fame and the replica of Wendell Scott's No. 34 \"\n",
      " '1962 Chevrolet\"',\n",
      " '\"Yes, the Champion logo is on the side of both the Bobby Isaac\\'s No. 71 '\n",
      " \"Dodge at the NASCAR Hall of Fame and the replica of Wendell Scott's No. 34 \"\n",
      " '1962 Chevrolet.\"',\n",
      " '\"The Champion logo is not on the side of either the Bobby Isaac\\'s No. 71 '\n",
      " \"Dodge at the NASCAR Hall of Fame or the replica of Wendell Scott's No. 34 \"\n",
      " '1962 Chevrolet.\"',\n",
      " '\"The Champion logo can be found on both Bobby Isaac\\'s No. 71 Dodge at the '\n",
      " \"NASCAR Hall of Fame and the replica of Wendell Scott's No. 34 1962 \"\n",
      " 'Chevrolet.\"']\n",
      "'\"Yes.\"'\n",
      "\n",
      "[1.0, 1.0, 1.0]\n",
      "[0.6666622222518517, 0.9999950000249999, 0.9999950000249999]\n",
      "[6.865890476915431e-05, 0.6100034456478836, 0.00010745699313892367]\n",
      "[4.577229803078267e-05, 0.6100003956459054, 0.00010745645585664439]\n",
      "'\"Does the interior of Christ Church Cathedral in Dublin lack ceiling fans?\"'\n",
      "['\"The interior of Christ Church Cathedral in Dublin lacks ceiling fans.\"',\n",
      " '\"The interior of Christ Church Cathedral in Dublin lacks ceiling fans.\"',\n",
      " '\"Yes, there are no ceiling fans.\"',\n",
      " '\"Yes, the interior of Christ Church Cathedral in Dublin is lacking ceiling '\n",
      " 'fans.\"',\n",
      " '\"Yes, the interior lacks ceiling fans.\"',\n",
      " '\"The interior of Christ Church Cathedral in Dublin has no ceiling fans.\"']\n",
      "'\"yes\"'\n"
     ]
    }
   ],
   "source": [
    "for k in bleu4_img_clean:\n",
    "    if img_dataset[k]['Qcate'] in ['YesNo']:\n",
    "        if np.mean(F1_img_clean[k]) > 0.95: continue\n",
    "        if random.random() > 0.99: continue\n",
    "        print()\n",
    "        print(RE_img_clean[k])\n",
    "        print(F1_img_clean[k])\n",
    "        print(bleu4_img_clean[k])\n",
    "        print(mul_img_clean[k])\n",
    "        \n",
    "        pprint(img_dataset[k]['Q'])\n",
    "        pprint(img_dataset[k]['A'])\n",
    "        pprint(img_dataset[k]['Keywords_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "2999\n",
      "3499\n",
      "3499\n",
      "3999\n",
      "4076\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "## 同一个sample单独，最后取avg/max，RE<0.3的 full sentence 忽略\n",
    "eval_f = Evaluate()\n",
    "bleu4_txt_clean = {}\n",
    "RE_txt_clean = {}\n",
    "mul_txt_clean = {}\n",
    "keep_txt_A_list = {}\n",
    "drop = 0\n",
    "for k in txt_dataset:\n",
    "    if not 'test' in txt_dataset[k]['split']: continue\n",
    "    #if k in img_drop_k:\n",
    "        #drop += 1\n",
    "        #continue\n",
    "    bleu4_txt_clean[k] = []\n",
    "    RE_txt_clean[k] = []\n",
    "    mul_txt_clean[k] = []\n",
    "    keep_txt_A_list[k] = []\n",
    "    datum = txt_dataset[k]\n",
    "    Keywords_A = datum['Keywords_A'].replace('\"', \"\")\n",
    "    all_A = [a.replace('\"', \"\") for a in datum['A']]\n",
    "    for i in range(len(all_A)):\n",
    "        Q = datum['Q'].replace('\"', \"\")\n",
    "        C = [all_A[i]]\n",
    "        A_list = all_A[:i] + all_A[i+1:]\n",
    "        scores = eval_f.evaluate(cand=[C], ref=[A_list], return_scores=True)\n",
    "        #print(scores)\n",
    "        \n",
    "        F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A)\n",
    "        if RE_avg<0.5: continue\n",
    "        keep_txt_A_list[k].append(datum['A'][i])\n",
    "        bleu4_txt_clean[k].append(scores['Bleu_4'])\n",
    "        RE_txt_clean[k].append(RE_avg)\n",
    "        mul_txt_clean[k].append(RE_avg * scores['Bleu_4'])\n",
    "    if len(RE_txt_clean[k]) < 3: \n",
    "        drop += 1\n",
    "        del RE_txt_clean[k]\n",
    "        del mul_txt_clean[k]\n",
    "        del bleu4_txt_clean[k]\n",
    "    if len(RE_txt_clean) % 500 == 499: print(len(RE_txt_clean))\n",
    "assert len(RE_txt_clean) == len(mul_txt_clean) == len(bleu4_txt_clean)\n",
    "print(len(RE_txt_clean))\n",
    "print(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 1366, 5: 1343, 4: 874, 3: 493})\n",
      "mean RE:  0.9458907476823312\n",
      "mean mul:  0.5068453831403538\n",
      "mean bleu4:  0.5348509314403606\n"
     ]
    }
   ],
   "source": [
    "# 0.5 threshold\n",
    "print(Counter([len(RE_txt_clean[k]) for k in RE_txt_clean]))\n",
    "print(\"mean RE: \", np.mean([np.mean(RE_txt_clean[k]) for k in RE_txt_clean]))\n",
    "print(\"mean mul: \", np.mean([np.mean(mul_txt_clean[k]) for k in mul_txt_clean]))\n",
    "print(\"mean bleu4: \", np.mean([np.mean(bleu4_txt_clean[k]) for k in bleu4_txt_clean]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.5, 1.0, 1.0, 0.5]\n",
      "[0.3259481888646563, 0.8938651487393561, 0.6257642589497454, 0.828247753030668]\n",
      "[0.16297409443232816, 0.8938651487393561, 0.6257642589497454, 0.414123876515334]\n",
      "('Does the British basketball league system have less levels does the Spanish '\n",
      " 'basketball league system?')\n",
      "['No',\n",
      " '\"The British basketball league system has levels 2 to 4 while the Spanish '\n",
      " 'basketball league system has four levels.\"',\n",
      " '\"No, the British basketball league system does not have fewer levels than '\n",
      " 'the Spanish basketball league system.\"',\n",
      " '\"The British basketball league system fewer levels than the Spanish '\n",
      " 'basketball league system.\"',\n",
      " '\"No, the British basketball league system does not have less levels than the '\n",
      " 'Spanish basketball league system.\"']\n",
      "'\"fewer levels\"'\n",
      "\n",
      "[0.75, 0.75, 0.75, 0.75, 0.75]\n",
      "[0.3640930238335333, 0.6803749332091918, 0.9457416089045797, 0.9457416089045797, 0.2180019395508693]\n",
      "[0.27306976787514997, 0.5102811999068939, 0.7093062066784348, 0.7093062066784348, 0.16350145466315197]\n",
      "('Cognitive processing therapy has an identical acronym to a '\n",
      " 'neuropsychological test developed to test what?')\n",
      "[\"A person's sustained and selective attention\",\n",
      " '\"It tests  a person\\'s sustained and selective attention.\"',\n",
      " '\"Cognitive processing therapy has an identical acronym to a '\n",
      " \"neuropsychological test developed to test a person's sustained and selective \"\n",
      " 'attention.\"',\n",
      " '\"Ognitive processing therapy has an identical acronym to a '\n",
      " \"neuropsychological test developed to test a person's sustained and selective \"\n",
      " 'attention.\"',\n",
      " '\"Continuous performance task, continuous performance test, or CPT, is any of '\n",
      " \"several kinds of neuropsychological test that measures a person's sustained \"\n",
      " 'and selective attention.\"']\n",
      "'\"Sustained and selective attention.\"'\n",
      "\n",
      "[0.32, 0.44, 0.76]\n",
      "[0.5137480411615525, 0.44082318748606286, 0.4107267548142807]\n",
      "[0.1643993731716968, 0.19396220249386767, 0.31215233365885336]\n",
      "('What effects do Beta adrenergic and antihypotensive agents have on the human '\n",
      " 'body?')\n",
      "['They relax the muscles of the airways and raise low blood pressure.',\n",
      " '\"Beta adrenergic agents make breathing easier, while antihypotensive agents '\n",
      " 'raise low blood pressure.\"',\n",
      " '\"Beta adrenergic and antihypotensive agents relax muscles of the airways\"',\n",
      " '\"Beta adrenergic and antihypotensive agents have a relaxing effect on the '\n",
      " 'human body.\"',\n",
      " '\"Beta adrenergic and antihypotensive agents have a relaxation of muscles '\n",
      " 'effect on the human body.\"',\n",
      " '\"Beta adrenergic agonists relax muscles of the airways, causing widening of '\n",
      " 'the airways and resulting in easier breathing and antihypotensive agents '\n",
      " 'raise low blood pressure.\"']\n",
      "('\"While Beta ardenergic agents elax muscles of the airways, causing widening '\n",
      " 'of the airways and resulting in easier breathing, antihypotensive agents '\n",
      " 'tend to raise low blood pressure.\"')\n",
      "\n",
      "[1.0, 0.5, 1.0, 1.0, 1.0]\n",
      "[1.0922110994059825e-07, 0.5681096831943345, 0.30591948786433737, 0.8003203202714512, 0.9365137580725936]\n",
      "[1.0922110994059825e-07, 0.28405484159716726, 0.30591948786433737, 0.8003203202714512, 0.9365137580725936]\n",
      "('Was the Thiruvananthapuram railway division formed in the same or a '\n",
      " 'different decade as the Vijayawada railway division?')\n",
      "['A different decade',\n",
      " '\"The Thiruvananthapuram railway division was not formed in the same decade '\n",
      " 'as the Vijayawada railway division.\"',\n",
      " '\"The Thiruvananthapuram railway and the Vijayawada railway division was '\n",
      " 'formed during two different decades.\"',\n",
      " '\"The Thiruvananthapuram railway division was formed in a different decade '\n",
      " 'than the Vijayawada railway division.\"',\n",
      " '\"The Thiruvananthapuram railway division was formed in a different decade as '\n",
      " 'the Vijayawada railway division.\"']\n",
      "'\"A different decade.\"'\n",
      "\n",
      "[0.6, 1.0, 0.6, 0.6, 0.6, 0.6]\n",
      "[0.4168218946121226, 0.6784751099153218, 0.42612283565412407, 0.3145413833118944, 0.5280972215961978, 5.301490839718548e-05]\n",
      "[0.25009313676727357, 0.6784751099153218, 0.2556737013924744, 0.18872482998713663, 0.31685833295771865, 3.180894503831129e-05]\n",
      "'What regions can non-glacial loess be found?'\n",
      "['Non-glacial loess loess covers the Great Plains of Nebraska, Kansas, and '\n",
      " 'Colorado. It can also be found in China.',\n",
      " '\"Non-glacial loess can be found in the Great Plains of Nebraska, Kansas, and '\n",
      " 'Colorado, and in Australia and Africa.\"',\n",
      " '\"The regions covering the Great Plains of Nebraska, Kansas, and Colorado is '\n",
      " 'considered to be non-glacial desert loess.\"',\n",
      " '\"Non-glacial desert loess is found in Australia and Africa.\"',\n",
      " '\"Non-glacial loess can be found in Nebraska, Kansas, Colorado, Australia, '\n",
      " 'and Africa.\"',\n",
      " '\"The Great Plains of Nebraska and Colorado contain non-glacial desert '\n",
      " 'loess.\"']\n",
      "'\"Great Plains, Australia, and Africa\"'\n",
      "\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "[2.1296076724398306e-09, 0.4854917716711117, 0.7346682657828261, 0.7825422899176371, 0.9259610784897971]\n",
      "[7.098692241466102e-10, 0.16183059055703722, 0.24488942192760868, 0.2608474299725457, 0.3086536928299324]\n",
      "'Where were ATP World Tour Finals held in 2009 and 2012?'\n",
      "['O 2 Arena London',\n",
      " '\"The 2009 and 2012 ATP World Tour Finals were held in the London O2 Arena.\"',\n",
      " '\"The ATP World Tour Finals were held at The O 2 in London in 2009 and 2012.\"',\n",
      " '\"The ATP World Tour Finals were held in London in both 2009 and 2012.\"',\n",
      " '\"ATP World Tour Finals were held at the O2 Arena in 2009 and 2012.\"',\n",
      " '\"The ATP World Tour Finals were held in London in 2009 and 2012.\"']\n",
      "'\"London, United Kingdom\"'\n",
      "\n",
      "[0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "[5.281541522979181e-10, 0.8801117366484266, 0.8933479856551257, 0.5676721705993958, 0.7765453553765386]\n",
      "[2.6407707614895907e-10, 0.8801117366484266, 0.44667399282756287, 0.5676721705993958, 0.3882726776882693]\n",
      "('in what country were both Ken Hughes \"Confession\" and Tanel Toom\\'s \"The '\n",
      " 'Confession\" made?')\n",
      "['Britain.',\n",
      " '\"Ken Hughes \"Confession\" and Tanel Toom\\'s \"The Confession\" were made in '\n",
      " 'Great Britain\"',\n",
      " '\"Both Ken Hughes \"Confession\" and Tanel Toom\\'s \"The Confession\" were made '\n",
      " 'in the United Kingdom.\"',\n",
      " '\"Ken Hughes \"Confession\" and Tanel Toom\\'s \"The Confession\" were made in '\n",
      " 'Britain.\"',\n",
      " '\"In Great Britain was where both Ken Hughes \"Confession\" and Tanel Toom\\'s '\n",
      " '\"The Confession\" were made.\"',\n",
      " '\"Ken Hughes \"Confession\" and Tanel Toom\\'s \"The Confession\" were both made '\n",
      " 'in Britain.\"']\n",
      "'\"Great Britain\"'\n",
      "\n",
      "[1.0, 0.5, 0.5, 0.5, 1.0, 1.0]\n",
      "[0.2461837164833668, 0.6573798604398448, 0.5201592023279747, 0.7986477504295386, 1.8045983328146743e-09, 0.831303327525793]\n",
      "[0.2461837164833668, 0.3286899302199224, 0.2600796011639874, 0.3993238752147693, 1.8045983328146743e-09, 0.831303327525793]\n",
      "('How many years passed between the release of the film True Blood and the '\n",
      " 'premier of the third season of the television series of the same name?')\n",
      "['The premiere of the third season occurred approximately 21 years after the '\n",
      " 'release of the film.',\n",
      " '\"Twenty-one years passed between the release of the film, True Blood (1989), '\n",
      " 'and the premier of the third season of the television series with the same '\n",
      " 'name.\"',\n",
      " '\"Twenty one years passed between the release of the True Blood film and the '\n",
      " 'third season of the True Blood television series.\"',\n",
      " '\"About 11 years passed between the release of the film True Blood and the '\n",
      " 'premier of the third season of the television series of the same name.\"',\n",
      " '\"There were 21 years between them.\"',\n",
      " '\"21 years passed between the release of True Blood and the third season of '\n",
      " 'the television series of the same name.\"']\n",
      "'\"21 years\"'\n",
      "\n",
      "[1.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333]\n",
      "[0.16954225815740862, 0.7912619863266207, 0.9816435766277088, 0.9999999998587455, 0.9999999998587455]\n",
      "[0.16954225815740862, 0.7912619863266207, 0.9816435766277088, 0.3333333332862485, 0.3333333332862485]\n",
      "('How old was Dave Brown when Arnold Brown won the Perrier Award at the '\n",
      " 'Edinburgh Festival?')\n",
      "['Dave Brown was 14 years old.',\n",
      " '\"Dave Brown was 13 or 14 years old when Arnold Brown won the Perrier Award '\n",
      " 'at the Edinburgh Festival.\"',\n",
      " '\"Dave Brown was 14 years old when Arnold Brown won the Perrier Award at the '\n",
      " 'Edinburgh Festival\"',\n",
      " '\"Dave Brown was 14 when Arnold Brown won the Perrier Award at the Edinburgh '\n",
      " 'Festival\"',\n",
      " '\"Dave Brown was 14 when Arnold Brown won the Perrier Award at the Edinburgh '\n",
      " 'Festival.\"']\n",
      "'\"14 years old\"'\n",
      "\n",
      "[0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n",
      "[1.3939047821026512e-11, 0.9379736437149988, 0.9607071389606728, 0.9999999999621968, 1.2421889948936653e-12]\n",
      "[4.6463492736755036e-12, 0.6253157624766659, 0.3202357129868909, 0.6666666666414645, 1.2421889948936653e-12]\n",
      "('Were the 2002 American sports drama film \"The Rookie\" and the 1957 \"The '\n",
      " 'Rookie\" painting by American artist Norman Rockwell both inspired by the '\n",
      " 'same athlete?')\n",
      "['No',\n",
      " '\"No, the 2002 American sports drama film \"The Rookie\" and the 1957 \"The '\n",
      " 'Rookie\" painting by American artist Norman Rockwell were not inspired by the '\n",
      " 'same athlete.\"',\n",
      " '\"The 2002 American sports drama film \"The Rookie\" and the 1957 \"The Rookie\" '\n",
      " 'painting by American artist Norman Rockwell were not both inspired by the '\n",
      " 'same athlete.\"',\n",
      " '\"No, the 2002 American sports drama film \"The Rookie\" and the 1957 \"The '\n",
      " 'Rookie\" painting by American artist Norman Rockwell were not both inspired '\n",
      " 'by the same athlete.\"',\n",
      " '\"No, they were based on different athletes.\"']\n",
      "'\"no, different athletes\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[1.3939047821026512e-11, 0.9621954581250233, 0.7071067809859904, 0.37684991632384973, 0.9999999999264825, 0.7071067809859904]\n",
      "[6.969523910513256e-12, 0.48109772906251164, 0.3535533904929952, 0.18842495816192487, 0.49999999996324124, 0.3535533904929952]\n",
      "('Did the debut of \"The Man Show\" and the UK Singles Chart peak of the song '\n",
      " '\"Why Does It Always Rain on Me\" occur in the same year?')\n",
      "['Yes.',\n",
      " '\"Yes, the debut of \"The Man Show\" and the UK Singles Chart peak of the song '\n",
      " '\"Why Does It Always Rain on Me\" occured in the same year\"',\n",
      " '\"Yes, both events happened in the same year.\"',\n",
      " '\"Yes, they occurred in the same year.\"',\n",
      " '\"Yes, the debut of \"The Man Show\" and the UK Singles Chart peak of the song '\n",
      " '\"Why Does It Always Rain on Me\" occured in the same year.\"',\n",
      " '\"Yes, these events happened in the same  year.\"']\n",
      "'\"Yes, 1999.\"'\n",
      "\n",
      "[1.0, 1.0, 0.5, 0.5, 1.0, 1.0]\n",
      "[0.00022313015995319128, 0.5231163089099012, 0.4738611152162556, 1.0445522729063402e-12, 1.2574334292795093e-08, 0.23287896951259746]\n",
      "[0.00022313015995319128, 0.5231163089099012, 0.2369305576081278, 5.222761364531701e-13, 1.2574334292795093e-08, 0.23287896951259746]\n",
      "('How long after becoming a city did Coldwater Michigan experience the opening '\n",
      " \"of Michigan's State Public School?\")\n",
      "['13 years',\n",
      " '\"Coldwater, Michigan experienced the opening of Michigan\\'s State Public '\n",
      " 'School thirteen years after becoming a city.\"',\n",
      " '\"10 years after Coldwater Michigan became a city it experienced the opening '\n",
      " 'of Michigan\\'s State Public School\"',\n",
      " '\"There were 34 years between the two events.\"',\n",
      " '\"It was 13 years later.\"',\n",
      " '\"Michigan\\'s State Public School opened in 1874, 13 years after Coldwater, '\n",
      " 'Michigan was incorporated as a city.\"']\n",
      "'\"13 years\"'\n",
      "\n",
      "[0.5, 0.5, 0.5]\n",
      "[5.939694940227884e-05, 0.4154794556202093, 2.680165156076365e-09]\n",
      "[2.969847470113942e-05, 0.20773972781010466, 1.3400825780381825e-09]\n",
      "('How is the oldest form of music made that is found in a choir and organized '\n",
      " 'in choral music?')\n",
      "['With the human voice.',\n",
      " '\"That form of music is made vocally.\"',\n",
      " '\"Vocal music is the oldest form of music.\"',\n",
      " '\"Vocal music is probably the oldest form of music\"',\n",
      " '\"Vocal music is probably the oldest form of music, since it does not require '\n",
      " 'any instrument besides the human voice.\"',\n",
      " '\"Vocal music can be made by screaming, growling, throat singing, or '\n",
      " 'yodelling, among other techniques; it requires only the voice.\"']\n",
      "'\"only uses the human voice\"'\n",
      "\n",
      "[0.6666666666666666, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5, 0.6666666666666666]\n",
      "[0.5877283724477892, 0.6891557807180503, 5.224081267611123e-05, 0.6566137936206581, 0.26782849582389207, 0.8327418162460896]\n",
      "[0.3918189149651928, 0.45943718714536685, 2.6120406338055614e-05, 0.4377425290804387, 0.13391424791194603, 0.5551612108307263]\n",
      "('In which city can you find both an international airport and the Emirates '\n",
      " 'Club, pro football club?')\n",
      "['Ras Al Khaimah has an international airport and the Emirates Club.',\n",
      " '\"Ras Al Khaimah is the city where you can find both an international airport '\n",
      " 'and the Emirates Club, pro football club\"',\n",
      " '\"You can find all of these at Ras Al Khaimah.\"',\n",
      " '\"You can find an international airport and the Emirates Club, pro football '\n",
      " 'club in the city of Ras Al Khaimah.\"',\n",
      " '\"Both are found in Ras Al Khaimah.\"',\n",
      " '\"You can find both an international airport and the Emirates Club, pro '\n",
      " 'football club in Ras Al Khaimah.\"']\n",
      "'\"Ras Al Khaimah, United Arab Emirates.\"'\n",
      "\n",
      "[0.75, 0.75, 0.75, 0.75, 0.75, 0.75]\n",
      "[0.5424888010543112, 0.8415565472106424, 0.5645588237486409, 0.2847262120235456, 5.943817664613028e-09, 0.4973567355687908]\n",
      "[0.4068666007907334, 0.6311674104079819, 0.42341911781148067, 0.21354465901765918, 4.457863248459771e-09, 0.3730175516765931]\n",
      "('What practice that is reminiscent of baptism do Christians use to remind '\n",
      " 'them of the promises made upon baptism, whether as an infant or an adult?')\n",
      "['They use holy water that is blessed by a priest to remind them of their '\n",
      " 'baptismal promises.',\n",
      " '\"The use of holy water is a reminder of the baptismal promises.\"',\n",
      " '\"The use of holy water that is blessed by a priest or a deacon is the '\n",
      " 'practice in question.\"',\n",
      " '\"The use of holy water is a practice that is reminiscent of baptism and is '\n",
      " 'used by Christians to remind them of the promises made upon baptism, whether '\n",
      " 'as an infant or an adult.\"',\n",
      " '\"Holy water is often used to remind Christians of baptism.\"',\n",
      " '\"Using holy water is believed to be a reminder of the baptismal promises.\"']\n",
      "'\"The blessing of holy water.\"'\n",
      "\n",
      "[1.0, 1.0, 1.0, 0.5, 1.0]\n",
      "[7.646460556623667e-10, 0.6763047111850591, 0.7605636835918287, 0.7539352393812688, 1.537842166783819e-05]\n",
      "[7.646460556623667e-10, 0.6763047111850591, 0.7605636835918287, 0.3769676196906344, 1.537842166783819e-05]\n",
      "('What kind of law were both the Acts of Apparel and the law that exhorted '\n",
      " 'males to not wear silk clothes?')\n",
      "['They are called sumptuary laws.',\n",
      " '\"Sumptuary is the kind of law were both the Acts of Apparel and the law that '\n",
      " 'exhorted males to not wear silk clothes\"',\n",
      " '\"The Acts of Apparel and the law that exhorted males to not wear silk '\n",
      " 'clothes were both sumptuary laws.\"',\n",
      " '\"Both the Acts of Apparel and the law that exhorted males to not wear silk '\n",
      " 'clothes were laws pertaining to clothing.\"',\n",
      " '\"A Statute Concerning Diet and Apparel was a sumptuary law and was one of a '\n",
      " 'series of laws that form what are known as the Acts of Apparel. Males are '\n",
      " 'exhorted not to wear silk clothes through Islamic sumptuary laws. The answer '\n",
      " 'is sumptuary law.\"']\n",
      "'\"sumptuary laws\"'\n",
      "\n",
      "[1.0, 1.0, 1.0, 0.5, 0.5, 1.0]\n",
      "[0.0003678794408495482, 4.5936133196460516e-05, 9.554427919774495e-09, 0.00012574334290280228, 0.7825422899429405, 0.5828233953717938]\n",
      "[0.0003678794408495482, 4.5936133196460516e-05, 9.554427919774495e-09, 6.287167145140114e-05, 0.39127114497147025, 0.5828233953717938]\n",
      "('What character does Shenae Grimes portray who is an aspiring actress who '\n",
      " 'moves to Beverly Hills?')\n",
      "['Annie Wilson.',\n",
      " '\"Shanae Grimes plays an aspiring actress named Annie Wilson.\"',\n",
      " '\"She plays the character Annie Wilson.\"',\n",
      " '\"Shenae Grimes portrays Annie.\"',\n",
      " '\"Annie is an aspiring actress who moves to Beverly Hills\"',\n",
      " '\"Shenae Grimes portrays Annie Wilson, who is an aspiring actress who moves '\n",
      " 'to Beverly Hills.\"']\n",
      "'\"Annie Wilson\"'\n",
      "\n",
      "[0.3076923076923077, 0.46153846153846156, 0.38461538461538464, 0.5384615384615384, 0.46153846153846156]\n",
      "[1.720854139627232e-05, 0.7978739410052669, 0.9174014450410533, 0.6783017596913866, 0.6280707731640274]\n",
      "[5.294935814237638e-06, 0.3682495112332001, 0.35284670963117437, 0.3652394090645928, 0.28987881838339724]\n",
      "('In addition to being affected by the tides, wind, atmospheric pressure, and '\n",
      " 'temperature, what other factors determine sea level?')\n",
      "['In the case that the world ocean on average is young, the seafloor with be '\n",
      " 'relatively shallow and in effect the sea level will be high.',\n",
      " '\"Local gravitational differences, temperature, and salinity also determine '\n",
      " 'sea level.\"',\n",
      " '\"In addition to being affected by the tides, wind, atmospheric pressure, and '\n",
      " 'temperature, local gravitational differences and salinity determine sea '\n",
      " 'level.\"',\n",
      " '\"In addition to being affected by the tides, wind, atmospheric pressure, and '\n",
      " 'temperature, sea level is determined by local gravitational differences\"',\n",
      " '\"In addition to being affected by the tides, wind, atmospheric pressure, and '\n",
      " 'temperature, sea level is also determined by local gravitational '\n",
      " 'differences, salinity, and the age of the world ocean.\"',\n",
      " '\"In addition to being affected by the tides, wind, atmospheric pressure and '\n",
      " 'temperature, the sea level is also affected by local gravitational '\n",
      " 'differences and salinity.\"']\n",
      "('\"The slope of the continental shelf, local differences in gravity, and '\n",
      " 'salinity are three more.\"')\n",
      "\n",
      "[0.5, 0.5, 0.5]\n",
      "[0.6914415691741982, 0.5623413250567932, 0.19860074524418025]\n",
      "[0.3457207845870991, 0.2811706625283966, 0.09930037262209013]\n",
      "('If one had the female name Nielsa, what name would that translate into if '\n",
      " 'one were in America?')\n",
      "['Nielsa is the feminine form of Niels and Niels is the root of Nielson which '\n",
      " 'translates to Nelson in America.',\n",
      " '\"The female name Nielsa would translate to Nelson.\"',\n",
      " '\"The name would translate to Nelson.\"',\n",
      " '\"That would translate to Nelson.\"',\n",
      " '\"The female name Nielsa translates to Nelson if one were to translate it '\n",
      " 'into English in America.\"']\n",
      "'\"The name Nicole\"'\n",
      "\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "[4.7192976329474405e-05, 1.2093855513630156e-08, 0.6389431040881217]\n",
      "[1.57309921098248e-05, 4.031285171210051e-09, 0.21298103469604057]\n",
      "'How old was Akhtar Raza Khan when he got married?'\n",
      "['He was 24 when he got married.',\n",
      " '\"Akhtar Raza Khan was 24 when he got married?\"',\n",
      " '\"Akhtar Raza Khan married at the age of 25.\"',\n",
      " '\"He was 25 at the time.\"',\n",
      " '\"Akhtar Raza Khan was 25 when he got married.\"']\n",
      "'\"25 years old.\"'\n",
      "\n",
      "[0.5, 1.0, 0.5, 0.5]\n",
      "[0.7175852913353725, 0.7860753019966, 0.6418910528207539, 0.6029094773276028]\n",
      "[0.35879264566768626, 0.7860753019966, 0.32094552641037694, 0.3014547386638014]\n",
      "('Did Central Michigan have more All-IIAC first-team players in the season '\n",
      " 'where Ralph Sofferdine and Larry Moore won team MVP, or the season when '\n",
      " 'Chuck Koons won team MVP?')\n",
      "['The season when Ralph Sofferdine and Larry Moore won team MVP',\n",
      " '\"They had more when Moore won MVP.\"',\n",
      " '\"Central Michigan had more All-IIAC first-team players in the 1962 season.\"',\n",
      " '\"Central Michigan had more All-IIAC first-team players in the season where '\n",
      " 'Ralph Sofferdine and Larry Moore won team MVP than in the season where Chuck '\n",
      " 'Koons won team MVP.\"',\n",
      " '\"They had more All-IIAC first-team players in the season where Ralph '\n",
      " 'Sofferdine and Larry Moore won team MVP, as they had five such players in '\n",
      " 'that season, but only four in the season where Chuck Koons won team MVP.\"']\n",
      "'\"the 1962 season\"'\n",
      "\n",
      "[0.5, 1.0, 0.5]\n",
      "[0.6687403046281203, 0.4231178541294984, 0.7071067808182633]\n",
      "[0.33437015231406014, 0.4231178541294984, 0.35355339040913164]\n",
      "('What type of geological phenomenon is Mount Etna and the other name of a '\n",
      " 'composite volcano?')\n",
      "['They are stratovolcanos.',\n",
      " '\"Mount Etna and Mauna Kea are stratovolcanoes.\"',\n",
      " '\"Mount Etna and the other name of a composite volcano are stratovolcanoes.\"',\n",
      " '\"Mount Etna is a stratovolcano.\"',\n",
      " '\"Mount Etna is an active stratovolcano which is the other name of a '\n",
      " 'composite volcano.\"',\n",
      " '\"Mount Etna is a stratovolcano\"']\n",
      "'\"an active stratovolcano\"'\n",
      "\n",
      "[1.0, 0.8, 0.8, 0.8, 1.0, 0.8]\n",
      "[0.5059974314168683, 0.8557222469601231, 0.7643838122099781, 0.8571061116436268, 0.455417327077688, 0.6118729878789785]\n",
      "[0.5059974314168683, 0.6845777975680986, 0.6115070497679825, 0.6856848893149015, 0.455417327077688, 0.4894983903031828]\n",
      "('What are the basic capabilities of the surveillance and target acquisitions '\n",
      " 'portions of the RSTA operations?')\n",
      "['They watch an area to see what changes and acquire targets based on that '\n",
      " 'information.',\n",
      " '\"Surveillance and target acquisition in RSTA involves watching an area to '\n",
      " 'see what changes (surveillance) and then the acquisition of targets based on '\n",
      " 'that information.\"',\n",
      " '\"They are watching an area to see what changes and then the acquisition of '\n",
      " 'targets based on that information\"',\n",
      " '\"Basic capabilities involve watching an area to see what changes '\n",
      " '(surveillance) and then the acquisition of targets based on that '\n",
      " 'information.\"',\n",
      " '\"The basic capabilities of the surveillance and target acquisition portions '\n",
      " 'of the RSTA operations are watching an area to see what changes '\n",
      " '(surveillance) and then acquiring targets based on that information.\"',\n",
      " '\"Surveillance and target acquisition is a military role assigned to units '\n",
      " 'and/or their equipment. It involves watching an area to see what changes '\n",
      " '(surveillance) and then the acquisition of targets based on that '\n",
      " 'information.\"']\n",
      "'\"Watching an area and acquiring targets\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 1.0, 1.0]\n",
      "[4.4016240625277834e-05, 0.7166258374748192, 0.9740274533679583, 0.48902552900791785, 0.905728498019393, 0.3335910322568057]\n",
      "[2.2008120312638917e-05, 0.3583129187374096, 0.48701372668397913, 0.24451276450395892, 0.905728498019393, 0.3335910322568057]\n",
      "('What name is shared by a planetoid, distinct region in the Realm of the dead '\n",
      " \"who aren't honored or dishonored and it's ruled by Hela and is also a Pass, \"\n",
      " 'with the official name of Colchuck Pass?')\n",
      "['The name shared by Colchuck Pass and planetoid, realm of the dead is Asgard.',\n",
      " '\"The name Asgard is shared by a planetoid, with the official name of '\n",
      " 'Colchuck Pass.\"',\n",
      " '\"Asgard is the name shared by a planetoid, distinct region in the Realm of '\n",
      " \"the dead who aren't honored or dishonored and it's ruled by Hela and is also \"\n",
      " 'a Pass, with the official name of Colchuck Pass.\"',\n",
      " '\"Asgard is the name shared by a planetoid, an unique territory in the Realm '\n",
      " \"of the Dead that isn't honored or dishonored, and it's ruled by Hela, as \"\n",
      " 'well as a Pass with the official name of Colchuck Pass.\"',\n",
      " '\"Aasgard Pass, whose name is shared by a planetoid, distinct region in the '\n",
      " \"Realm of the dead who aren't honored or dishonored and it's ruled by Hela \"\n",
      " 'and is also a Pass, with the official name of Colchuck Pass.\"',\n",
      " '\"Asgard is the name of a fictional planetoid, and Aasgard Pass is the '\n",
      " 'official name of the Colchuck Pass.\"']\n",
      "'\"Aasgard Pass\"'\n",
      "\n",
      "[1.0, 0.75, 0.75, 0.75, 0.75]\n",
      "[6.395245098669694e-07, 0.7438252804005364, 0.9053695904095419, 0.755059484147278, 0.8974269664600314]\n",
      "[6.395245098669694e-07, 0.5578689603004023, 0.6790271928071564, 0.5662946131104585, 0.6730702248450235]\n",
      "('What did the first season of the Swans 3-season winning streak in the WAFL '\n",
      " 'have in common with the VFL Grand Final that was held on a September 25 at '\n",
      " 'the Melbourne Cricket ground in Melbourne?')\n",
      "['They were both held in 1982',\n",
      " '\"The first season of the Swans 3-season winning streak in the WAFL, and he '\n",
      " 'VFL Grand Final that was held on a September 25 at the Melbourne Cricket '\n",
      " 'ground in Melbourne were both held during the year 1982.\"',\n",
      " '\"The first season of the Swans 3-season winning streak in the WAFL and the '\n",
      " 'VFL Grand Final that was held on a September 25 at the Melbourne Cricket '\n",
      " 'ground in Melbourne both started in 1982\"',\n",
      " '\"The first season of the Swans 3-season winning streak in the WAFL had the '\n",
      " 'year 1982 in common with the VFL Grand Final that was held on a September 25 '\n",
      " 'at the Melbourne Cricket ground in Melbourne.\"',\n",
      " '\"The first season of the Swans 3-season winning streak in the WAFL and the '\n",
      " 'VFL Grand Final that was held on a September 25 at the Melbourne Cricket '\n",
      " 'ground in Melbourne both took place in 1982.\"']\n",
      "'\"they were in 1982\"'\n",
      "\n",
      "[0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 1.0]\n",
      "[3.3521134184793864e-05, 0.7825422899735328, 0.8344522895723738, 0.3678794410227578, 0.496168299944889]\n",
      "[1.1173711394931288e-05, 0.7825422899735328, 0.27815076319079124, 0.3678794410227578, 0.496168299944889]\n",
      "'How old was Yuka Koide when Yuka Saito got married to Takeshi Kusao?'\n",
      "['30. Koide was born in 1985 and Saito got married in 2015',\n",
      " '\"Yuka Koide was 30 years old when Yuka Saito got married to Takeshi Kusao.\"',\n",
      " '\"Yuka Koide was 30 when Yuka Saito got married to Takeshi Kusao.\"',\n",
      " '\"Yuka Koide was 30 years old.\"',\n",
      " '\"When Yuka Saito married Takeshi Kusao, Yuka Koide was 30 years old.\"']\n",
      "'\"30 years old\"'\n",
      "\n",
      "[1.0, 1.0, 0.5, 1.0]\n",
      "[1.2574334290280229e-08, 0.9036020035156419, 1.871311409458588e-08, 0.9036020035156419]\n",
      "[1.2574334290280229e-08, 0.9036020035156419, 9.35655704729294e-09, 0.9036020035156419]\n",
      "('What kind of area is the Parcul Natural Cefa and the place that is in the '\n",
      " 'hydrographical basin of the Putna?')\n",
      "['They are a Natural Park.',\n",
      " '\"They are in protected areas.\"',\n",
      " '\"The Parcul Natural Cefa and the place that is in the hydrographical basin '\n",
      " 'of the Putna are both national parks.\"',\n",
      " '\"They are both parks.\"',\n",
      " '\"The Parcul Natural Cefa and the place that is in the hydrographical basin '\n",
      " 'of the Putna are both natural parks.\"']\n",
      "'\"Natural Park\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 1.0, 1.0]\n",
      "[4.978706832430036e-05, 0.6308068516198804, 0.38967188122673563, 3.0623636037672815e-05, 0.8648454150228945]\n",
      "[4.978706832430036e-05, 0.3154034258099402, 0.38967188122673563, 3.0623636037672815e-05, 0.8648454150228945]\n",
      "'The Waldsteinburg is a castle on a mountain summit which is how high?'\n",
      "['877 metres',\n",
      " '\"The Waldsteinburg is a castle on a mountain summit that\\'s 877 meters '\n",
      " 'high.\"',\n",
      " '\"The Waldsteinburg is a castle on the summit of the Großer Waldstein in the '\n",
      " 'Fichtel Mountains of Germany, which is 877 metres high.\"',\n",
      " '\"Großer Waldstein is 877 metres (2,877 ft) high.\"',\n",
      " '\"The Waldsteinburg is a castle on a mountain summit which is 877 metres '\n",
      " 'high.\"']\n",
      "'\"877 metres\"'\n",
      "\n",
      "[0.5, 1.0, 1.0, 0.5, 1.0]\n",
      "[0.3945881255245354, 0.7126109689704401, 0.9999999999351453, 0.8313539763197327, 0.804615058252844]\n",
      "[0.1972940627622677, 0.7126109689704401, 0.9999999999351453, 0.41567698815986637, 0.804615058252844]\n",
      "'What does the text that was translated by Kumārajīva try to refute?'\n",
      "[\"It tries to refute the criticism that Buddhism's monastic focus undermines \"\n",
      " 'filial piety.',\n",
      " '\"The text that was translated by Kumārajīva, the Sutra of Filial Piety, '\n",
      " \"tries to refute Confucian criticism that Buddhism's traditionally monastic \"\n",
      " 'focus undermines the virtue of filial piety.\"',\n",
      " '\"It tries to refute Confucian criticism that Buddhism\\'s traditionally '\n",
      " 'monastic focus undermines the virtue of filial piety.\"',\n",
      " '\"The text that was translated by Kumārajīva tries to refute Confucian '\n",
      " 'ideals.\"',\n",
      " '\"The text that was translated by Kumārajīva tries to refute Confucian '\n",
      " \"criticism that Buddhism's traditionally monastic focus undermines the virtue \"\n",
      " 'of filial piety.\"']\n",
      "'\"Confucian criticism\"'\n",
      "\n",
      "[0.75, 0.75, 0.5, 1.0]\n",
      "[0.6188604784024277, 0.7855348580698538, 0.7825422898146908, 0.9457416087349345]\n",
      "[0.46414535880182084, 0.5891511435523904, 0.3912711449073454, 0.9457416087349345]\n",
      "('Was the weapon nicknamed Möbelwagen and the 1.1\"/75 caliber gun both used in '\n",
      " 'the same war?')\n",
      "['The Möbelwagen and the 1.1\"/75 caliber gun were both used during World War '\n",
      " 'II.',\n",
      " '\"The weapons named Möbelwagen and the 1.1\"/75 caliber gun were both used in '\n",
      " 'World War II.\"',\n",
      " '\"Yes, both were used in the same war.\"',\n",
      " '\"The weapon nicknamed Möbelwagen and the 1.1\"/75 caliber gun were both used '\n",
      " 'in the same war\"',\n",
      " '\"Yes, both were used in World War II.\"']\n",
      "'\"Yes, World War II\"'\n",
      "\n",
      "[1.0, 1.0, 0.6, 1.0, 0.6, 0.6]\n",
      "[0.5488116358081874, 0.4832697830390307, 0.610195043038188, 0.6685732242586269, 0.6756000773113596, 0.47287080444496554]\n",
      "[0.5488116358081874, 0.4832697830390307, 0.3661170258229128, 0.6685732242586269, 0.4053600463868158, 0.2837224826669793]\n",
      "'What positions did Cecil Paget hold at Derby Works?'\n",
      "['Works Manager and General Superintendent',\n",
      " '\"Cecil Paget was general superintendent and works manager at Derby Works.\"',\n",
      " '\"Cecil Paget was general superintendent at Derby Works.\"',\n",
      " '\"Cecil Paget held the positions of Works Manager and General Superintendent '\n",
      " 'at Derby Works.\"',\n",
      " '\"Cecil Paget was the General Superintendent at Derby Works.\"',\n",
      " '\"Cecil Paget held the General Superintendent position at Derby Works.\"']\n",
      "'\"Works Manager and General Superintendent\"'\n",
      "\n",
      "[0.75, 0.75, 1.0]\n",
      "[0.0005791913564370277, 0.7573885179500758, 0.47245835681928156]\n",
      "[0.00043439351732777083, 0.5680413884625568, 0.47245835681928156]\n",
      "('What conference did the Michigan Wolverines football team play in the year '\n",
      " 'Bill Freehan was hit by a pitch 24 times in a single season?')\n",
      "['Big Ten Conference.',\n",
      " '\"The Michigan Wolverines football team played in the Big Ten Conference in '\n",
      " 'the year Bill Freehan was hit by a pitch 24 times in a single season.\"',\n",
      " '\"It says that Freehan was hit by a pitch 24 times in 1968 and that The 1968 '\n",
      " 'Michigan Wolverines football team represented the University of Michigan in '\n",
      " 'the 1968 Big Ten Conference football season. Therefore the answer is the Big '\n",
      " 'Ten Conference.\"',\n",
      " '\"The Michigan Wolverines football team represented the University of '\n",
      " 'Michigan in 1968, the year Bill Freehan was hit by a pitch 24 times in a '\n",
      " 'single season.\"',\n",
      " '\"Bill Freehan was hit by a pitch 24 times in a single season in 1968.\"']\n",
      "'\"1968 Big Ten Conference\"'\n",
      "\n",
      "[0.6, 0.4, 0.4, 0.4]\n",
      "[4.051197204697244e-05, 2.9452743651560214e-05, 4.873039688361635e-05, 5.6591192562306006e-05]\n",
      "[2.4307183228183463e-05, 1.1781097460624086e-05, 1.949215875344654e-05, 2.2636477024922402e-05]\n",
      "('How do the number of member states of the European Union compare to the '\n",
      " 'number of member states of the United Nations?')\n",
      "['There are significantly more members of the United Nations, encompassing 193 '\n",
      " \"sovereign states to the European Union's 27 members.\",\n",
      " '\"There are less member states in the EU than in the UN.\"',\n",
      " '\"The European Union (EU) consists of 27 member states, whereas the United '\n",
      " 'Nations member states are 193 sovereign states.\"',\n",
      " '\"The United Nations has more member states than the European Union does.\"',\n",
      " '\"There are more states in the United Nations.\"',\n",
      " '\"There are more member states of the United Nations than member states of '\n",
      " 'the EU.\"']\n",
      "'\"166 fewer states in EU\"'\n",
      "\n",
      "[0.8, 1.0, 0.8, 0.8, 1.0, 1.0]\n",
      "[0.27952792727404036, 0.9999999999036617, 0.16299446730562733, 0.6432188697623412, 0.7505336182150305, 0.4569328549088463]\n",
      "[0.2236223418192323, 0.9999999999036617, 0.13039557384450187, 0.514575095809873, 0.7505336182150305, 0.4569328549088463]\n",
      "('Where is the Holy of Holies in the church that defines membership as: Those '\n",
      " 'who have been baptized and confirmed?')\n",
      "['In the Salt Lake Temple',\n",
      " '\"The Holy of Holies is a room in the Salt Lake Temple.\"',\n",
      " '\"The Holy of Holies in the church that defines membership as \"those who have '\n",
      " 'been baptized and confirmed\" is found at Salt Lake Temple.\"',\n",
      " '\"The Holy of Holies is in the Salt Lake Temple.\"',\n",
      " '\"The Holy of Holies is a room in the Salt Lake Temple of the LDS Church.\"',\n",
      " '\"In the Church of Jesus Christ of Latter-day Saints, the Holy of Holies is a '\n",
      " 'room in the Salt Lake Temple.\"']\n",
      "'\"room in the Salt Lake Temple\"'\n",
      "\n",
      "[1.0, 1.0, 0.5, 1.0, 1.0]\n",
      "[0.00833567340487775, 7.311104454657567e-05, 0.660632863439242, 6.803749330907337e-05, 0.7476743904255464]\n",
      "[0.00833567340487775, 7.311104454657567e-05, 0.330316431719621, 6.803749330907337e-05, 0.7476743904255464]\n",
      "('Between The Independent Commission on Policing for Northern Ireland and The '\n",
      " 'Garda Síochána which was/is headed by the Garda Commissioner?')\n",
      "['The Garda Síochána',\n",
      " '\"The Garda Commissioner heads the Garda Síochána.\"',\n",
      " '\"The Garda Siochana is headed by the Garda Commissioner.\"',\n",
      " '\"The Garda Commissioner headed The Garda Síochána.\"',\n",
      " '\"The Garda Síochána is headed by the Garda Commissioner.\"']\n",
      "'\"Garda Síochána\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5]\n",
      "[0.9999999998957473, 0.9554427921047594, 0.7978381198094268, 0.9579472507872808]\n",
      "[0.49999999994787364, 0.4777213960523797, 0.3989190599047134, 0.4789736253936404]\n",
      "('What does the 401st Fighter Squadron and the 755th Bombardment Squadron of '\n",
      " 'the US Air Force have in common regarding their establishment?')\n",
      "['They were both established/activated in July, 1943',\n",
      " '\"The 401st Fighter Squadron and the 755th Bombardment Squadron of the US Air '\n",
      " 'Force were both established in July 1943.\"',\n",
      " '\"The 401st Fighter Squadron and the 755th Bombardment Squadron of the US Air '\n",
      " 'Force are both established in July 1943.\"',\n",
      " '\"They were both established or activated in July 1943.\"',\n",
      " '\"The 401st Fighter Squadron and the 755th Bombardment Squadron of the US Air '\n",
      " 'Force are both in Oklahoma.\"',\n",
      " '\"The 401st Fighter Squadron and the 755th Bombardment Squadron of the US Air '\n",
      " 'Force were both established in July 1943\"']\n",
      "'\"Air bases\"'\n",
      "\n",
      "[0.6666666666666666, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334]\n",
      "[5.501034141770605e-13, 0.8881501211228651, 0.6367373508085807, 0.7298360142352576]\n",
      "[3.6673560945137365e-13, 0.7401251009357209, 0.5306144590071507, 0.6081966785293813]\n",
      "'How does Fiber to the x send telecommunications?'\n",
      "['By utilizing optical fiber, it sends light which forms a carrier signal that '\n",
      " 'carries information.',\n",
      " '\"Fiber to the x sends telecommunications from one place to another by '\n",
      " 'sending light through an optical fiber.\"',\n",
      " '\"Fiber-optic communication systems transmit information from one place to '\n",
      " 'another by sending light through an optical fiber.\"',\n",
      " '\"Fiber to the x sends telecommunications by sending light through an optical '\n",
      " 'fiber.\"']\n",
      "'\"Through sending light through an optical fiber.\"'\n",
      "\n",
      "[0.5, 1.0, 1.0]\n",
      "[1.0445522729469615e-12, 0.5737074988775397, 0.3482990918400241]\n",
      "[5.222761364734807e-13, 0.5737074988775397, 0.3482990918400241]\n",
      "('Which cancer is a very rare histologic disease affecting stellate shaped '\n",
      " 'cells that are also called basket cells?')\n",
      "['Epithelial-myoepithelial tumor are rare and shaped in a stellate form.',\n",
      " '\"Epithelial-myoepithelial carcinoma of the lung is a very rare histologic '\n",
      " 'disease affecting stellate shaped cells that are also called basket cells.\"',\n",
      " '\"Epithelial-myoepithelial carcinoma of the lung is a type of cancer which is '\n",
      " 'a very rare histologic disease that affects the stellate shaped '\n",
      " 'Myoepithelial cells. Myoepithelial cells are also known by the name basket '\n",
      " 'cells.\"',\n",
      " '\"Myoepithelioma is a cancer of myoepithelial cells.\"']\n",
      "'\"Epithelial-myoepithelial carcinoma\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 1.0, 0.5, 1.0]\n",
      "[0.5170787125129048, 0.35131458626381135, 0.4169392926979028, 0.7194089027599377, 0.5711023015364362, 0.652622081730238]\n",
      "[0.5170787125129048, 0.17565729313190567, 0.4169392926979028, 0.7194089027599377, 0.2855511507682181, 0.652622081730238]\n",
      "('How long after Lambert started lobbying for a second season of Doctor Who '\n",
      " 'did it start airing?')\n",
      "['The second season started airing on 31 October which was 2 months after '\n",
      " 'Lambert started lobbying for it.',\n",
      " '\"Verity Lambert began lobbying for a second season of Doctor Who in August, '\n",
      " '1964. The second season the science fiction series Doctor Who began airing '\n",
      " 'approximately three months later on October 31, 1964\"',\n",
      " '\"Two months after Lambert began advocating for a second season of Doctor '\n",
      " 'Who, the show premiered.\"',\n",
      " '\"The second season of Doctor Who started airing two months after Lambert '\n",
      " 'started lobbying for it.\"',\n",
      " '\"Doctor Who started a few months after Verity Lambert began lobbying for a '\n",
      " 'second season.\"',\n",
      " '\"It started airing 2 months after Lambert started lobbying for a second '\n",
      " 'season.\"']\n",
      "'\"2 months\"'\n",
      "\n",
      "[1.0, 0.4, 0.4, 0.8]\n",
      "[5.721248422925795e-05, 5.186805879258314e-09, 0.8801117365999962, 3.695372083780018e-05]\n",
      "[5.721248422925795e-05, 2.0747223517033257e-09, 0.3520446946399985, 2.9562976670240145e-05]\n",
      "'Are freshwater mussels and clams the only filter-feeding bivlaves?'\n",
      "['No, all species of bivalves are filter feeders.',\n",
      " '\"No. There are over 30,000 species of bivalves, including the fossil '\n",
      " 'species.\"',\n",
      " '\"Freshwater mussels and clams are not the only filter-feeding bivalves.\"',\n",
      " '\"No, they are not the only filter-feeding bivlaves.\"',\n",
      " '\"No, over 30,000 bivalves are filter feeders other than freshwater mussels '\n",
      " 'and clams.\"',\n",
      " '\"Freshwater mussels and clams are not the only filter-feeding bivlaves\"']\n",
      "'\"all bivalves are filter feeders\"'\n",
      "\n",
      "[0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0]\n",
      "[0.00022313015995319128, 0.9999999999254122, 0.8699353243381894, 0.5974970908727522, 9.036020033199396e-05, 0.7677331682957133]\n",
      "[0.00014875343996879418, 0.9999999999254122, 0.5799568828921262, 0.3983313939151681, 6.024013355466264e-05, 0.7677331682957133]\n",
      "('Are Hobbs Army Airfield and Army training base Camp White found in the same '\n",
      " 'US state or different US states?')\n",
      "['different states',\n",
      " '\"Hobbs Army Airfield and Army training base Camp White are found in '\n",
      " 'different US states.\"',\n",
      " '\"Hobbs Army Airfield and Army training base Camp White are in different '\n",
      " 'states\"',\n",
      " '\"Hobbs Army Airfield and Army training base Camp White are not found in the '\n",
      " 'same US state.\"',\n",
      " '\"They are in different states.\"',\n",
      " '\"Hobbs Army Airfield and Camp White are found in different US states.\"']\n",
      "'\"different US states\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[2.397816141809042e-14, 0.9764540895921194, 0.9510699414672664, 0.8333521523938978, 0.8593887046899319]\n",
      "[1.198908070904521e-14, 0.4882270447960597, 0.4755349707336332, 0.4166760761969489, 0.42969435234496595]\n",
      "('How many years after I Am the Blues by  Willie Dixon was released was \"You '\n",
      " 'Don\\'t Even Know Who I Am\" by Gretchen Peters released?')\n",
      "['25',\n",
      " '\"\"You Don\\'t Even Know Who I Am\" by Gretchen Peters was released 25 years '\n",
      " 'after I Am the Blues by Willie Dixon was released.\"',\n",
      " '\"You Don\\'t Even Know Who I Am\" by Gretchen Peters was released 25 years '\n",
      " 'after I Am the Blues by Willie Dixon.\"',\n",
      " '\"25 years after I Am the Blues by Willie Dixon was released,\"You Don\\'t Even '\n",
      " 'Know Who I Am\" by Gretchen Peters released\"',\n",
      " '\"25 years after I Am the Blues by Willie Dixon was released, \"You Don\\'t '\n",
      " 'Even Know Who I Am\" by Gretchen Peters was released.\"']\n",
      "'\"About 25\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5]\n",
      "[0.9426151475778155, 0.9426151475778155, 0.8277932959419472, 0.8883547142709762]\n",
      "[0.47130757378890775, 0.47130757378890775, 0.4138966479709736, 0.4441773571354881]\n",
      "('A fixed action pattern and behaviors that may be maladaptive, involving '\n",
      " 'self-injury or reduced reproductive success are what type of behaviors?')\n",
      "['Stereotyped.',\n",
      " '\"A fixed action pattern and behaviors that may be maladaptive, involving '\n",
      " 'self-injury or reduced reproductive success are stereotyped behaviors.\"',\n",
      " '\"A fixed action pattern and behaviors that may be maladaptive, involving '\n",
      " 'self-injury or reduced reproductive success are stereotyped  behaviors\"',\n",
      " '\"fixed action pattern and behaviors that may be maladaptive, involving '\n",
      " 'self-injury or reduced reproductive success are instinctive behavioral '\n",
      " 'sequences\"',\n",
      " '\"A fixed action pattern and behaviors that may be maladaptive, involving '\n",
      " 'self-injury or reduced reproductive success are stereotypies.\"']\n",
      "'\"Stereotyped behaviors\"'\n",
      "\n",
      "[0.3333333333333333, 1.0, 1.0, 1.0]\n",
      "[2.7388268265591994e-09, 0.8232490470944713, 0.7825422899429405, 0.8333521523938978]\n",
      "[9.129422755197331e-10, 0.8232490470944713, 0.7825422899429405, 0.8333521523938978]\n",
      "('What reign period did not occur under the emperor who had Yu Zhong briefly '\n",
      " 'serving as a regent during his reign?')\n",
      "['The Taihe.',\n",
      " '\"The Taihe reign period did not occur under the emperor who had Yu Zhong '\n",
      " 'briefly serving as a regent during his reign\"',\n",
      " '\"The Taihe reign period did not occur under Emperor Xiaoming.\"',\n",
      " '\"The Taihe reign period did not occur under the Emperor who had Yu Zhong '\n",
      " 'briefly serving as a regent during his reign.\"']\n",
      "'\"Taihe reign period\"'\n",
      "\n",
      "[0.5, 1.0, 1.0, 1.0, 1.0]\n",
      "[7.147789179383195e-11, 0.5221307184952051, 0.8761560782555948, 0.8441121389338955, 0.4783236719597441]\n",
      "[3.573894589691597e-11, 0.5221307184952051, 0.8761560782555948, 0.8441121389338955, 0.4783236719597441]\n",
      "('During the final century of whose rule, whom Syagrius competed with for '\n",
      " 'power in northern France, were the kings increasingly pushed into a '\n",
      " 'ceremonial role?')\n",
      "['Merovingian',\n",
      " '\"Kings increasingly pushed into a ceremonial role during the final century '\n",
      " 'of Merovingian rule.\"',\n",
      " '\"During the final century of Merovingian rule, kings were increasingly '\n",
      " 'pushed into a ceremonial role.\"',\n",
      " '\"During the final century of Merovingian rule, the kings were increasingly '\n",
      " 'pushed into a ceremonial role.\"',\n",
      " '\"It was during the reign of Clovis I, the son of Childeric, that Syagrius '\n",
      " 'contended for power in northern France, where the monarchs were being forced '\n",
      " 'into a ceremonial role.\"',\n",
      " '\"During the final century of Merovingian rule, whom Syagrius competed with '\n",
      " 'for power in northern France, the kings increasingly pushed into a '\n",
      " 'ceremonial role.\"']\n",
      "'\"Merovingian rule\"'\n",
      "\n",
      "[0.6666666666666666, 1.0, 1.0, 0.3333333333333333]\n",
      "[0.20774818707447526, 0.6960159732133566, 0.9808875933622485, 0.9999999999457473]\n",
      "[0.1384987913829835, 0.6960159732133566, 0.9808875933622485, 0.33333333331524906]\n",
      "('The country whose saga has provided a historical account of Norse funerals '\n",
      " 'shares a common cultural heritage with which other countries?')\n",
      "['Denmark, the Faroe Islands, Norway, and Sweden.',\n",
      " '\"Iceland shares a common cultural heritage with the Scandinavian countries '\n",
      " 'of Denmark, the Faroe Islands, Norway, and Sweden.\"',\n",
      " '\"The country whose saga has provided a historical account of Norse funerals '\n",
      " 'shares a common cultural heritage with Scandinavian countries of Denmark, '\n",
      " 'the Faroe Islands, Norway, and Sweden.\"',\n",
      " '\"The country whose saga has provided a historical account of Norse funerals '\n",
      " 'shares a common cultural heritage with Scandinavian countries\"']\n",
      "'\"The Scandinavian countries of Denmark, the Faroe Islands, Norway, and Sweden\"'\n",
      "\n",
      "[1.0, 1.0, 0.8, 0.8, 0.8, 1.0]\n",
      "[0.5093498412543512, 0.9125598853061244, 0.7165178402162298, 0.9426151475778155, 0.9999999998899907, 0.8578928091787059]\n",
      "[0.5093498412543512, 0.9125598853061244, 0.5732142721729838, 0.7540921180622524, 0.7999999999119926, 0.8578928091787059]\n",
      "('What is the homeport of the lead ship of the Independence class of littoral '\n",
      " 'combat ships?')\n",
      "['The home port of the USS Independence is Naval Base San Diego, California.',\n",
      " '\"The homeport of the lead ship of the Independence class of littoral combat '\n",
      " 'ships is Naval Base San Diego, California.\"',\n",
      " '\"Naval Base San Diego is the homeport of the USS Independence.\"',\n",
      " '\"Naval Base San Diego is the homeport of the lead ship of the Independence '\n",
      " 'class of littoral combat ships.\"',\n",
      " '\"Naval Base San Diego is the homeport of the lead ship of the Independence '\n",
      " 'class of littoral combat ships\"',\n",
      " '\"The homeport of the lead ship of the Independence class of littoral combat '\n",
      " 'ships was Naval Base San Diego, California.\"']\n",
      "'\"Naval Base San Diego, California\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 1.0]\n",
      "[6.376715692927575e-09, 0.5974970908751231, 1.0330619227359553e-12, 0.5898185344332446, 0.6216190256905751, 0.6234181303992828]\n",
      "[3.1883578464637877e-09, 0.2987485454375616, 5.165309613679777e-13, 0.2949092672166223, 0.31080951284528757, 0.6234181303992828]\n",
      "('Uterus didelphys is a uterine malformation where the uterus is present as a '\n",
      " 'paired organ when the embryogenetic fusion of what paired ducts of the '\n",
      " 'embryo that run down the lateral sides of the urogenital ridge and terminate '\n",
      " 'at the sinus tubercle in the primitive urogenital sinus fails to occur?')\n",
      "['It happens when the Mullerian ducts fail to fuse.',\n",
      " '\"Uterus didelphys is a uterine malformation that occurs when embryogenetic '\n",
      " 'fusion of the paramesonephric ducts fails to occur.\"',\n",
      " '\"The ducts in question are paramesonephric ducts.\"',\n",
      " '\"Uterus didelphys is a uterine malformation where the uterus is present as a '\n",
      " 'paired organ when the embryogenetic fusion of paramesonephric ducts '\n",
      " 'terminate at the sinus tubercle in the primitive urogenital sinus fails to '\n",
      " 'occur.\"',\n",
      " '\"Uterus didelphys is a uterine malformation where the uterus is present as a '\n",
      " 'paired organ when the embryogenetic fusion of the Paramesonephric ducts of '\n",
      " 'the embryo that run down the lateral sides of the urogenital ridge and '\n",
      " 'terminate at the sinus tubercle in the primitive urogenital sinus fails to '\n",
      " 'occur\"',\n",
      " '\"It occurs when the embryogenetic fusion of the Müllerian ducts fails to '\n",
      " 'occur.\"']\n",
      "'\"The Müllerian ducts.\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[4.625839070654737e-05, 0.699887870235901, 0.4805842062725349, 0.7896895366643114, 0.7526098029304232, 7.071067810743787e-05]\n",
      "[2.3129195353273686e-05, 0.3499439351179505, 0.24029210313626745, 0.3948447683321557, 0.3763049014652116, 3.5355339053718935e-05]\n",
      "('The sugar-free pastilles made with gum arabic called Läkerol are made from '\n",
      " 'what kind of company that is called Cloetta?')\n",
      "['A Swedish confectionery company.',\n",
      " '\"The sugar-free pastilles made with gum arabic called Läkerol are made by '\n",
      " 'the Swedish company Cloetta.\"',\n",
      " '\"Swedish confectionery company Cloetta makes sugar-free pastilles made with '\n",
      " 'gum arabic called Läkerol.\"',\n",
      " '\"The sugar-free pastilles made with gum arabic called Läkerol are made by a '\n",
      " 'Swedish confectionery company called Cloetta.\"',\n",
      " '\"The sugar-free pastilles made with gum arabic called Läkerol are made from '\n",
      " 'the Swedish confectionery company called Cloetta\"',\n",
      " '\"A Swedish confectionery company makes the sugar-free pastilles.\"']\n",
      "'\"Candy company\"'\n",
      "\n",
      "[0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666]\n",
      "[0.32771767404643004, 0.9487294799120681, 0.9709835433619685, 0.28313021971814156, 0.3735942070445661]\n",
      "[0.10923922468214334, 0.31624315997068936, 0.6473223622413122, 0.09437673990604718, 0.24906280469637737]\n",
      "('Were Fenrir and the iron she-wolf that the grand duke Gediminas dreamt of '\n",
      " 'both in the same mythology?')\n",
      "['They were not as Fenrir appeared in Norse mythology while Medeina whom the '\n",
      " 'grand duke Gediminas dreamt of appeared in Lithuanian mythology.',\n",
      " '\"Fenrir and the iron she-wolf that the grand duke Gediminas dreamt of were '\n",
      " 'not both in the same mythology.\"',\n",
      " '\"No, Fenrir and the iron she-wolf that the grand duke Gediminas dreamt of '\n",
      " 'were not both in the same mythology.\"',\n",
      " '\"No, the iron she-wolf was from Lithuania and Fenrir is from Norse myth.\"',\n",
      " '\"No, Fenrir is from Norse mythology while the iron she-wolf is from '\n",
      " 'Lithuanian mythology.\"']\n",
      "'\"no, different mythologies\"'\n",
      "\n",
      "[0.5, 1.0, 1.0]\n",
      "[3.902560660212479e-09, 0.8801117365999962, 0.8801117365999962]\n",
      "[1.9512803301062397e-09, 0.8801117365999962, 0.8801117365999962]\n",
      "'The Chimera and Pegasus are mythical creatures from what type of mythology?'\n",
      "['Greek',\n",
      " '\"The Chimera and Pegasus are mythical creatures from Greek mythology.\"',\n",
      " '\"The Chimera and Pegasus are mythical creatures from Greek mythology\"']\n",
      "'\"Greek mythology\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 1.0, 0.5, 1.0]\n",
      "[0.1982406728663299, 0.853141360557912, 0.7539221179084472, 0.3941226347551419, 0.853141360557912, 0.7539221179084472]\n",
      "[0.09912033643316495, 0.426570680278956, 0.3769610589542236, 0.3941226347551419, 0.426570680278956, 0.7539221179084472]\n",
      "('The American voice actor Dan Green is best known for being the voice of what '\n",
      " 'fictional character who is the main character of the manga series Yu-Gi-Oh!?')\n",
      "['He is the voice of Yugi Muto.',\n",
      " '\"The American voice actor Dan Green is best known for being the voice of '\n",
      " 'Yugi Motou who is the main character of the manga series Yu-Gi-Oh!\"',\n",
      " '\"Dan Green is best known for being the voice of Mutou from Yu-Gi-Oh.\"',\n",
      " '\"Dan Green, an American voice actor, is best known as the voice of Yugi '\n",
      " 'Mutou, the main character of the manga series Yu-Gi-Oh.\"',\n",
      " '\"The American voice actor Dan Green is best known for being the voice of '\n",
      " 'Yugi Muto who is the main character of the manga series Yu-Gi-Oh!.\"',\n",
      " '\"The American voice actor Dan Green is best known for voicing Yugi Mutou.\"']\n",
      "'\"Yugi Mutou\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 0.5, 0.5, 1.0]\n",
      "[2.1937646365034236e-06, 0.73879457880161, 0.00010745699315683318, 0.8394327082755885, 0.9306048589253956, 8.657023703488241e-05]\n",
      "[2.1937646365034236e-06, 0.369397289400805, 0.00010745699315683318, 0.41971635413779423, 0.4653024294626978, 8.657023703488241e-05]\n",
      "('Dyslexia is what kind of common language-based disability that contains 64 '\n",
      " 'subcategories and WIkimedia Commons media related to it?')\n",
      "['A learning disability.',\n",
      " '\"Dyslexia is a common learning language-based disability that contains 64 '\n",
      " 'subcategories and WIkimedia Commons media related to it\"',\n",
      " '\"Dyslexia is a language-based learning disability.\"',\n",
      " '\"Dyslexia is a common language-based learning disability that contains 64 '\n",
      " 'subcategories and WIkimedia Commons media related to it.\"',\n",
      " '\"Dyslexia is a common language-based learning disability.\"',\n",
      " '\"Dyslexia is a learning disability.\"']\n",
      "'\"learning disability\"'\n",
      "\n",
      "[1.0, 0.6666666666666666, 1.0, 0.8333333333333334]\n",
      "[0.24764986872287945, 0.7881929716801647, 0.8761560782555948, 0.3853695927923461]\n",
      "[0.24764986872287945, 0.5254619811201098, 0.8761560782555948, 0.3211413273269551]\n",
      "('What style of writing was The Travels of Marco Polo likely written in during '\n",
      " 'that period?')\n",
      "['narrative, prose, essay and diary style',\n",
      " '\"The Travels of Marco Polo was likely  written in essay and diary style.\"',\n",
      " '\"The Travels of Marco Polo was likely written in narrative, prose, essay and '\n",
      " 'diary style.\"',\n",
      " '\"The Travels of Marco Polo was likely written in the style of travel '\n",
      " 'literature.\"',\n",
      " '\"The Travels of Marco Polo was a classic of travel literature and likely '\n",
      " 'written in a narrative, prose, and diary style.\"']\n",
      "'\"Narrative, prose, essay, and diary style\"'\n",
      "\n",
      "[0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571]\n",
      "[0.9999999998203284, 0.9131007161017753, 0.634046627590766, 0.5568544122326815, 0.6010525950706805]\n",
      "[0.8571428569888528, 0.7826577566586645, 0.5434685379349423, 0.47730378191372697, 0.5151879386320118]\n",
      "'Which Greek philosophers proposed that air is both hot and wet?'\n",
      "['Both Plato and Aristotle proposed that air is both hot and wet.',\n",
      " '\"Plato and Aristotle proposed that air is both hot and wet.\"',\n",
      " '\"Both Plato and Aristotle though the air is both hot and wet.\"',\n",
      " '\"Aristotle and Plato were philosophers that proposed that air is both hot '\n",
      " 'and wet.\"',\n",
      " '\"Plato proposed that air is both hot and wet\"']\n",
      "'\"Plato said air is hot and wet\"'\n",
      "\n",
      "[0.3333333333333333, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0]\n",
      "[0.47987820657421176, 0.3832265833506572, 7.84663035422101e-05, 0.914691219047893, 0.8891397048981752, 0.7765453554296355]\n",
      "[0.15995940219140392, 0.3832265833506572, 7.84663035422101e-05, 0.914691219047893, 0.29637990163272504, 0.7765453554296355]\n",
      "'What type of animal lives in Africa that has a slender-snout?'\n",
      "['A type of Crocodile lines in Africa that has a slender-snout',\n",
      " '\"The animal that lives in Africa that has a slender-snout is known as the '\n",
      " 'West African slender-snouted crocodile.\"',\n",
      " '\"The West African slender-snouted crocodile lives in Africa.\"',\n",
      " '\"A West African crocodile lives in Africa and has a slender-snout.\"',\n",
      " '\"The crocodile lives in Africa and has a slender-snout.\"',\n",
      " '\"The West African crocodile lives in Africa and has a slender snout.\"']\n",
      "'\"West African crocodile\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 0.5, 0.5]\n",
      "[1.1192959249681344e-11, 0.9999999999056192, 0.4952330115666676, 0.9217324939077369, 0.9174014450410533]\n",
      "[1.1192959249681344e-11, 0.4999999999528096, 0.4952330115666676, 0.46086624695386846, 0.4587007225205266]\n",
      "('There are 139 prehistoric what in the Radnorshire area that include Roman '\n",
      " 'sites, all related to the military occupation of Wales?')\n",
      "['Scheduled Monuments.',\n",
      " '\"There are 139 prehistoric scheduled monuments in the Radnorshire area that '\n",
      " 'include Roman sites, all related to the military occupation of Wales.\"',\n",
      " '\"There are 139 Scheduled monuments in Radnorshire from historic times that '\n",
      " 'include Roman sites related to the military occupation of Wales.\"',\n",
      " '\"There are 139 prehistoric scheduled monuments in the Radnorshire area that '\n",
      " 'include Roman sites all related to the military occupation of Wales.\"',\n",
      " '\"There are 139 prehistoric monuments in the Radnorshire area that include '\n",
      " 'Roman sites, all related to the military occupation of Wales.\"']\n",
      "'\"scheduled monuments\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 1.0, 0.5, 1.0]\n",
      "[8.208499855207459e-05, 1.3747081014995343e-12, 0.6585051938499097, 0.9607071389606728, 0.9400346837028796, 0.9999999999236716]\n",
      "[4.104249927603729e-05, 6.873540507497671e-13, 0.32925259692495484, 0.9607071389606728, 0.4700173418514398, 0.9999999999236716]\n",
      "('What is the name of a classic short hairstyle or hairdo that is cut above '\n",
      " 'the shoulders in a blunt cut with typically no layers?')\n",
      "['Bob cut',\n",
      " '\"This hairstyle is called a bob cut.\"',\n",
      " '\"The classic short hairstyle cut above the shoulders in a blunt cut is the '\n",
      " 'bob.\"',\n",
      " '\"The Caesar cut is the name of a classic short hairstyle or hairdo that is '\n",
      " 'cut above the shoulders in a blunt cut with typically no layers\"',\n",
      " '\"A Bob cut is the name of a classic short hairstyle or hairdo that is cut '\n",
      " 'above the shoulders in a blunt cut with typically no layers.\"',\n",
      " '\"The Caesar cut is the name of a classic short hairstyle or hairdo that is '\n",
      " 'cut above the shoulders in a blunt cut with typically no layers.\"']\n",
      "'\"The Caesar cut\"'\n",
      "\n",
      "[0.9444444444444444, 0.9444444444444444, 0.8333333333333334, 0.9444444444444444, 0.4444444444444444, 0.6666666666666666]\n",
      "[0.9999999999379111, 0.9999999999379111, 0.5505341063496607, 0.7525418262013699, 0.3369157282498007, 0.8618926733772352]\n",
      "[0.9444444443858049, 0.9444444443858049, 0.45877842195805063, 0.7107339469679604, 0.14974032366657808, 0.5745951155848235]\n",
      "'What is Sieve (email filtering language) and what generates Sieve scripts?'\n",
      "['Sieve is a programming language that can be used for email filtering. The '\n",
      " 'Sieve scripts may be generated by a GUI-based rules editor or they may be '\n",
      " 'entered directly using a text editor.',\n",
      " '\"Sieve is a programming language that can be used for email filtering. The '\n",
      " 'Sieve scripts may be generated by a GUI-based rules editor or they may be '\n",
      " 'entered directly using a text editor.\"',\n",
      " '\"Sieve is a programming language that can be used for email filtering, and a '\n",
      " 'GUI-based rules editor can generate Sieve scripts.\"',\n",
      " '\"Sieve is a programming language that can be used for email filtering. Seive '\n",
      " 'scripts can be generated by a GUI-based rules editor or may be entered '\n",
      " 'directly using a text editor.\"',\n",
      " '\"Sieve is a programming language and a GUI-based rules editor generates '\n",
      " 'Sieve scripts.\"',\n",
      " '\"Sieve is a programming language, and Sieve scripts may be generated by a '\n",
      " 'GUI-based rules editor or they may be entered directly using a text editor.\"']\n",
      "('\"Sieve is a programming language that can be used for email filtering, and '\n",
      " 'is generated by a GUI-based rules editor\"')\n",
      "\n",
      "[0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
      "[0.9999999998352859, 0.9999999998352859, 0.398066873807724, 0.6909993405276814]\n",
      "[0.6666666665568572, 0.6666666665568572, 0.265377915871816, 0.4606662270184543]\n",
      "('The biblical canon that includes the Chronicles as the conclusion to the '\n",
      " 'third section of Ketuvim overlaps with which two other canons?')\n",
      "['The Hebrew Bible overlaps with the Greek Septuagint and the Christian Old '\n",
      " 'Testament.',\n",
      " '\"The Hebrew Bible overlaps with the Greek Septuagint and the Christian Old '\n",
      " 'Testament.\"',\n",
      " '\"The biblical canon that includes the Chronicles as the conclusion to the '\n",
      " 'third section of Ketuvim overlaps with the Greek Septuagint and the '\n",
      " 'Christian Old Testament.\"',\n",
      " '\"The biblical canon overlaps the Greek Septuagint and the Christian Old '\n",
      " 'Testament.\"']\n",
      "'\"The Septuagint and the Paralipoménōn\"'\n",
      "\n",
      "[1.0, 1.0, 1.0, 0.3333333333333333]\n",
      "[0.697224290938336, 0.7140573909858762, 0.25214324242770014, 6.389431040945238e-05]\n",
      "[0.697224290938336, 0.7140573909858762, 0.25214324242770014, 2.129810346981746e-05]\n",
      "(\"In the narrative of humanity's past, how is it understood, as exemplified in \"\n",
      " 'modern humans spreading rapidly from Africa to Europe 60,000 years ago?')\n",
      "['Anthropology.',\n",
      " '\"The narrative of humanity\\'s past is understood through archaeology, '\n",
      " 'anthropology, genetics, and linguistics, and from primary and secondary '\n",
      " 'sources.\"',\n",
      " '\"The narrative of humanity\\'s past is understood through archaeology, '\n",
      " 'anthropology, genetics, and linguistics, and since the advent of writing, '\n",
      " 'from primary and secondary sources.\"',\n",
      " '\"In the narrative of humanity\\'s past, it is understood through archaeology, '\n",
      " 'anthropology, genetics, and linguistics,, as exemplified in modern humans '\n",
      " 'spreading rapidly from Africa to Europe 60,000 years ago.\"',\n",
      " '\"Human history is understood through archaeology.\"']\n",
      "'\"through archaeology, anthropology, genetics, and linguistics\"'\n",
      "\n",
      "[1.0, 0.4, 1.0, 0.6, 1.0, 1.0]\n",
      "[0.8278527840033559, 0.467944395174271, 0.9999999999351453, 0.5827355624670193, 0.9234732617360961, 3.107425138040234e-05]\n",
      "[0.8278527840033559, 0.1871777580697084, 0.9999999999351453, 0.3496413374802116, 0.9234732617360961, 3.107425138040234e-05]\n",
      "'What is Łódź Voivodeship and when was it created?'\n",
      "['Łódź Voivodeship is a province - voivodeship in central Poland. It was '\n",
      " 'created on 1 January 1999 out of the former Łódź Voivodeship (1975–1999) and '\n",
      " 'the Sieradz.',\n",
      " '\"Łódź Voivodeship is a province in Poland created out of the former Łódź '\n",
      " 'Voivodeship (1975–1999) and the Sieradz, Piotrków Trybunalski and '\n",
      " 'Skierniewice Voivodeships and part of Płock Voivodeship.\"',\n",
      " '\"Łódź Voivodeship is a province - voivodeship in central Poland. It was '\n",
      " 'created on 1 January 1999.\"',\n",
      " '\"Lodz Voivodeship is a province in central Poland created in 1999.\"',\n",
      " '\"Łódź Voivodeship is a province in central Poland created on 1 January '\n",
      " '1999.\"',\n",
      " '\"Łodz Voivodeship is a Polish province that was founded on January 1, 1999.\"']\n",
      "'\"province - voivodeship; 1 January 1999\"'\n",
      "\n",
      "[0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0]\n",
      "[1.7202151607477576e-15, 0.8363600587098489, 0.8557423955303941, 0.7633713437391342, 0.6341088815049161, 0.9510699415104968]\n",
      "[5.734050535825859e-16, 0.8363600587098489, 0.285247465176798, 0.7633713437391342, 0.4227392543366107, 0.9510699415104968]\n",
      "('A solid oxide electrolyzer cell (SOEC) is a solid oxide fuel cell that runs '\n",
      " 'in regenerative mode to achieve the what, which is an important technology '\n",
      " 'for the production of hydrogen to be used as an energy carrier?')\n",
      "['Electrolysis',\n",
      " '\"A solid oxide electrolyzer cell (SOEC) is a solid oxide fuel cell that runs '\n",
      " 'in regenerative mode to achieve the electrolysis of water (and/or carbon '\n",
      " 'dioxide).\"',\n",
      " '\"A solid oxide electrolyzer cell (SOEC) is a solid oxide fuel cell that runs '\n",
      " 'in regenerative mode to achieve electrolysis.\"',\n",
      " '\"A solid oxide fuel cell that runs in regenerative mode to achieve the '\n",
      " 'electrolysis of water.\"',\n",
      " '\"A solid oxide electrolyzer cell (SOEC) is a solid oxide fuel cell that runs '\n",
      " 'in regenerative mode to achieve the electrolysis, which is an important '\n",
      " 'technology for the production of hydrogen.\"',\n",
      " '\"Solid oxide electrolyzer cell (SOEC) is a solid oxide fuel cell that runs '\n",
      " 'in regenerative mode to achieve the electrolysis of water.\"']\n",
      "'\"Electrolysis of water.\"'\n",
      "\n",
      "[1.0, 1.0, 0.5, 1.0, 0.5, 1.0]\n",
      "[1.0922110994059825e-07, 0.9428731437382619, 0.9999999999391136, 3.2085837485131566e-09, 0.8891397049684446, 0.6933955661843876]\n",
      "[1.0922110994059825e-07, 0.9428731437382619, 0.4999999999695568, 3.2085837485131566e-09, 0.4445698524842223, 0.6933955661843876]\n",
      "('Which side probably came out worse during the earliest recorded battle, '\n",
      " 'involving 5 to 6,000 chariots total?')\n",
      "['Egypt, Ramesses II',\n",
      " '\"Ramesses II probably came out worse during the earliest recorded battle, '\n",
      " 'involving 5,000 to 6,000 chariots total.\"',\n",
      " '\"Ramesses II\\'s side probably came out worse during the earliest recorded '\n",
      " 'battle, involving 5,000 to 6,000 chariots total.\"',\n",
      " '\"It is believed that the battle ended worse for Ramesses II than Muwatalli '\n",
      " 'II.\"',\n",
      " '\"Ramesses II\\'s side probably came out worse during the earliest recorded '\n",
      " 'battle that involved 5 to 6,000 chariots total.\"',\n",
      " '\"Ramesses II probably came out worse during the earliest recorded battle '\n",
      " 'that involved a total of 5 to 6,000 chariots.\"']\n",
      "'\"Ramesses II\"'\n",
      "\n",
      "[0.8, 0.8, 1.0, 1.0, 0.8, 1.0]\n",
      "[0.24447946427940517, 0.8395876230551684, 0.7809325627907618, 0.7667884229554821, 0.913100716196083, 0.9009325445418138]\n",
      "[0.19558357142352414, 0.6716700984441348, 0.7809325627907618, 0.7667884229554821, 0.7304805729568664, 0.9009325445418138]\n",
      "'What is the Zenith STOL CH 801 and what is it made from?'\n",
      "['The Zenith STOL CH 801 is a four-seat sport STOL aircraft developed by Chris '\n",
      " 'Heintz and available in kit form from the Zenith Aircraft Company. It is '\n",
      " 'made from sheet aluminium and employs a deep wing chord, full-length leading '\n",
      " 'edge slots and trailing edge flaperons to develop high lift at low speed, '\n",
      " 'while maintaining a short wing-span for maximum strength and ground '\n",
      " 'maneuverability.',\n",
      " '\"The Zenith STOL CH 801 is a four-seat sport STOL aircraft that was '\n",
      " 'developed by Chris Heintz, and it is made from sheet aluminium.\"',\n",
      " '\"The Zenith STOL CH 801 is a four-seat sport STOL aircraft which is made '\n",
      " 'from sheet aluminum.\"',\n",
      " '\"The Zenith STOL CH 801 is a four-seat sport STOL aircraft made from sheet '\n",
      " 'aluminum.\"',\n",
      " '\"The Zenith STOL CH 801 is a four-seat sport STOL aircraft developed by '\n",
      " 'Chris Heintz, and it is made from sheet aluminium.\"',\n",
      " '\"The Zenith STOL CH 801 is a four-seat sport STOL aircraft and it is made '\n",
      " 'from sheet aluminum.\"']\n",
      "'\"Aircraft made from sheet aluminum\"'\n",
      "\n",
      "[1.0, 0.75, 0.5, 1.0, 1.0]\n",
      "[1.7017510922614895e-05, 0.6704226836958771, 0.8524419935996841, 0.9554427921525315, 0.22416933497894614]\n",
      "[1.7017510922614895e-05, 0.5028170127719078, 0.42622099679984204, 0.9554427921525315, 0.22416933497894614]\n",
      "('What son of Michael Corleone had a small role in the first film of the '\n",
      " 'trilogy directed by Francis Ford Coppola?')\n",
      "['Anthony Vito \" Tony \" Corleone.',\n",
      " '\"Anthony Vito Corleone had a small role in the first Godfather film.\"',\n",
      " '\"Anthony Corleone had a small role in the first film of the trilogy directed '\n",
      " 'by Francis Ford Coppola.\"',\n",
      " '\"Anthony Vito \" Tony \" Corleone had a small role in the first film of the '\n",
      " 'trilogy directed by Francis Ford Coppola.\"',\n",
      " '\"Anthony Vito \" Tony \" Corleone is the character this question is referring '\n",
      " 'to.\"']\n",
      "'\"Anthony Vito \" Tony \" Corleone\"'\n",
      "\n",
      "[1.0, 0.5263157894736842, 1.0]\n",
      "[0.7421944324408976, 0.6608372989506845, 0.7614685243146528]\n",
      "[0.7421944324408976, 0.3478091047108866, 0.7614685243146528]\n",
      "'Why is the Canadian Charter of Right and Freedoms so unique?'\n",
      "['It projects other matters which are not covered in other North American '\n",
      " 'charters.',\n",
      " '\"The Charter of Human Rights and Freedoms is unique among Canadian (and '\n",
      " 'North American) human rights documents in that it covers not only the '\n",
      " 'fundamental (civil and political) human rights but also a number of '\n",
      " 'important social and economic rights.\"',\n",
      " '\"The Canadian Charter of Rights and Freedoms is unique because it includes a '\n",
      " 'number of important social and economic rights.\"',\n",
      " '\"The Canadian Charter of Human Rights and Freedoms is unique in that it '\n",
      " 'covers not only the fundamental (civil and political) human rights but also '\n",
      " 'a number of important social and economic rights.\"']\n",
      "('\"it covers not only the fundamental (civil and political) human rights but '\n",
      " 'also a number of important social and economic rights.\"')\n",
      "\n",
      "[0.5, 0.5, 1.0, 1.0, 0.5]\n",
      "[4.231178541052573e-09, 0.2663148665400221, 0.591978312090077, 0.31402281189201875, 8.656385437908143e-13]\n",
      "[2.1155892705262866e-09, 0.13315743327001106, 0.591978312090077, 0.31402281189201875, 4.3281927189540714e-13]\n",
      "('What sandstone rock formation in Australia also known as Ayers Rock is '\n",
      " 'sacred to the Pitjantjatjara, the Aboriginal people of the area?')\n",
      "['Uluruis a large sandstone rock formation in the southern part of the '\n",
      " 'Northern Territory in Australia.',\n",
      " '\"Uluru is a rock formation sacred to the Pitjantjatjara.\"',\n",
      " '\"Uluru in Australia also known as Ayers Rock is sacred to the '\n",
      " 'Pitjantjatjara, the Aboriginal people of the area.\"',\n",
      " '\"Uluru is also known at Ayers Rock and is sacred to the Pitjantjatjara.\"',\n",
      " '\"This rock is Uluru.\"',\n",
      " '\"Uluru is sacred to the Pitjantjatjara, the Aboriginal people of the area, '\n",
      " 'known as the Aṉangu.\"']\n",
      "'\"Ayers Rock\"'\n",
      "\n",
      "[0.5, 0.75, 0.75, 0.5, 1.0]\n",
      "[0.8914703663507608, 0.6687403048494411, 0.7344112539427865, 0.9858120082525833, 0.6506288046815797]\n",
      "[0.4457351831753804, 0.5015552286370808, 0.5508084404570899, 0.49290600412629165, 0.6506288046815797]\n",
      "('The name of the oil platform that Shell operates in the same gulf as Devils '\n",
      " 'Tower translates to what in Spanish?')\n",
      "['Lost',\n",
      " '\"The name of the oil platform that Shell operates in the same gulf as Devils '\n",
      " 'Tower translates to Perdido in Spanish.\"',\n",
      " '\"Perdido platform translates to \"lost\" in Spanish.\"',\n",
      " '\"Perdido,  The name of the oil platform that Shell operates in the same gulf '\n",
      " 'as Devils Tower, translates into \"lost\" in Spanish.\"',\n",
      " '\"The name of the oil platform that Shell operates in the same gulf as Devils '\n",
      " 'Tower translates to \"lost\" in Spanish.\"',\n",
      " '\"Perdido (spanish for lost) is the name of the oil platform that Shell '\n",
      " 'operates in the same gulf as Devils Tower.\"']\n",
      "'\"Perdido (spanish for lost)\"'\n",
      "\n",
      "[0.8, 1.0, 1.0, 0.6, 1.0, 1.0]\n",
      "[8.025716722742473e-09, 0.7924634119291644, 0.6887246539249051, 5.555238066968751e-05, 0.30538187670136796, 0.8696398661806125]\n",
      "[6.4205733781939786e-09, 0.7924634119291644, 0.6887246539249051, 3.33314284018125e-05, 0.30538187670136796, 0.8696398661806125]\n",
      "('What group goes to a rainbow viewing island near the same body of water as '\n",
      " 'Navy Island to answer questions about Niagara falls?')\n",
      "['Schoellkopf Geological museum representatives',\n",
      " '\"Representatives of the nearby Schoellkopf Geological Museum go to the '\n",
      " 'rainbow viewing island near the same body of water as Navy Island to answer '\n",
      " 'questions about Niagara Falls.\"',\n",
      " '\"Representatives of the Schoellkopf Geological Museum often go to Luna '\n",
      " 'Island.\"',\n",
      " '\"This group is the Schoellkopf Geological Museum.\"',\n",
      " '\"Representatives of the nearby Schoellkopf Geological Museum often come to '\n",
      " 'Luna Island in the Niagara River which is also the location of Navy Island.\"',\n",
      " '\"Representatives of the nearby Schoellkopf Geological Museum often go to a '\n",
      " 'rainbow viewing island near the same body of water as Navy Island to answer '\n",
      " 'questions about Niagara falls.\"']\n",
      "'\"Representatives of the Schoellkopf Geological Museum\"'\n",
      "\n",
      "[1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0]\n",
      "[8.070409085385518e-07, 0.7858173638298225, 0.32951032909760464, 1.1559871146073225e-12, 0.8701761845743532, 0.9000001337811073]\n",
      "[8.070409085385518e-07, 0.5238782425532149, 0.32951032909760464, 3.853290382024408e-13, 0.8701761845743532, 0.9000001337811073]\n",
      "('In what kind of agreement involves cooperation between at least two '\n",
      " 'countries to reduce trade barriers to form free-trade areas outside the '\n",
      " 'realm of the multilateral trading system?')\n",
      "['Free trade agreements.',\n",
      " '\"In a free trade involvement, there is cooperation between at least two '\n",
      " 'countries to reduce trade barriers to form free-trade areas outside the '\n",
      " 'realm of the multilateral trading system.\"',\n",
      " '\"Free trade agreements  involve cooperation between at least two countries '\n",
      " 'to reduce trade barriers, import quotas and tariffs, and to increase trade '\n",
      " 'of goods and services with each other.\"',\n",
      " '\"This is referred to as a Free-Trade Agreement.\"',\n",
      " '\"A free trade agreement involves cooperation between at least two countries '\n",
      " 'to reduce trade barriers to form free-trade areas outside the realm of the '\n",
      " 'multilateral trading system.\"',\n",
      " '\"Free trade agreements involves cooperation between at least two countries '\n",
      " 'to reduce trade barriers to form free-trade areas outside the realm of the '\n",
      " 'multilateral trading system.\"']\n",
      "'\"Free trade agreement\"'\n",
      "\n",
      "[0.3333333333333333, 1.0, 1.0]\n",
      "[5.127889122861252e-12, 0.8408964150152105, 0.8408964150152105]\n",
      "[1.7092963742870841e-12, 0.8408964150152105, 0.8408964150152105]\n",
      "'Semimembranosus and skeletal are both types of what?'\n",
      "['Muscles',\n",
      " '\"Semimembranosus and skeletal are both types of muscles.\"',\n",
      " '\"Semimembranosus and skeletal are both types of muscle.\"']\n",
      "'\"Types of muscles\"'\n",
      "\n",
      "[0.75, 0.75, 0.75, 0.75, 0.75, 0.75]\n",
      "[0.10539922448061924, 0.7825422899176371, 0.9306048589605762, 0.07201026821836519, 0.518434107397391, 0.6471826824290907]\n",
      "[0.07904941836046443, 0.5869067174382279, 0.6979536442204322, 0.05400770116377389, 0.3888255805480433, 0.48538701182181804]\n",
      "('In what two countries can Syntheosciurus brochus and Microsciurus alfari '\n",
      " 'both be found?')\n",
      "['Costa Rica and Panama',\n",
      " '\"Both Syntheosciurus brochus and Microsciurus alfari can be found in Costa '\n",
      " 'Rica and Panama.\"',\n",
      " '\"Syntheosciurus brochus and Microsciurus alfari can both be found in Costa '\n",
      " 'Rica and Panama.\"',\n",
      " '\"Bangs\\'s mountain squirrel ( Syntheosciurus brochus) is a species of tree '\n",
      " 'squirrel, that only lives in Costa Rica and Panama. The Central American '\n",
      " \"dwarf squirrel, also known as Alfaro's pygmy squirrel, ( Microsciurus \"\n",
      " 'alfari) found in Colombia, Costa Rica, Nicaragua, and Panama. The only '\n",
      " 'countries that both are found in, are Costa Rica and Panama. The answer is '\n",
      " 'Costa Rica and Panama.\"',\n",
      " '\"Costa Rica and Panama are the two countries where the Syntheosciurus '\n",
      " 'brochus and Microsciurus alfari can both be found.\"',\n",
      " '\"Syntheosciurus brochus and Microsciurus alfari are both found in Costa Rica '\n",
      " 'and Panama.\"']\n",
      "'\"Costa Rice and Panama\"'\n",
      "\n",
      "[0.5, 0.6, 0.5, 0.5, 0.6, 0.6]\n",
      "[0.8801117366880071, 0.5348259311781718, 0.7476743904255464, 0.9764540894833008, 0.6147881527990924, 1.2500763055417205e-05]\n",
      "[0.44005586834400356, 0.32089555870690306, 0.3738371952127732, 0.4882270447416504, 0.3688728916794554, 7.500457833250322e-06]\n",
      "'How old was Zhao Kuangyin when the Tang Dynasty was operating?'\n",
      "['Zhao Kuangyin was not alive when the Tang Dynasty operated.',\n",
      " '\"Zhao Kuangyin wasn\\'t yet born when the Tang Dynasty was operating.\"',\n",
      " '\"Zhao Kuangyin was not alive during the Tang Dynasty.\"',\n",
      " '\"Zhao Kuangyin was not alive when the Tang Dynasty was operating.\"',\n",
      " '\"Zhao Kuangyin was not born during the Tang Dynasty.\"',\n",
      " '\"Zhao Kuangin was 33 years old when his reign of the Tang Dynasty began, in '\n",
      " '960, and 49 years old when it ended, in 976 at his death.\"']\n",
      "'\"The Tang Dynasty ended 20 years before Zhao Kuangyin was born.\"'\n",
      "\n",
      "[1.0, 1.0, 1.0, 1.0, 0.5, 0.5]\n",
      "[7.82603450480608e-08, 0.6262844962330957, 0.9153767854823969, 0.8656030552096342, 0.6370555116371679, 0.7498810286074887]\n",
      "[7.82603450480608e-08, 0.6262844962330957, 0.9153767854823969, 0.8656030552096342, 0.31852775581858395, 0.37494051430374437]\n",
      "('In the organ with the colored muscularly operated diaphragm, what membrane '\n",
      " 'in aquatic birds covers the eye and acts as a contact lens?')\n",
      "['The nictitating membrane.',\n",
      " '\"The nictitating membrane covers the eye and acts as a contact lens in many '\n",
      " 'aquatic birds.\"',\n",
      " '\"The nictitating membrane in aquatic birds covers the eye and acts as a '\n",
      " 'contact lens\"',\n",
      " '\"In the organ with the iris, the nictitating membrane in aquatic birds '\n",
      " 'covers the eye and acts as a contact lens.\"',\n",
      " '\"The nictitating is the membrane in aquatic birds that covers the eye and '\n",
      " 'acts as a contact lens.\"',\n",
      " '\"In the organ with the colored muscularly operated diaphragm, the '\n",
      " 'nictitating membrane in aquatic birds covers the eye and acts as a contact '\n",
      " 'lens.\"']\n",
      "'\"The nictitating membrane\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 1.0, 1.0]\n",
      "[0.003066522873974082, 0.5438653754649864, 0.44109539637738465, 0.6868616145620733, 0.9999999999193516]\n",
      "[0.003066522873974082, 0.2719326877324932, 0.44109539637738465, 0.6868616145620733, 0.9999999999193516]\n",
      "('What system of soft tissue found in most animals is an organ system '\n",
      " 'consisting of skeletal, smooth and cardiac muscles?')\n",
      "['The muscular system',\n",
      " '\"Muscle is the system of soft tissue found in most animals is an organ '\n",
      " 'system consisting of skeletal, smooth and cardiac muscles\"',\n",
      " '\"The muscular system consists of skeletal, smooth and cardiac muscles.\"',\n",
      " '\"The muscular system is an organ system consisting of skeletal, smooth and '\n",
      " 'cardiac muscles and is found in most animals.\"',\n",
      " '\"The muscular system is an organ system consisting of skeletal, smooth and '\n",
      " 'cardiac muscles.\"']\n",
      "'\"Muscular system.\"'\n",
      "\n",
      "[0.75, 0.75, 1.0, 1.0, 1.0, 0.5]\n",
      "[1.9453508341809884e-08, 0.9725766308263739, 0.9865741363936358, 0.7848518349024594, 0.7588339224453144, 0.8831560648823531]\n",
      "[1.4590131256357412e-08, 0.7294324731197804, 0.9865741363936358, 0.7848518349024594, 0.7588339224453144, 0.44157803244117655]\n",
      "('The protein encoded by the KCNA4 gene, and the protein encoded by the KCND2 '\n",
      " 'gene both result in what kinds of subfamilies?')\n",
      "['Potassium voltage-gated channels.',\n",
      " '\"The protein encoded by the KCNA4 gene and the protein encoded by the KCND2 '\n",
      " 'gene both result in potassium voltage-gated channels.\"',\n",
      " '\"The protein encoded by the KCNA4 gene and the protein encoded by the KCND2 '\n",
      " 'gene both result in potassium voltage-gated channel subfamilies.\"',\n",
      " '\"The protein encoded by the KCNA4 gene and the protein encoded by the KCND2 '\n",
      " 'gene both belong to the potassium voltage-gated channel subfamilies.\"',\n",
      " '\"The protein encoded by the KCNA4 gene, and the protein encoded by the KCND2 '\n",
      " 'gene both result in Potassium voltage-gated channel subfamilies.\"',\n",
      " '\"The protein encoded by the KCNA4 gene and the protein encoded by the KCND2 '\n",
      " 'gene both result in channel subfamilies.\"']\n",
      "'\"Potassium voltage-gated channel subfamily\"'\n",
      "\n",
      "[1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666]\n",
      "[1.1263163195091694e-06, 0.7498810286074887, 0.4774900726089245, 0.9999999998635914, 0.3089575774178525, 0.7595809015196485]\n",
      "[1.1263163195091694e-06, 0.7498810286074887, 0.31832671507261634, 0.9999999998635914, 0.3089575774178525, 0.5063872676797656]\n",
      "('Gastric mucosa is part of what diffuse system of small concentrations of '\n",
      " 'lymphoid tissue in submucosal membrane sites of the body?')\n",
      "['Mucosa-associated lymphoid tissue',\n",
      " '\"Gastric mucosa is part of the mucosa-associated lymphoid tissue which is a '\n",
      " 'small concentrations of lymphoid tissue in submucosal membrane sites of the '\n",
      " 'body.\"',\n",
      " '\"Gastric mucosa is not part of any diffuse system of small concentrations of '\n",
      " 'lymphoid tissue in submucosal membrane sites of the body since it is a '\n",
      " 'mucous membrane and not a submucosal membrane.\"',\n",
      " '\"Gastric mucosa is part of the mucosa-associated lymphoid tissue.\"',\n",
      " '\"This refers to the mucosa-associated lymphoid tissue.\"',\n",
      " '\"Gastric mucosa is part of a diffuse system of small concentrations of '\n",
      " 'lymphoid tissue in submucosal membrane sites of the body.\"']\n",
      "'\"The mucosa-associated lymphoid tissue\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5]\n",
      "[2.0237345066702103e-08, 0.795270728445629, 0.7118304475833442, 0.795270728445629]\n",
      "[1.0118672533351051e-08, 0.3976353642228145, 0.3559152237916721, 0.3976353642228145]\n",
      "('The Phoebastria albatrus is a what kind of bird that the small mollymawk was '\n",
      " 'once considered conspecific with?')\n",
      "['An albatross.',\n",
      " '\"He Phoebastria albatrus is a large rare seabird that the small mollymawk '\n",
      " 'was once considered conspecific with.\"',\n",
      " '\"The Phoebastria albatrus is a albatross\"',\n",
      " '\"The Phoebastria albatrus is an albatross bird that the small mollymawk was '\n",
      " 'once considered conspecific with.\"',\n",
      " '\"The Phoebastria albatrus is an albatross.\"']\n",
      "'\"Short-tailed albatross\"'\n",
      "\n",
      "[1.0, 0.5, 0.5, 0.5, 1.0, 1.0]\n",
      "[5.939694940227884e-05, 0.6434588839466586, 0.8164965808163489, 0.4549941402534101, 0.7311104454657565, 0.36720562695015824]\n",
      "[5.939694940227884e-05, 0.3217294419733293, 0.40824829040817445, 0.22749707012670506, 0.7311104454657565, 0.36720562695015824]\n",
      "'How long can a Lampropeltis alterna grow?'\n",
      "['Up to 4 feet.',\n",
      " '\"A Lampropeltis alterna can grow 4ft long.\"',\n",
      " '\"A Lampropeltis alterna can grow up to 4 ft.\"',\n",
      " '\"The Lampropeltis alterna can grow to 4ft\"',\n",
      " '\"It can grow up to 4 feet.\"',\n",
      " '\"A Lampropeltis alterna can grow upp to four feet in length.\"']\n",
      "'\"4 feet\"'\n",
      "\n",
      "[0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]\n",
      "[0.7259795290164472, 0.8606031404446072, 0.31482826890405136, 0.7200242075539716, 0.6319145616813112, 0.7238348098418133]\n",
      "[0.48398635267763146, 0.8606031404446072, 0.20988551260270089, 0.7200242075539716, 0.6319145616813112, 0.7238348098418133]\n",
      "('Where does the name of the North American genus of turtles in the family '\n",
      " 'Trionychidae come from?')\n",
      "['From the Greek word apalos, meaning soft or tender',\n",
      " '\"The name of the North American genus of turtles in the family Trionychidae '\n",
      " 'comes from the Greek word apalos.\"',\n",
      " '\"The North American genus Apalone is from the Greek word apalos, meaning '\n",
      " 'soft or tender, and spinifera is Latin; spina- referring to thorn or spine '\n",
      " 'and -ifer meaning bearing.\"',\n",
      " '\"The name of the North American genus of turtles in the family Trionychidae '\n",
      " 'come from the Greek word apalos and spinifera from Latin.\"',\n",
      " '\"Apalone comes from the Greek word apalos\"',\n",
      " '\"The name of the North American genus of turtles in the Trionychidae family '\n",
      " 'is derived from the Greek word apalos.\"']\n",
      "'\"Greek word apalos\"'\n",
      "\n",
      "[0.5, 1.0, 1.0]\n",
      "[1.5744053386817196e-06, 0.8843946453261532, 0.8979007599007977]\n",
      "[7.872026693408598e-07, 0.8843946453261532, 0.8979007599007977]\n",
      "('The alternated  cubic honeycomb is one  of 28 space-filling uniform '\n",
      " 'tessellations in Euclidean space of how many dimensions, the answer being '\n",
      " 'one more than are involved in planar tiling?')\n",
      "['3',\n",
      " '\"The alternated cubic honeycomb is one of 28 space-filling uniform '\n",
      " 'tessellations in Euclidean space of three dimensions.\"',\n",
      " '\"The alternated cubic honeycomb is one of 28 space-filling uniform '\n",
      " 'tessellations in Euclidean 3-space.\"',\n",
      " '\"The number is 2.\"',\n",
      " '\"The alternated cubic honeycomb is one of 28 space-filling uniform '\n",
      " 'tessellations in Euclidean 3-space\"',\n",
      " '\"The alternated cubic honeycomb is one of 28 space-filling uniform '\n",
      " 'tessellations in Euclidean space of 3 dimensions.\"']\n",
      "'\"3 dimensions\"'\n",
      "\n",
      "[1.0, 0.3333333333333333, 0.3333333333333333]\n",
      "[0.1794813649937813, 0.9391044156632808, 0.5378454935425518]\n",
      "[0.1794813649937813, 0.3130348052210936, 0.17928183118085061]\n",
      "'Dathomirians and Humans are both species in what?'\n",
      "['Star Wars',\n",
      " '\"It says that Humans are a species in the fictional Star Wars universe and '\n",
      " 'that Dathomirians are a humanoid sentient species from the Star Wars '\n",
      " 'franchise. Therefore the answer is the Star Wars universe.\"',\n",
      " '\"Dathomirians and Humans are both species in the fictional Star Wars '\n",
      " 'universe.\"',\n",
      " '\"Dathomirians and Humans are both species in Star Wars.\"']\n",
      "'\"Humanoid sentient species\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 1.0]\n",
      "[0.9193227151507766, 0.712574364869788, 0.23746239163345456, 0.7845783168140213]\n",
      "[0.9193227151507766, 0.356287182434894, 0.23746239163345456, 0.7845783168140213]\n",
      "('What family was a branch of the royal family of the Zhou Dynasty and had '\n",
      " 'their surname coming from the dynasty where surviving members changed their '\n",
      " 'surname to Yin?')\n",
      "['Shang.',\n",
      " '\"The Shan family was a branch of the royal family of the Zhou Dynasty.\"',\n",
      " '\"The Shang family was a branch of the royal family of the Zhou Dynasty and '\n",
      " 'had their surname coming from the dynasty where surviving members changed '\n",
      " 'their surname to Yin.\"',\n",
      " '\"There is no family that matches the conditions in the question. The Shan '\n",
      " 'were a branch of the Zhou Dynasty, while the family whose surviving members '\n",
      " 'changed their surname to Yin are the Shang, not the Shan.\"',\n",
      " '\"The Shan family was a branch of the royal family of the Zhou Dynasty whose '\n",
      " 'surname came from the dynasty where surviving members changed their surname '\n",
      " 'to Yin.\"']\n",
      "'\"Shan family\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[4.5855212421841376e-07, 0.9999999999254122, 0.6395028446574536, 0.5423604480283163, 0.8052253760679794]\n",
      "[2.2927606210920688e-07, 0.4999999999627061, 0.3197514223287268, 0.27118022401415814, 0.4026126880339897]\n",
      "('A documentary film may also be written in what style to heighten narrative '\n",
      " 'interest before it is broadcast via over-the-air?')\n",
      "['A procedural style.',\n",
      " '\"A documentary film may also be written in a procedural style to heighten '\n",
      " 'narrative interest.\"',\n",
      " '\"A documentary film may also be written in a procedural style to heighten '\n",
      " 'narrative interest before it is broadcast via over-the-air.\"',\n",
      " '\"The film may also be written in a procedural style.\"',\n",
      " '\"A documentary film may be written in a procedural style to heighten '\n",
      " 'narrative interest.\"']\n",
      "'\"Procedural drama\"'\n",
      "\n",
      "[0.5, 1.0, 1.0, 0.5, 1.0]\n",
      "[5.782700798817902e-07, 0.7307717332579815, 0.20149416156302874, 0.495024256625707, 0.7476743905086212]\n",
      "[2.891350399408951e-07, 0.7307717332579815, 0.20149416156302874, 0.2475121283128535, 0.7476743905086212]\n",
      "('What sort of revival in the nation with the bazaari and Islamic tendencies '\n",
      " 'included the Tahirids, Saffarids and Sajids?')\n",
      "['The Iranian Intermezzo.',\n",
      " '\"The Iranian revival in the nation with the bazaari and Islamic tendencies '\n",
      " 'included the Tahirids, Saffarids and Sajids.\"',\n",
      " '\"Within Iran, the nation with bazaari and Islamic tendencies, the revival '\n",
      " 'that involved the Tahirids, Saffarids and Sajids revived Iranian national '\n",
      " 'spirit and culture in an Islamic form.\"',\n",
      " '\"A national spirit and Islamic culture revival took place in the nation with '\n",
      " 'the bazaari and Islamic tendencies.\"',\n",
      " '\"The Iranian revival included the Tahirids, Saffarids and Sajids.\"']\n",
      "'\"Iranian revival\"'\n",
      "\n",
      "[0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]\n",
      "[0.8107492450250514, 4.6141917687024804e-05, 0.8938466181415624, 0.6815757063798585, 0.16575908104550177, 0.7726644475896123]\n",
      "[0.5404994966833676, 4.6141917687024804e-05, 0.8938466181415624, 0.6815757063798585, 0.1105060540303345, 0.7726644475896123]\n",
      "('Using the United Nations geographic definitions, which continents are '\n",
      " 'crossed by the 78th parallel north, but not by the 13th parallel north?')\n",
      "['Europe is crossed by the 78th parallel north, but not by the 13th parallel '\n",
      " 'north.',\n",
      " '\"the 78th parallel north crosses North America and Europe, which the 13th '\n",
      " 'parallel north does not.\"',\n",
      " '\"Using the United Nations geographic definitions, Europe and North America '\n",
      " 'are crossed by the 78th parallel north, but not by the 13th parallel north.\"',\n",
      " '\"Using the United Nations geographic definitions, Europe, the Artic Ocean, '\n",
      " 'and North America are crossed by the 78th parallel north, and not by the '\n",
      " '13th parallel north.\"',\n",
      " '\"Europe does not cross the 13th parallel north.\"',\n",
      " '\"Using the United Nations geographic definitions, North America and Europe '\n",
      " 'are crossed by the 78th parallel north, but not by the 13th parallel north?\"']\n",
      "'\"Europe, North America\"'\n",
      "\n",
      "[0.5, 0.5, 1.0, 0.5]\n",
      "[3.902560660212479e-09, 0.8942255541612756, 0.8985396083066598, 0.8307018473418094]\n",
      "[1.9512803301062397e-09, 0.4471127770806378, 0.8985396083066598, 0.4153509236709047]\n",
      "('There is no scholarly consensus about where what language which had four '\n",
      " 'basic vowels, *i, *e, *a, *o, each of which had a long counterpart, was '\n",
      " 'spoken?')\n",
      "['Proto-Algonquian',\n",
      " '\"There is no scholarly consensus about where Proto-Algonquian, which had '\n",
      " 'four basic vowels, *i, *e, *a, *o, each of which had a long counterpart, was '\n",
      " 'spoken.\"',\n",
      " '\"There is no scholarly consensus about where Proto-Algonquian language which '\n",
      " 'had four basic vowels, *i, *e, *a, *o, each of which had a long counterpart, '\n",
      " 'was spoken.\"',\n",
      " '\"There is no scholarly consensus about where Proto-Algonquian was spoken.\"',\n",
      " '\"There is no scholarly consensus about where Proto-Algonquian,which had four '\n",
      " 'basic vowels, *i, *e, *a, *o, each of which had a long counterpart, was '\n",
      " 'spoken.\"']\n",
      "'\"Proto-Algonquian language\"'\n",
      "\n",
      "[0.5, 1.0, 1.0, 0.75, 1.0, 1.0]\n",
      "[2.0237345066702103e-08, 0.831818006131277, 0.15456639687483092, 7.259795289430573e-05, 0.831818006131277, 0.9999999998802581]\n",
      "[1.0118672533351051e-08, 0.831818006131277, 0.15456639687483092, 5.44484646707293e-05, 0.831818006131277, 0.9999999998802581]\n",
      "('An odometer or odograph is an example of what which have been augmented by '\n",
      " 'software-powered display panels conveying information on display panels?')\n",
      "['Vehicle instrument',\n",
      " '\"An odometer or odograph is an example of vehicle instruments that have been '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'augmented by software-powered display panels conveying information on '\n",
      " 'display panels\"',\n",
      " '\"Electronic instrument clusters augment vehicle instruments via '\n",
      " 'software-powered display panels, and an odometer is an example of such a '\n",
      " 'vehicle instrument.\"',\n",
      " '\"It\\'s an example of an instrument.\"',\n",
      " '\"An odometer or odograph is an example of vehicle instruments which have '\n",
      " 'been augmented by software-powered display panels conveying information on '\n",
      " 'display panels.\"',\n",
      " '\"An odometer or odograph is an example of vehicle instruments\"']\n",
      "'\"example of vehicle instruments\"'\n",
      "\n",
      "[1.0, 0.9230769230769231, 0.5384615384615384]\n",
      "[0.5623413251690909, 0.8094889502425031, 0.4557357795787848]\n",
      "[0.5623413251690909, 0.7472205694546183, 0.24539618900396104]\n",
      "'Beira barb can be found feeding at what lake depths?'\n",
      "['The redeye barb lives and feeds on the bottom as well as in the middle of '\n",
      " 'the water column and at the surface - so, at all depths.',\n",
      " '\"Beira barb can be found feeding at the bottom as well as in the middle of '\n",
      " 'the water column and at the surface of lakes.\"',\n",
      " '\"It can be found feeding at the Limpopo River and Incomati River.\"',\n",
      " '\"Beira barb can be found feeding throughout the water column, at the surface '\n",
      " 'and the bottom of lakes.\"',\n",
      " '\"Beira barb can be found feeding at the bottom of the lake.\"']\n",
      "('\"on the bottom as well as in the middle of the water column and at the '\n",
      " 'surface\"')\n",
      "\n",
      "[0.8947368421052632, 0.8947368421052632, 0.631578947368421, 0.8947368421052632, 0.8421052631578947]\n",
      "[0.8466657105163113, 0.9889485799391424, 0.6358410041545819, 0.9640126436939372, 0.8862476419167338]\n",
      "[0.7575430041461733, 0.8848487294192326, 0.4015837920976306, 0.8625376285682597, 0.7463138037193547]\n",
      "'What is Pyrolysis and what is it most commonly used for?'\n",
      "['Pyrolysis is the thermal decomposition of materials at elevated temperatures '\n",
      " 'in an inert atmosphere. It is most commonly used in the treatment of organic '\n",
      " 'materials.',\n",
      " '\"Pyrolysis is the thermal decomposition of materials at elevated '\n",
      " 'temperatures in an inert atmosphere and it is most commonly used in the '\n",
      " 'treatment of organic materials.\"',\n",
      " '\"Pyrolysis is the thermal decomposition of materials, it is most commonly '\n",
      " 'used in the treatment of organic materials.\"',\n",
      " '\"Pyrolysis is the thermal decomposition of materials at elevated '\n",
      " 'temperatures in an inert atmosphere and it is used in the treatment of '\n",
      " 'organic materials.\"',\n",
      " '\"Pyrolysis is the thermal decomposition of materials at elevated '\n",
      " 'temperatures in an inert atmosphere and is used in the treatment of organic '\n",
      " 'materials.\"']\n",
      "('\"Pyrolysis  is the thermal decomposition of materials at elevated '\n",
      " 'temperatures in an inert atmosphere. It is used when treating organic '\n",
      " 'materials.\"')\n",
      "\n",
      "[0.5, 1.0, 1.0, 1.0]\n",
      "[1.886444984907315e-12, 0.5378454935425518, 0.6340466276436032, 1.4377919099523268e-05]\n",
      "[9.432224924536574e-13, 0.5378454935425518, 0.6340466276436032, 1.4377919099523268e-05]\n",
      "'Papilio leucotaenia and Papilio menestheus are both what types of butterfly?'\n",
      "['Swallowtails',\n",
      " '\"Papilio leucotaenia and Papilio menestheus are both swallowtail '\n",
      " 'butterflies.\"',\n",
      " '\"Papilio leucotaenia and Papilio menestheus are both what types of '\n",
      " 'swallowtail butterfly.\"',\n",
      " '\"It says that Papilio leucotaenia, is a  cream-banded swallowtail, and '\n",
      " 'Papilio menestheus, the western emperor swallowtail, is a species of '\n",
      " 'swallowtail butterfly. Therefore the answer is swallowtail.\"']\n",
      "'\"Swallowtail butterfly\"'\n",
      "\n",
      "[0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666]\n",
      "[0.49999999985818483, 0.8164965808163489, 0.44827003178420904, 0.728954518120046, 0.49999999985818483, 0.9457416087349345]\n",
      "[0.3333333332387899, 0.8164965808163489, 0.2988466878561393, 0.728954518120046, 0.49999999985818483, 0.6304944058232896]\n",
      "'In which ocean would you find Cuba?'\n",
      "['You would find it in the Atlantic Ocean.',\n",
      " '\"You would find Cuba in the North Atlantic Ocean\"',\n",
      " '\"It\\'s in the Atlantic Ocean.\"',\n",
      " '\"Cuba is in the North Atlantic Ocean.\"',\n",
      " '\"Cuba is in the western North Atlantic Ocean.\"',\n",
      " '\"You would find Cuba in the Atlantic Ocean.\"']\n",
      "'\"North Atlantic Ocean\"'\n",
      "\n",
      "[0.5714285714285714, 0.5714285714285714, 0.42857142857142855, 0.42857142857142855, 0.5714285714285714]\n",
      "[0.23859485377233258, 0.498595199996924, 0.7745522060880237, 0.36475619024563005, 0.26017826738578537]\n",
      "[0.1363399164413329, 0.2849115428553851, 0.33195094546629583, 0.15632408153384145, 0.1486732956490202]\n",
      "('Why would a Roman in ancient Rome not wear a short-sleeved or sleeveless, '\n",
      " 'knee-length tunic for males to a formal event?')\n",
      "['A Roman would not wear a short-sleeved, knee-length tunic to a formal '\n",
      " 'function in ancient Rome since formal attire included a woolen toga thrown '\n",
      " 'over their tunic.',\n",
      " '\"On formal occasions Romans would wear a toga instead of a short-sleeved or '\n",
      " 'sleeveless, knee-length tunic for males to a formal event.\"',\n",
      " '\"A Roman in ancient Rome would not wear a short-sleeved or sleeveless, '\n",
      " 'knee-length tunic for males to a formal event if they were a woman.\"',\n",
      " '\"On formal occasions  in ancient Rome, adult male citizens could wear a '\n",
      " 'woolen toga, draped over their tunic.\"',\n",
      " '\"It was customary for Roman\\'s to wear woolen toga, draped over their tunic '\n",
      " 'to formal events.\"',\n",
      " '\"A Roman in ancient Rome would not wear a short-sleeved or sleeveless, '\n",
      " 'knee-length tunic for males to a formal event if he or she was a female.\"']\n",
      "'\"They have to wear a woolen toga instead.\"'\n",
      "\n",
      "[0.8, 0.55, 0.95, 0.55, 0.5]\n",
      "[0.6676260762419972, 0.5339935148355802, 0.47630011397890176, 0.8761560782555948, 0.8332857101494949]\n",
      "[0.5341008609935978, 0.29369643315956917, 0.45248510827995664, 0.4818858430405772, 0.41664285507474746]\n",
      "('The animal that has the scientific name Eutamias sibiricus has a diet of '\n",
      " 'what foods?')\n",
      "['The Siberian chipmunk eats pine seeds, deciduous and coniferous tree seeds, '\n",
      " 'herb roots, insects, molluscs, birds, reptiles, grains, fruit, and fungus.',\n",
      " '\"The animal known as Eutamias sabiricus is an omnivore, consuming primarily '\n",
      " 'pine seeds, herb roots, insects, molluscs, birds, reptiles, grains, fruit, '\n",
      " 'and fungus.\"',\n",
      " '\"The Siberian chipmunk has a diet of pine seeds, along with different '\n",
      " 'deciduous and coniferous tree seeds. In addition to seeds, they eat herb '\n",
      " 'roots, insects, molluscs, birds, reptiles, grains, fruit, and fungus.\"',\n",
      " '\"The animal that has the scientific name Eutamias sibiricus has an '\n",
      " 'omnivorous diet.\"',\n",
      " '\"Eutamias sibiricus eats pine seeds, herb roots, insects, molluscs, birds, '\n",
      " 'reptiles, grains, fruit, and fungus.\"',\n",
      " '\"Eutamias sibiricus has a diet of seeds, herb roots, insects, molluscs, '\n",
      " 'birds, reptiles, grains, fruit, and fungus.\"']\n",
      "('\"pine seeds, along with different deciduous and coniferous tree seeds, herb '\n",
      " 'roots, insects, mollusks, birds, reptiles, grains, fruit, and fungus\"')\n",
      "\n",
      "[1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333]\n",
      "[3.54532060098309e-05, 0.5217904522745634, 0.902473701815318, 0.46257998900031966, 0.8280362645856009, 5.859059369587253e-05]\n",
      "[3.54532060098309e-05, 0.3478603015163756, 0.902473701815318, 0.1541933296667732, 0.5520241763904006, 1.9530197898624176e-05]\n",
      "('The two figures depicted in the noteworthy tribute to Byzantine art in which '\n",
      " 'the subject faces the viewer, while the child gazes up at her also appear in '\n",
      " 'which painting that takes place inside a rose garden of late Gothic style?')\n",
      "['Madonna with Child contains the same subjects as Madonna and Child.',\n",
      " '\"Madonna with Child is the name of the painting that depicts two figures in '\n",
      " 'a noteworthy tribute to Byzantine art where the subject faces the viewer, '\n",
      " 'while the child gazes up at her.\"',\n",
      " '\"The two figures depicted in the noteworthy tribute to Byzantine art in '\n",
      " 'which the subject faces the viewer, while the child gazes up at her also '\n",
      " 'appear in \"Madonna and Child\" as well.\"',\n",
      " '\"Madonna of the Quail takes place in a rose garden of the late Gothic '\n",
      " 'style.\"',\n",
      " '\"The two figures depicted in the noteworthy tribute to Byzantine art in '\n",
      " 'which the subject faces the viewer, while the child gazes up at her also '\n",
      " 'appear in Madonna of the Quail that takes place inside a rose garden of late '\n",
      " 'Gothic style.\"',\n",
      " '\"These two figures also appear in the painting Madonna of the Quail.\"']\n",
      "'\"Madonna and Child\"'\n",
      "\n",
      "[0.5, 1.0, 1.0, 1.0, 0.5, 1.0]\n",
      "[3.789026039791798e-11, 2.945274365311036e-09, 8.087648624525816e-09, 8.30701847283545e-09, 0.27998107459557153, 0.21202634868790135]\n",
      "[1.894513019895899e-11, 2.945274365311036e-09, 8.087648624525816e-09, 8.30701847283545e-09, 0.13999053729778577, 0.21202634868790135]\n",
      "('In the country that contains different forms of dances that originated in '\n",
      " 'different parts of it, into what heritage of social norms and traditional '\n",
      " 'customs does it belong to?')\n",
      "['Culture.',\n",
      " '\"Indian culture is the heritage of social norms, ethical values, traditional '\n",
      " 'customs, belief systems, political systems, artifacts and technologies.\"',\n",
      " '\"It\\'s a part of Indian culture.\"',\n",
      " '\"Indian dance is based in Indian culture.\"',\n",
      " '\"Different forms of dances originated in different parts of the country with '\n",
      " 'Indian heritage.\"',\n",
      " '\"In the country that contains different forms of dances that originated in '\n",
      " 'different parts of it,  the social norms and traditional customs it belongs '\n",
      " 'to is the Indian culture.\"']\n",
      "'\"Indian culture\"'\n",
      "\n",
      "[1.0, 0.5, 0.5, 1.0, 0.5]\n",
      "[5.9333610708186794e-12, 0.7825422898646864, 0.8633400212526835, 7.090230909659934e-09, 0.759835685484625]\n",
      "[5.9333610708186794e-12, 0.3912711449323432, 0.43167001062634175, 7.090230909659934e-09, 0.3799178427423125]\n",
      "'The Gambler and Airport are both names of what?'\n",
      "['Film series',\n",
      " '\"The Gambler and Airport are both names of movie series.\"',\n",
      " '\"The Gambler and Airport are both names of films.\"',\n",
      " '\"The Airport and Gambler are both film series.\"',\n",
      " '\"The Gambler and Airport are both names of television films\"',\n",
      " '\"They are names of movies.\"']\n",
      "'\"film series\"'\n",
      "\n",
      "[0.8, 0.8, 0.4, 0.8, 0.8, 0.8]\n",
      "[0.5201564655732288, 0.6893133766819752, 0.8395876230551684, 0.3820008938661867, 0.6452320785811906, 0.6077244564912772]\n",
      "[0.41612517245858305, 0.5514507013455802, 0.3358350492220674, 0.3056007150929494, 0.5161856628649525, 0.48617956519302175]\n",
      "(\"Who wrote the 1957 children's book about a tall, anthropomorphic cat who \"\n",
      " 'wears a red and white-striped hat and a red bow tie?')\n",
      "['The Cat in the Hat was written and illustrated by the American author '\n",
      " 'Theodor Geisel, using the pen name Dr. Seuss.',\n",
      " '\"American author Theodor Geisel, used the pen name Dr. Seuss to write The '\n",
      " 'Cat in the Hat, a story about a tall, anthropomorphic cat who wears a red '\n",
      " 'and white-striped hat and a red bow tie.\"',\n",
      " '\"Dr. Seuss wrote the 1957 children\\'s book about a tall, anthropomorphic cat '\n",
      " 'who wears a red and white-striped hat and a red bow tie.\"',\n",
      " '\"Theodor Geisel, using the pen name Dr. Seuss, wrote \"The Cat in the Hat\".\"',\n",
      " '\"Theodor Geisel, using the pen name Dr. Seuss wrote the book The Cat and The '\n",
      " 'Hat, about a tall, anthropomorphic cat who wears a red and white striped '\n",
      " 'hat.\"',\n",
      " '\"The Cat in the Hat (a book about a tall, anthropomorphic cat who wears a '\n",
      " 'red and white-striped hat and a red bow tie) was written by Theodor Geisel, '\n",
      " 'also known as Dr. Seuss.\"']\n",
      "'\"Theodor Geisel, AKA Dr. Seuss\"'\n",
      "\n",
      "[1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0]\n",
      "[4.919625501680315e-05, 0.7308025729816102, 0.6968510143254569, 7.311104455930481e-05, 0.7284498525910669, 0.6083390278587288]\n",
      "[4.919625501680315e-05, 0.4872017153210735, 0.6968510143254569, 7.311104455930481e-05, 0.4856332350607112, 0.6083390278587288]\n",
      "('How many Chief Rabbis are in the authority that provides kosher supervision '\n",
      " 'for all of the Osem products that are produced in Israel?')\n",
      "['This authority has two Chief Rabbis.',\n",
      " '\"2 Chief Rabbis are in the authority that provides kosher supervision for '\n",
      " 'all of the Osem products that are produced in Israel.\"',\n",
      " '\"The Chief Rabbinate of Israel consists of two Chief Rabbis: an Ashkenazi '\n",
      " 'rabbi, and a Sephardi rabbi.\"',\n",
      " '\"The Chief Rabbinate Council assists two Chief Rabbis.\"',\n",
      " '\"There are two Chief Rabbis that are in the authority that provides kosher '\n",
      " 'supervision for all of the Osem products that are produced in Israel\"',\n",
      " '\"The Chief Rabbinate of Israel consists of two Chief Rabbis: an Ashkenazi '\n",
      " 'rabbi, and a Sephardi rabbi; the latter also is known as the Rishon leZion.\"']\n",
      "'\"Two Chief Rabbis\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 1.0, 1.0]\n",
      "[8.270540380894002e-11, 0.36807054403941214, 0.7048590794189892, 0.3689395297443587, 0.6698303498041884]\n",
      "[8.270540380894002e-11, 0.18403527201970607, 0.7048590794189892, 0.3689395297443587, 0.6698303498041884]\n",
      "('According to a hypothesis, further what, which is the process by which '\n",
      " 'humans acquire the capacity to perceive and comprehend language, becomes '\n",
      " 'much more difficult outside of an ideal time window ?')\n",
      "['Language acquisition',\n",
      " '\"According to the critical period hypothesis humans acquire the capacity to '\n",
      " 'perceive and comprehend language in a linguistically rich environment and it '\n",
      " 'becomes more difficult outside of an ideal time window.\"',\n",
      " '\"According to a hypothesis, further language acquisition becomes much more '\n",
      " 'difficult outside of an ideal time window.\"',\n",
      " '\"The hypothesis claims that there is an ideal time window to acquire '\n",
      " 'language after which further language acquisition becomes much more '\n",
      " 'difficult and effortful.\"',\n",
      " '\"According to the critical period hypothesis, further language acquisition '\n",
      " 'becomes much more difficult and effortful after the ideal time window.\"']\n",
      "'\"Language acquisition\"'\n",
      "\n",
      "[0.9, 1.0, 0.7, 0.7, 0.8, 0.6]\n",
      "[0.38992498156924094, 0.7577395671888485, 0.8648454150228945, 0.7381535620988638, 0.9999999999254122, 0.3370679494412266]\n",
      "[0.35093248341231686, 0.7577395671888485, 0.6053917905160261, 0.5167074934692046, 0.7999999999403298, 0.20224076966473595]\n",
      "\"Who was Adaeus and which Macedonian King's death did he allude?\"\n",
      "['Adaeus was a Greek epigrammatic poet who lived in the time of Alexander the '\n",
      " 'Great, to whose death he alludes.',\n",
      " '\"Adaeus was a Greek epigrammatic poet and he alluded to the death of '\n",
      " 'Alexander the Great.\"',\n",
      " '\"Adaeus was a Greek poet who alluded to the death of Alexander the Great.\"',\n",
      " '\"Adaeus was a Greek epigrammatic poet who alluded to Alexander the Great\\'s '\n",
      " 'death.\"',\n",
      " '\"Adaeus was a Greek epigrammatic poet who alluded to the death of Alexander '\n",
      " 'the Great.\"',\n",
      " '\"The Greek epigrammatic poet Adaeus alluded to Alexander the Great.\"']\n",
      "'\"A Greek epigrammatic poet and he alludes the death of Alexander the Great.\"'\n",
      "\n",
      "[1.0, 0.45454545454545453, 1.0, 1.0, 1.0]\n",
      "[0.9121679089903078, 0.14612476989078169, 0.710578169012056, 0.9234732618606082, 0.942723029210907]\n",
      "[0.9121679089903078, 0.06642034995035531, 0.710578169012056, 0.9234732618606082, 0.942723029210907]\n",
      "('An HDD storage device is a type of magnetic storage that has data written '\n",
      " 'into it by what kind of mechanical changes?')\n",
      "['From mechanical changes to a surface layer of one or more rotating disks.',\n",
      " '\"It says that an HDD is an electro-mechanical data storage device. It also '\n",
      " 'says that disk storage (also sometimes called drive storage) is a general '\n",
      " 'category of storage mechanisms where data is recorded by various electronic, '\n",
      " 'magnetic, optical, or mechanical changes. Therefore the answer is '\n",
      " 'electronic, magnetic, optical or mechanical.\"',\n",
      " '\"It is written into it by various electronic, magnetic, optical, or '\n",
      " 'mechanical changes to a surface layer of one or more rotating disks.\"',\n",
      " '\"An HDD storage device is a type of magnetic storage that has data written '\n",
      " 'into it by recording various electronic, magnetic, optical, or mechanical '\n",
      " 'changes to a surface layer of one or more rotating disks.\"',\n",
      " '\"An HDD storage device is a type of magnetic storage that has data written '\n",
      " 'into it by mechanical changes to a surface layer of one or more rotating '\n",
      " 'disks.\"',\n",
      " '\"It is written by magnetic changes.\"']\n",
      "'\"mechanical changes to the surface layer of one or more rotating disks\"'\n",
      "\n",
      "[0.3333333333333333, 1.0, 0.3333333333333333, 0.3333333333333333]\n",
      "[0.9999999998203284, 8.445588024384488e-17, 0.43022709312513885, 0.9999999998203284]\n",
      "[0.3333333332734428, 8.445588024384488e-17, 0.14340903104171293, 0.3333333332734428]\n",
      "('What is a particle-like property of the electrons which can only be an '\n",
      " 'integer if orbiting the nucleus?')\n",
      "['Each wave state has the same electrical charge as its electron particle.',\n",
      " '\"Electrons jump between orbitals like particles.\"',\n",
      " '\"A particle-like attribute of electrons that can only be an integer if they '\n",
      " 'are orbiting the nucleus and keeping particle-like properties such as having '\n",
      " 'the same electrical charge as its electron particle.\"',\n",
      " '\"A particle-like property of the electrons is the number of electrons '\n",
      " 'orbiting the nucleus can only be an integer\"',\n",
      " '\"An integer  is a particle-like property of the electrons which can only be '\n",
      " 'an integer if orbiting the nucleus.\"',\n",
      " '\"Each wave state has the same electrical charge as its electron particle.\"']\n",
      "'\"Like particles, Electrons jump between orbitals.\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "[9.39205654357949e-14, 0.9200444144640174, 0.8656030552096342, 0.7765453554362727, 0.8680538145221822]\n",
      "[4.696028271789745e-14, 0.4600222072320087, 0.4328015276048171, 0.38827267771813634, 0.4340269072610911]\n",
      "('The simple wheel and Saxony wheel were both used to spin what, for which '\n",
      " 'Manchester was famous in the 19th century?')\n",
      "['Cotton',\n",
      " '\"The simple wheel and Saxony wheel were both used to spin cotton.\"',\n",
      " '\"The simple wheel and Saxony wheel were both used to spin cotton, for which '\n",
      " 'Manchester was famous in the 19th century.\"',\n",
      " '\"The simple wheel and the Saxony wheel were both used to spin cotton.\"',\n",
      " '\"The simple wheel and Saxony wheel were both used to spin cotton, which '\n",
      " 'Manchester was famous in the 19th century.\"']\n",
      "'\"raw cotton\"'\n",
      "\n",
      "[1.0, 1.0, 1.0, 0.3333333333333333]\n",
      "[0.7071067809512664, 0.6434588839466586, 0.5828233953717938, 0.4296943523361429]\n",
      "[0.7071067809512664, 0.6434588839466586, 0.5828233953717938, 0.1432314507787143]\n",
      "('What program or software agent that receives electronic mail messages would '\n",
      " 'use SMTP on TCP port 587?')\n",
      "['A message submission agent would use this.',\n",
      " '\"An MSA would use SMTP on TCP port 587.\"',\n",
      " '\"Email would use SMTP on TCP port 587\"',\n",
      " '\"A message submission agent would do this.\"',\n",
      " '\"A message submission agent receives electronic mail messages would use SMTP '\n",
      " 'on TCP port 587.\"',\n",
      " '\"A mail user agent would uses SMTP on TCP port 587.\"']\n",
      "'\"message submission agent\"'\n",
      "\n",
      "[0.5, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.3939047821026512e-11, 0.4004970148065696, 0.904837417837129, 0.7016879390528286, 0.503174762615483]\n",
      "[6.969523910513256e-12, 0.4004970148065696, 0.904837417837129, 0.7016879390528286, 0.503174762615483]\n",
      "'MMP, FPTP, and DMP are all what types of system?'\n",
      "['Electoral',\n",
      " '\"They are all types of electoral system.\"',\n",
      " '\"MMP, FPTP, and DMP are all types of electoral systems.\"',\n",
      " '\"MMP, FPTP, and DMP are all different types of electoral systems.\"',\n",
      " '\"MMP, FPTP, and DMP are all types of representatives in proportional '\n",
      " 'representation electoral (voting) systems.\"']\n",
      "'\"electoral system\"'\n",
      "\n",
      "[0.3333333333333333, 1.0, 1.0]\n",
      "[3.558674685530305e-12, 0.5963584321080208, 0.5819422126333536]\n",
      "[1.1862248951767682e-12, 0.5963584321080208, 0.5819422126333536]\n",
      "('What Catholic Church, some of which Assyrians self-identify as, and the '\n",
      " 'Syro-Malabar Catholic Church are in full communion with the Holy See?')\n",
      "['Chaldean',\n",
      " '\"The Chaldean Catholic Church, some of which Assyrians self-identify as, and '\n",
      " 'the Syro-Malabar Catholic Church are in full communion with the Holy See.\"',\n",
      " '\"The Chaldean Catholic Church and the Syro-Malabar Catholic Church are in '\n",
      " 'full communion with the Holy See.\"']\n",
      "'\"The Chaldean Catholic Church\"'\n",
      "\n",
      "[0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666]\n",
      "[2.0237345066702103e-08, 0.795270728445629, 0.8091067113010008, 0.8408964149739164, 0.7598356853444925, 0.43472087180034347]\n",
      "[1.3491563377801401e-08, 0.26509024281520965, 0.2697022371003336, 0.5605976099826109, 0.2532785617814975, 0.2898139145335623]\n",
      "'Gyūdon and Oden are both what?'\n",
      "['Japanese dishes',\n",
      " '\"Gyūdon and Oden are both dishes.\"',\n",
      " '\"Gyūdon and Oden are both Japanese meals.\"',\n",
      " '\"Gyūdon and Oden are both Japanese dishes.\"',\n",
      " '\"Gyūdon and Oden are both food.\"',\n",
      " '\"Both Gyūdon and Oden are food dishes.\"']\n",
      "'\"Japanese food dishes.\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5]\n",
      "[1.886444984907315e-12, 0.5328009719478115, 0.16959011074261374, 0.460866246974817]\n",
      "[9.432224924536574e-13, 0.26640048597390575, 0.08479505537130687, 0.2304331234874085]\n",
      "('What fifteenth-largest ethnic group in the world come from a country that '\n",
      " 'became home to a large number of foreign ethnicities?')\n",
      "['Koreans.',\n",
      " '\"Koreans come from a country that became home to a large number of foreign '\n",
      " 'ethnicities.\"',\n",
      " '\"Koreans are the fifteenth-largest ethnic group in the world.\"',\n",
      " '\"Koreans, the fifteenth-larges ethnic group in the world, come from Korea, '\n",
      " 'which has become home to a large number of foreign ethnicities.\"']\n",
      "'\"South Koreans\"'\n",
      "\n",
      "[0.3333333333333333, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5]\n",
      "[0.8408964151203224, 0.8395876230201856, 0.8489699464834778, 0.7989918854894862, 0.8280264443959445]\n",
      "[0.28029880504010746, 0.4197938115100928, 0.5659799643223185, 0.26633062849649536, 0.41401322219797226]\n",
      "('The main Greco-Roman source on what people, sources used to reconstruct the '\n",
      " 'history of which are few and disparate, wrote an anthology drawn from what '\n",
      " 'person?')\n",
      "['Pompeius Trogus',\n",
      " '\"He wrote an anthology drawn from Pompeius Trogus.\"',\n",
      " '\"The main Greco-Roman source of Indo-Greeks used to reconstruct the history '\n",
      " 'of which are few and disparate, wrote an anthology drawn from Pompeius '\n",
      " 'Trogus.\"',\n",
      " '\"The main Greco-Roman source on Indo-Greeks, sources used to reconstruct the '\n",
      " 'history of which are few and disparate, wrote an anthology drawn from '\n",
      " 'Justin.\"',\n",
      " '\"The main Greco-Roman source on what people, sources used to reconstruct the '\n",
      " 'history of which are few and disparate, wrote an anthology drawn from '\n",
      " 'Pompeius Trogus\"',\n",
      " '\"The main Greco-Roman source on the Indo-Greeks, which sources used to '\n",
      " 'reconstruct the history of which are few and disparate, wrote an anthology '\n",
      " 'drawn from Pompeius Trogus.\"']\n",
      "'\"Anthology, written by Justin about Indo-Greeks\"'\n",
      "\n",
      "[1.0, 1.0, 0.5, 1.0, 1.0]\n",
      "[0.005972770989312134, 0.9656628853208405, 0.9244754046447258, 0.543558857175796, 0.4111336168353014]\n",
      "[0.005972770989312134, 0.9656628853208405, 0.4622377023223629, 0.543558857175796, 0.4111336168353014]\n",
      "('A what, which have no minimum or maximum range, although the broadcast power '\n",
      " 'level imposes a practical limit on range,  is said to be matched when the '\n",
      " 'receiver filter size matches the RMS bandwidth of the FM noise on the '\n",
      " 'transmit signal?')\n",
      "['A CW radar',\n",
      " '\"A CW radar is said to be matched when the receiver filter size matches the '\n",
      " 'RMS bandwidth of the FM noise on the transmit signal.\"',\n",
      " '\"A continuous-wave radar is said to be matched when the receiver filter size '\n",
      " 'matches the RMS bandwidth of the FM noise on the transmit signal.\"',\n",
      " '\"A CW radar, which have no minimum or maximum range, although the broadcast '\n",
      " 'power level imposes a practical limit on range, is said to be matched when '\n",
      " 'the receiver filter size matches the RMS bandwidth of the FM noise on the '\n",
      " 'transmit signal\"',\n",
      " '\"CW radar has no minimum or maximum range.\"']\n",
      "'\"CW radar\"'\n",
      "\n",
      "[1.0, 1.0, 0.4, 0.4]\n",
      "[0.3678794409798387, 0.8344522896419115, 0.9999999997802583, 0.8801117365999962]\n",
      "[0.3678794409798387, 0.8344522896419115, 0.39999999991210333, 0.3520446946399985]\n",
      "'What two things are sometimes composed of grains of quartz?'\n",
      "['Shale and clastic sedimentary rocks',\n",
      " '\"Shale and clastic sedimentary rocks are sometimes composed of grains of '\n",
      " 'quartz.\"',\n",
      " '\"Shales and clasts are sometimes composed of grains of quartz.\"',\n",
      " '\"Shales and clasts are sometimes composed of grains of quartz\"']\n",
      "'\"Shales and clastic sedimentary rocks.\"'\n",
      "\n",
      "[0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666]\n",
      "[0.9036020034312353, 0.34364463929801803, 0.8349950230407167, 4.715663208579191e-05, 0.6680785126431021, 0.45857140232832544]\n",
      "[0.30120066781041177, 0.22909642619867868, 0.27833167434690553, 1.5718877361930636e-05, 0.4453856750954014, 0.3057142682188836]\n",
      "('What is the mountain range made of that together with the Boston mountains '\n",
      " 'forms the Ozarks?')\n",
      "['St. Francois Mountains are made up of igneous and volcanic rocks.',\n",
      " '\"The mountain range is the St. Francois Mountains.\"',\n",
      " '\"The St. Francois Mountains are made of igneous and volcanic rocks.\"',\n",
      " '\"Together the Boston Mountains of Arkansas and the St. Francois Mountains of '\n",
      " 'Arkansas form the Ozarks.\"',\n",
      " '\"The St. Francois Mountains are made up of the eroded remnants of an ancient '\n",
      " 'range and together with the Boston mountains, they form the Ozarks.\"',\n",
      " '\"The mountain range is made of eroded remnants of an ancient range that, '\n",
      " 'together with the Boston mountains, forms the Ozarks.\"']\n",
      "'\"Proterozoic mountain range\"'\n",
      "\n",
      "[0.5, 1.0, 0.5]\n",
      "[1.3939047821026512e-11, 0.5578002858912754, 0.5410822689681074]\n",
      "[6.969523910513256e-12, 0.5578002858912754, 0.2705411344840537]\n",
      "'Boolean and symmetric are both types of what?'\n",
      "['Functions',\n",
      " '\"Boolean and symmetric are both mathematical functions.\"',\n",
      " '\"Boolean and symmetric are both types of functions.\"']\n",
      "'\"Mathematical functions\"'\n",
      "\n",
      "[0.5, 0.5, 0.5, 0.5, 1.0, 1.0]\n",
      "[8.931375819381362e-07, 3.784157746578089e-09, 0.8307018473239388, 0.6389431041697643, 0.8003203202714512, 0.6771219107844341]\n",
      "[4.465687909690681e-07, 1.8920788732890443e-09, 0.4153509236619694, 0.31947155208488215, 0.8003203202714512, 0.6771219107844341]\n",
      "('A procedural drama can be what content produced for viewing on a television '\n",
      " 'set?')\n",
      "['A TV show.',\n",
      " '\"A procedural or procedural drama is a cross- genre type of literature, '\n",
      " 'film, or television program involving a sequence of technical detail.\"',\n",
      " '\"A procedural drama can be a television program produced for viewing on a '\n",
      " 'television set.\"',\n",
      " '\"A procedural drama can be a type of TV show.\"',\n",
      " '\"A procedural drama can be a television show produced for viewing on a '\n",
      " 'television set.\"',\n",
      " '\"A procedural drama can be a television show.\"']\n",
      "'\"A television show\"'\n",
      "\n",
      "[1.0, 0.5, 1.0, 1.0]\n",
      "[5.016336313403614e-11, 0.9426151475778155, 0.852245671308248, 0.9999999998899907]\n",
      "[5.016336313403614e-11, 0.47130757378890775, 0.852245671308248, 0.9999999998899907]\n",
      "('What occurs naturally in many foods and is also a metabolism product of the '\n",
      " 'degradation of ethylene glycol?')\n",
      "['Oxalic acid.',\n",
      " '\"Oxalix acid occurs naturally in many foods and is also a metabolism product '\n",
      " 'of the degradation of ethylene glycol.\"',\n",
      " '\"Oxalic acid occurs naturally in many foods and is a metabolism product of '\n",
      " 'the degradation of ethylene glycol.\"',\n",
      " '\"Oxalic acid occurs naturally in many foods and is also a metabolism product '\n",
      " 'of the degradation of ethylene glycol.\"']\n",
      "'\"Oxalic acid\"'\n"
     ]
    }
   ],
   "source": [
    "for k in bleu4_txt_clean:\n",
    "    if np.mean(RE_txt_clean[k]) > 0.9: continue\n",
    "    if random.random() > 0.1: continue\n",
    "    print()\n",
    "    print(RE_txt_clean[k])\n",
    "    print(bleu4_txt_clean[k])\n",
    "    print(mul_txt_clean[k])\n",
    "        \n",
    "    pprint(txt_dataset[k]['Q'])\n",
    "    pprint(txt_dataset[k]['A'])\n",
    "    pprint(txt_dataset[k]['Keywords_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24962\n",
      "before cleaning, #test =  4695\n",
      "after cleaning, #test =  4076\n",
      "24343\n",
      "after cleaning, #test =  4076\n"
     ]
    }
   ],
   "source": [
    "### Save txt_dataset with a cleaner testing set\n",
    "txt_dataset_0823_clean_te = copy.deepcopy(txt_dataset)\n",
    "print(len(txt_dataset_0823_clean_te))\n",
    "print(\"before cleaning, #test = \", len([k for k in txt_dataset_0823_clean_te if txt_dataset_0823_clean_te[k]['split'] == 'test']))\n",
    "print(\"after cleaning, #test = \", len(RE_txt_clean))\n",
    "for k in txt_dataset:\n",
    "    if not txt_dataset_0823_clean_te[k]['split'] == 'test': continue\n",
    "    if not k in RE_txt_clean:\n",
    "        del txt_dataset_0823_clean_te[k]\n",
    "    else:\n",
    "        txt_dataset_0823_clean_te[k]['A'] = keep_txt_A_list[k]\n",
    "print(len(txt_dataset_0823_clean_te))\n",
    "print(\"after cleaning, #test = \", len([k for k in txt_dataset_0823_clean_te if txt_dataset_0823_clean_te[k]['split'] == 'test']))\n",
    "json.dump(txt_dataset_0823_clean_te, open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0823_clean_te.json\", \"w\"), indent=4)\n",
    "#json.dump(txt_dataset_0823_clean_te, open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0823_clean_te_5.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check clean_te version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0823_clean_te.json\", \"r\"))\n",
    "img_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0823_clean_te.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 1579, 5: 780, 4: 703, 3: 402})\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for k in img_dataset:\n",
    "    if img_dataset[k]['split'] == 'test':\n",
    "        x.append(len(img_dataset[k]['A']))\n",
    "print(Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "3464\n",
      "defaultdict(<class 'int'>, {})\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## 同一个sample单独，最后取avg/max，RE<0.3的 full sentence 忽略\n",
    "### Double check on the clean_te version\n",
    "eval_f = Evaluate()\n",
    "bleu4_img_clean = {}\n",
    "RE_img_clean = {}\n",
    "F1_img_clean = {}\n",
    "mul_img_clean = {}\n",
    "\n",
    "drop = defaultdict(int)\n",
    "for k in img_dataset:\n",
    "    if not 'test' in img_dataset[k]['split']: continue\n",
    "    bleu4_img_clean[k] = []\n",
    "    RE_img_clean[k] = []\n",
    "    mul_img_clean[k] = []\n",
    "    F1_img_clean[k] = []\n",
    "    datum = img_dataset[k]\n",
    "    Keywords_A = datum['Keywords_A'].replace('\"', \"\")\n",
    "    all_A = [a.replace('\"', \"\") for a in datum['A']]\n",
    "    Qcate = img_dataset[k]['Qcate']\n",
    "    for i in range(len(all_A)):\n",
    "        Q = datum['Q'].replace('\"', \"\")\n",
    "        C = [all_A[i]]\n",
    "        A_list = all_A[:i] + all_A[i+1:]\n",
    "        scores = eval_f.evaluate(cand=[C], ref=[A_list], return_scores=True)\n",
    "        #print(scores)\n",
    "        \n",
    "        if Qcate == 'color': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", color_set)\n",
    "        elif Qcate == 'shape': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", shape_set)\n",
    "        elif Qcate == 'YesNo': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", yesno_set)\n",
    "        elif Qcate == 'number': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", {\"NUMBER\"})\n",
    "        else: F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A)\n",
    "        bleu4_img_clean[k].append(scores['Bleu_4'])\n",
    "        RE_img_clean[k].append(RE_avg)\n",
    "        F1_img_clean[k].append(F1_avg)\n",
    "        if Qcate in ['choose', 'Others']: mul_img_clean[k].append(RE_avg * scores['Bleu_4'])\n",
    "        else: mul_img_clean[k].append(F1_avg * scores['Bleu_4'])\n",
    "        \n",
    "    if len(RE_img_clean) % 500 == 499: print(len(RE_img_clean))\n",
    "assert len(RE_img_clean) == len(mul_img_clean) == len(bleu4_img_clean) == len(F1_img_clean)\n",
    "print(len(RE_img_clean))\n",
    "print(drop)\n",
    "print(np.sum(list(drop.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 1579, 5: 780, 4: 703, 3: 402})\n",
      "mean RE:  0.9544662625724938\n",
      "mean F1:  0.5658698487995043\n",
      "mean bleu4:  0.6172481514538837\n",
      "mean mul:  0.5891873785394158\n",
      "\n",
      " choose\n",
      "mean RE:  0.9746595876568294\n",
      "mean F1:  0.3082771627038374\n",
      "mean bleu4:  0.6640435153229656\n",
      "mean mul:  0.651500361127975\n",
      "\n",
      " YesNo\n",
      "mean RE:  1.0\n",
      "mean F1:  0.9996384943803229\n",
      "mean bleu4:  0.5561091179381232\n",
      "mean mul:  0.5559100812476657\n",
      "\n",
      " Others\n",
      "mean RE:  0.8799223590146941\n",
      "mean F1:  0.24272256117956434\n",
      "mean bleu4:  0.6320506209199894\n",
      "mean mul:  0.5653609569231084\n",
      "\n",
      " color\n",
      "mean RE:  0.9836866471734893\n",
      "mean F1:  0.958286424484597\n",
      "mean bleu4:  0.6043261385509513\n",
      "mean mul:  0.5827412047857489\n",
      "\n",
      " shape\n",
      "mean RE:  0.9821236559139784\n",
      "mean F1:  0.9421993814777573\n",
      "mean bleu4:  0.5660267821267729\n",
      "mean mul:  0.5332073612663406\n",
      "\n",
      " number\n",
      "mean RE:  0.995\n",
      "mean F1:  0.9469256561066419\n",
      "mean bleu4:  0.6258465290872643\n",
      "mean mul:  0.5898577775655651\n"
     ]
    }
   ],
   "source": [
    "print(Counter([len(RE_img_clean[k]) for k in RE_img_clean]))\n",
    "Qcate = ['choose', 'YesNo', 'Others', 'color', 'shape', 'number']\n",
    "print(\"mean RE: \", np.mean([np.mean(RE_img_clean[k]) for k in RE_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "print(\"mean F1: \", np.mean([np.mean(F1_img_clean[k]) for k in F1_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "print(\"mean bleu4: \", np.mean([np.mean(bleu4_img_clean[k]) for k in bleu4_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "print(\"mean mul: \", np.mean([np.mean(mul_img_clean[k]) for k in mul_img_clean if img_dataset[k]['Qcate'] in Qcate]))\n",
    "\n",
    "Qcate = ['choose', 'YesNo', 'Others', 'color', 'shape', 'number']\n",
    "for cate in Qcate:\n",
    "    print(\"\\n\", cate)\n",
    "    print(\"mean RE: \", np.mean([np.mean(RE_img_clean[k]) for k in RE_img_clean if img_dataset[k]['Qcate'] == cate]))\n",
    "    print(\"mean F1: \", np.mean([np.mean(F1_img_clean[k]) for k in F1_img_clean if img_dataset[k]['Qcate'] == cate]))\n",
    "    print(\"mean bleu4: \", np.mean([np.mean(bleu4_img_clean[k]) for k in bleu4_img_clean if img_dataset[k]['Qcate'] == cate]))\n",
    "    print(\"mean mul: \", np.mean([np.mean(mul_img_clean[k]) for k in mul_img_clean if img_dataset[k]['Qcate'] == cate]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 1366, 5: 1343, 4: 874, 3: 493})\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for k in txt_dataset:\n",
    "    if txt_dataset[k]['split'] == 'test':\n",
    "        x.append(len(txt_dataset[k]['A']))\n",
    "print(Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "3499\n",
      "3999\n",
      "4076\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## 同一个sample单独，最后取avg/max，RE<0.5的 full sentence 忽略\n",
    "eval_f = Evaluate()\n",
    "bleu4_txt_clean = {}\n",
    "RE_txt_clean = {}\n",
    "mul_txt_clean = {}\n",
    "drop = 0\n",
    "for k in txt_dataset:\n",
    "    if not 'test' in txt_dataset[k]['split']: continue\n",
    "    bleu4_txt_clean[k] = []\n",
    "    RE_txt_clean[k] = []\n",
    "    mul_txt_clean[k] = []\n",
    "    datum = txt_dataset[k]\n",
    "    Keywords_A = datum['Keywords_A'].replace('\"', \"\")\n",
    "    all_A = [a.replace('\"', \"\") for a in datum['A']]\n",
    "    for i in range(len(all_A)):\n",
    "        Q = datum['Q'].replace('\"', \"\")\n",
    "        C = [all_A[i]]\n",
    "        A_list = all_A[:i] + all_A[i+1:]\n",
    "        scores = eval_f.evaluate(cand=[C], ref=[A_list], return_scores=True)\n",
    "        #print(scores)\n",
    "        \n",
    "        F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A)\n",
    "        bleu4_txt_clean[k].append(scores['Bleu_4'])\n",
    "        RE_txt_clean[k].append(RE_avg)\n",
    "        mul_txt_clean[k].append(RE_avg * scores['Bleu_4'])\n",
    "    \n",
    "    if len(RE_txt_clean) % 500 == 499: print(len(RE_txt_clean))\n",
    "assert len(RE_txt_clean) == len(mul_txt_clean) == len(bleu4_txt_clean)\n",
    "print(len(RE_txt_clean))\n",
    "print(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 1366, 5: 1343, 4: 874, 3: 493})\n",
      "mean RE:  0.9458907476823312\n",
      "mean mul:  0.4871889696253697\n",
      "mean bleu4:  0.5139965782866891\n"
     ]
    }
   ],
   "source": [
    "# 0.3 threshold\n",
    "print(Counter([len(RE_txt_clean[k]) for k in RE_txt_clean]))\n",
    "print(\"mean RE: \", np.mean([np.mean(RE_txt_clean[k]) for k in RE_txt_clean]))\n",
    "print(\"mean mul: \", np.mean([np.mean(mul_txt_clean[k]) for k in mul_txt_clean]))\n",
    "print(\"mean bleu4: \", np.mean([np.mean(bleu4_txt_clean[k]) for k in bleu4_txt_clean]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25015\n"
     ]
    }
   ],
   "source": [
    "Q = []\n",
    "A_list = []\n",
    "C = []\n",
    "Keywords_A = []\n",
    "for k in txt_dataset:\n",
    "    if not 'test' in txt_dataset[k]['split']: continue\n",
    "    datum = txt_dataset[k]\n",
    "    all_A = [a.replace('\"', \"\") for a in datum['A']]\n",
    "    for i in range(len(all_A)):\n",
    "        Q.append(datum['Q'].replace('\"', \"\"))\n",
    "        C.append([all_A[i]])\n",
    "        A_list.append(all_A[:i] + all_A[i+1:])\n",
    "        Keywords_A.append(datum['Keywords_A'].replace('\"', \"\"))\n",
    "assert len(C) == len(Q) == len(A_list) == len(Keywords_A)\n",
    "print(len(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 365753, 'reflen': 368388, 'guess': [365753, 340738, 317201, 294375], 'correct': [302169, 244036, 202037, 168574]}\n",
      "ratio: 0.9928472154358965\n",
      "Bleu_1\n",
      "Bleu_2\n",
      "Bleu_3\n",
      "Bleu_4\n",
      "ROUGE_L\n",
      "Bleu_1:\t 0.820225403511018\n",
      "Bleu_2:\t 0.7636931139008422\n",
      "Bleu_3:\t 0.7171364099147381\n",
      "Bleu_4:\t 0.6766927878708912\n",
      "ROUGE_L: 0.6734202548341871\n"
     ]
    }
   ],
   "source": [
    "eval_f = Evaluate()\n",
    "scores = eval_f.evaluate(cand=C, ref=A_list, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_avg = 0.2933705406243417\n",
      "F1_max = 0.2933705406243417\n",
      "EM = 0.07567459524285429\n",
      "RE_avg = 0.7901031055052431\n",
      "PR_avg = 0.22620708177082618\n",
      "RE * BLEU4 = 0.5346570731697918\n"
     ]
    }
   ],
   "source": [
    "# SQuAD style vqa eval: EM, F1\n",
    "F1_avg_scores = []\n",
    "F1_max_scores = []\n",
    "EM_scores = []\n",
    "RE_scores = []\n",
    "PR_scores = []\n",
    "#F1_avg_bertscores = []\n",
    "#F1_max_bertscores = []\n",
    "for cands, a in zip(C, Keywords_A):\n",
    "    assert len(cands)==1\n",
    "    F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics([cands[0]], a)\n",
    "    F1_avg_scores.append(F1_avg)\n",
    "    F1_max_scores.append(F1_max)\n",
    "    EM_scores.append(EM)\n",
    "    RE_scores.append(RE_avg)\n",
    "    PR_scores.append(PR_avg)\n",
    "\n",
    "    #F1_avg_bertscore, F1_max_bertscore = compute_bertscore([cands[0]], a)\n",
    "    #F1_avg_bertscores.append(F1_avg_bertscore)\n",
    "    #F1_max_bertscores.append(F1_max_bertscore)\n",
    "\n",
    "F1_avg = np.mean(F1_avg_scores)\n",
    "F1_max = np.mean(F1_max_scores)\n",
    "EM = np.mean(EM_scores)\n",
    "RE_avg = np.mean(RE_scores)\n",
    "PR_avg = np.mean(PR_scores)\n",
    "\n",
    "#F1_avg_bertscore = np.mean(F1_avg_bertscores)\n",
    "#F1_max_bertscore = np.mean(F1_max_bertscores)\n",
    "print(\"F1_avg = {}\".format(F1_avg))\n",
    "print(\"F1_max = {}\".format(F1_max))\n",
    "print(\"EM = {}\".format(EM))\n",
    "print(\"RE_avg = {}\".format(RE_avg))\n",
    "print(\"PR_avg = {}\".format(PR_avg))\n",
    "\n",
    "#print(\"F1_avg_bertscore = {}\".format(F1_avg_bertscore))\n",
    "#print(\"F1_max_bertscore = {}\".format(F1_max_bertscore))\n",
    "\n",
    "print(\"RE * BLEU4 = {}\".format(RE_avg * scores['Bleu_4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
