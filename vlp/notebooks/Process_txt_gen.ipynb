{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json, time, copy\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "from word2number import w2n\n",
    "import string, re\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\",\"textcat\",\"parser\"])\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'train': 17812, 'test': 4076, 'val': 2455})\n",
      "24343\n"
     ]
    }
   ],
   "source": [
    "txt_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0823_clean_te.json\", \"r\"))\n",
    "\n",
    "print(Counter([txt_dataset[k]['split'] for k in txt_dataset]))\n",
    "print(len(set([txt_dataset[k]['Guid'] for k in txt_dataset])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 5, 'A': 3, 'Guid': 0, 'Keywords_A': 4, 'Passage': 6, 'Q': 2, 'Qcate': 1}\n"
     ]
    }
   ],
   "source": [
    "file = \"Txt_gen_model/Trial1_LargePredictions_4dc3.tsv\"\n",
    "with open(os.path.join(\"/home/yingshac/CYS/WebQnA/VLP/vlp/light_output/\", file), \"r\") as fp:\n",
    "    lines = fp.readlines()\n",
    "    header = lines[0].strip().split('\\t')\n",
    "    rows = lines[1:]\n",
    "key = dict(zip(header, range(len(header))))\n",
    "pprint(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4180\n"
     ]
    }
   ],
   "source": [
    "guid2output = dict([(r.strip().split('\\t')[0], r.strip().split('\\t')[-1]) for r in rows])\n",
    "print(len(guid2output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11a8fd8b-b505-473e-904a-889bd04af07d\n",
      "7257e221-9e93-45d9-8a81-8728a750f86f\n",
      "dcebed0b-269c-48b7-90fa-b3dd781e7483\n"
     ]
    }
   ],
   "source": [
    "f = open(os.path.join(\"/home/yingshac/CYS/WebQnA/VLP/vlp/light_output/\", file.split('.')[0]+\"_cor.tsv\"), \"w\")\n",
    "header = ['Guid', 'Qcate', 'Q', 'A', 'Keywords_A', 'Output_conf', 'Output']\n",
    "v = '{0}\\n'.format('\\t'.join(map(str, header)))\n",
    "f.write(v)\n",
    "for k in txt_dataset:\n",
    "    if not txt_dataset[k]['split'] == 'test': continue\n",
    "    guid = txt_dataset[k]['Guid']\n",
    "    if not guid in guid2output: \n",
    "        print(guid)\n",
    "        continue\n",
    "    row = [guid, 'text', txt_dataset[k]['Q'], json.dumps(txt_dataset[k]['A']), txt_dataset[k]['Keywords_A'], 1, json.dumps([guid2output[guid]])]\n",
    "    v = '{0}\\n'.format('\\t'.join(map(str, row)))\n",
    "    f.write(v)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2-Butoxyethanol is a solvent for paints and surface coatings, as well as cleaning products and inks. It can be obtained in the laboratory by performing a ring opening of 2-propyl-1.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = random.choice(list(guid2output.keys()))\n",
    "guid2output[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "folder = \"/home/yingshac/CYS/WebQnA/VLP/vlp/Human/\"\n",
    "with open(os.path.join(folder, \"df_txt_write_all_keep.json\"), \"r\", encoding=\"utf-8\") as file:\n",
    "    txt_data = json.load(file)\n",
    "with open(os.path.join(folder, \"df_img_write_all_keep.json\"), \"r\", encoding=\"utf-8\") as file:\n",
    "    mm_data = json.load(file)\n",
    "print(len(txt_data.values()))\n",
    "print(len(mm_data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Guid', 'Question', 'Qtype', 'AllFactsWithJudgments'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fact': \"Tolkien's Middle-earth stories mostly focus on the north-west of the continent. This part of Middle-earth is suggestive of Europe, the north-west of the Old World, with the environs of the Shire intended to be reminiscent of England (more specifically, the West Midlands, with the town at its centre, Hobbiton, at the same latitude as Oxford ).\",\n",
       " 'judgedIsSupporting': True,\n",
       " 'title': 'Middle-earth - Wikipedia',\n",
       " 'type': 'supp',\n",
       " 'url': 'https://en.wikipedia.org/wiki/Middle-earth'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(txt_data['0']['AllFactsWithJudgments'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not json.loads(txt_data['0']['AllFactsWithJudgments'])[1]['type'] == 'supp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9282856195848658\n",
      "0.9436666666666667\n",
      "0.9320999999999999\n"
     ]
    }
   ],
   "source": [
    "compute_retrieval_metrics([0,1,2], [1,3])\n",
    "F1s = []\n",
    "REs = []\n",
    "PRs = []\n",
    "for k in txt_data:\n",
    "    datum = txt_data[k]\n",
    "    pred = []\n",
    "    gth = []\n",
    "    i = 0\n",
    "    for f in json.loads(datum['AllFactsWithJudgments']):\n",
    "        if f['judgedIsSupporting']: pred.append(i)\n",
    "        if f['type'] == 'supp': gth.append(i)\n",
    "        i += 1\n",
    "    F1, RE, PR = compute_retrieval_metrics(pred, gth)\n",
    "    F1s.append(F1)\n",
    "    REs.append(RE)\n",
    "    PRs.append(PR)\n",
    "assert len(F1s) == len(REs) == len(PRs)\n",
    "print(np.mean(F1s))\n",
    "print(np.mean(REs))\n",
    "print(np.mean(PRs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[0, 1]\n",
      "0.7999952000287999 1.0 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    k = random.choice(list(mm_data.keys()))\n",
    "    datum = mm_data[k]\n",
    "    pred = []\n",
    "    gth = []\n",
    "    i = 0\n",
    "    for f in json.loads(datum['AllFactsWithJudgments']):\n",
    "        if f['judgedIsSupporting']: pred.append(i)\n",
    "        if f['type'] == 'supp': gth.append(i)\n",
    "        i += 1\n",
    "    F1, RE, PR = compute_retrieval_metrics(pred, gth)\n",
    "    if F1 < 0.999:\n",
    "        \n",
    "        print(pred)\n",
    "        print(gth)\n",
    "\n",
    "        print(F1, RE, PR)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 =  0.9054246800241467\n",
      "RE =  0.9493333333333333\n",
      "PR =  0.8974273522229403\n"
     ]
    }
   ],
   "source": [
    "compute_retrieval_metrics([0,1,2], [1,3])\n",
    "F1s = []\n",
    "REs = []\n",
    "PRs = []\n",
    "for k in mm_data:\n",
    "    datum = mm_data[k]\n",
    "    pred = []\n",
    "    gth = []\n",
    "    i = 0\n",
    "    for f in json.loads(datum['AllFactsWithJudgments']):\n",
    "        if f['judgedIsSupporting']: pred.append(i)\n",
    "        if f['type'] == 'supp': gth.append(i)\n",
    "        i += 1\n",
    "    F1, RE, PR = compute_retrieval_metrics(pred, gth)\n",
    "    F1s.append(F1)\n",
    "    REs.append(RE)\n",
    "    PRs.append(PR)\n",
    "for k in txt_data:\n",
    "    datum = txt_data[k]\n",
    "    pred = []\n",
    "    gth = []\n",
    "    i = 0\n",
    "    for f in json.loads(datum['AllFactsWithJudgments']):\n",
    "        if f['judgedIsSupporting']: pred.append(i)\n",
    "        if f['type'] == 'supp': gth.append(i)\n",
    "        i += 1\n",
    "    F1, RE, PR = compute_retrieval_metrics(pred, gth)\n",
    "    F1s.append(F1)\n",
    "    REs.append(RE)\n",
    "    PRs.append(PR)\n",
    "assert len(F1s) == len(REs) == len(PRs)\n",
    "print(\"F1 = \", np.mean(F1s))\n",
    "print(\"RE = \", np.mean(REs))\n",
    "print(\"PR = \", np.mean(PRs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_retrieval_metrics([0,1,2], [1,3])\n",
    "F1s = []\n",
    "REs = []\n",
    "PRs = []\n",
    "for k in mm_data:\n",
    "    datum = mm_data[k]\n",
    "    pred = []\n",
    "    gth = []\n",
    "    i = 0\n",
    "    for f in json.loads(datum['AllFactsWithJudgments']):\n",
    "        if f['judgedIsSupporting']: pred.append(i)\n",
    "        if f['type'] == 'supp': gth.append(i)\n",
    "        i += 1\n",
    "    F1, RE, PR = compute_retrieval_metrics(pred, gth)\n",
    "    F1s.append(F1)\n",
    "    REs.append(RE)\n",
    "    PRs.append(PR)\n",
    "assert len(F1s) == len(REs) == len(PRs)\n",
    "print(np.mean(F1s))\n",
    "print(np.mean(REs))\n",
    "print(np.mean(PRs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_retrieval_metrics(pred, gth):\n",
    "    common = len(set(pred).intersection(gth))\n",
    "    RE = common / len(gth)\n",
    "    if len(pred) == 0: return 0,0,0\n",
    "    PR = common / len(pred)\n",
    "    F1 = 2*PR*RE / (PR + RE + 1e-5)\n",
    "    return F1, RE, PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
