{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json, time, copy\n",
    "import math\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from word2number import w2n\n",
    "import string, re\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\",\"textcat\",\"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectNum(l):\n",
    "    result = []\n",
    "    for w in l:\n",
    "        try: result.append(str(int(w)))\n",
    "        except: pass\n",
    "    return result\n",
    "def toNum(word):\n",
    "    if word == 'point': return word\n",
    "    try: return w2n.word_to_num(word)\n",
    "    except:\n",
    "        return word\n",
    "\n",
    "def normalize_text(s):\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text): # additional: converting numbers to digit form\n",
    "        return \" \".join([str(toNum(w)) for w in text.split()])\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation) - set(['.'])\n",
    "        text1 = \"\".join(ch for ch in text if ch not in exclude)\n",
    "        return re.sub(r\"\\.(?!\\d)\", \"\", text1) # remove '.' if it's not a decimal point\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    def lemmatization(text):\n",
    "        return \" \".join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "    if len(s.strip()) == 1:\n",
    "        # accept article and punc if input is a single char\n",
    "        return white_space_fix(lower(s))\n",
    "    elif len(s.strip().split()) == 1: \n",
    "        # accept article if input is a single word\n",
    "        return lemmatization(white_space_fix(remove_punc(lower(s))))\n",
    "\n",
    "    return lemmatization(white_space_fix(remove_articles(remove_punc(lower(s)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'train': 17812, 'test': 4076, 'val': 2455})\n",
      "24343\n",
      "Counter({'train': 16448, 'test': 3464, 'val': 2511})\n",
      "Counter({'YesNo': 7430, 'Others': 5823, 'choose': 4693, 'number': 2084, 'color': 1832, 'shape': 561})\n",
      "Counter()\n",
      "22423\n"
     ]
    }
   ],
   "source": [
    "txt_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0823_clean_te.json\", \"r\"))\n",
    "img_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0823_clean_te.json\", \"r\"))\n",
    "\n",
    "print(Counter([txt_dataset[k]['split'] for k in txt_dataset]))\n",
    "print(len(set([txt_dataset[k]['Guid'] for k in txt_dataset])))\n",
    "\n",
    "print(Counter([img_dataset[k]['split'] for k in img_dataset]))\n",
    "print(Counter([img_dataset[k]['Qcate'] for k in img_dataset]))\n",
    "print(Counter([img_dataset[k]['Qcate'] for k in img_dataset if img_dataset[k]['split'] == 'ood_test']))\n",
    "print(len(set([img_dataset[k]['Guid'] for k in img_dataset])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 1366, 5: 1343, 4: 874, 3: 493})\n",
      "Counter({6: 1579, 5: 780, 4: 703, 3: 402})\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for k in txt_dataset:\n",
    "    if txt_dataset[k]['split'] == 'test':\n",
    "        x.append(len(txt_dataset[k]['A']))\n",
    "print(Counter(x))\n",
    "x = []\n",
    "for k in img_dataset:\n",
    "    if 'test' in img_dataset[k]['split']:\n",
    "        x.append(len(img_dataset[k]['A']))\n",
    "print(Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 同一个sample单独，最后取avg/max，RE<0.3的 full sentence 忽略\n",
    "### Double check on the clean_te version\n",
    "eval_f = Evaluate()\n",
    "bleu4_img_clean = {}\n",
    "RE_img_clean = {}\n",
    "F1_img_clean = {}\n",
    "mul_img_clean = {}\n",
    "\n",
    "drop = defaultdict(int)\n",
    "for k in img_dataset:\n",
    "    if not 'test' in img_dataset[k]['split']: continue\n",
    "    bleu4_img_clean[k] = []\n",
    "    RE_img_clean[k] = []\n",
    "    mul_img_clean[k] = []\n",
    "    F1_img_clean[k] = []\n",
    "    datum = img_dataset[k]\n",
    "    Keywords_A = datum['Keywords_A'].replace('\"', \"\")\n",
    "    all_A = [a.replace('\"', \"\") for a in datum['A']]\n",
    "    Qcate = img_dataset[k]['Qcate']\n",
    "    for i in range(len(all_A)):\n",
    "        Q = datum['Q'].replace('\"', \"\")\n",
    "        C = [all_A[i]]\n",
    "        A_list = all_A[:i] + all_A[i+1:]\n",
    "        scores = eval_f.evaluate(cand=[C], ref=[A_list], return_scores=True)\n",
    "        #print(scores)\n",
    "        \n",
    "        if Qcate == 'color': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", color_set)\n",
    "        elif Qcate == 'shape': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", shape_set)\n",
    "        elif Qcate == 'YesNo': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", yesno_set)\n",
    "        elif Qcate == 'number': F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A, \"\", {\"NUMBER\"})\n",
    "        else: F1_avg, F1_max, EM, RE_avg, PR_avg = compute_vqa_metrics(C, Keywords_A)\n",
    "        bleu4_img_clean[k].append(scores['Bleu_4'])\n",
    "        RE_img_clean[k].append(RE_avg)\n",
    "        F1_img_clean[k].append(F1_avg)\n",
    "        if Qcate in ['choose', 'Others']: mul_img_clean[k].append(RE_avg * scores['Bleu_4'])\n",
    "        else: mul_img_clean[k].append(F1_avg * scores['Bleu_4'])\n",
    "        \n",
    "    if len(RE_img_clean) % 500 == 499: print(len(RE_img_clean))\n",
    "assert len(RE_img_clean) == len(mul_img_clean) == len(bleu4_img_clean) == len(F1_img_clean)\n",
    "print(len(RE_img_clean))\n",
    "print(drop)\n",
    "print(np.sum(list(drop.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"bertscore\")\n",
    "def compute_bertscore(cands, a, model_type):\n",
    "    metric.add_batch(predictions = cands, references = [a]*len(cands))\n",
    "    score = metric.compute(model_type=model_type)\n",
    "    return np.mean(score['f1']), np.max(score['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00951297]\n",
      "[0.00951297]\n",
      "[0.77009736]\n",
      "(0.4098593592643738, 0.4098593592643738)\n"
     ]
    }
   ],
   "source": [
    "cands = [\"Beijing\"]\n",
    "a = [\"Yuzhny, which is an urban locality, is in the same district as Rytkuchi.\"]\n",
    "print(np.exp(bart_scorer.score(cands, a)))\n",
    "print(np.exp(bart_scorer.score(cands, a)))\n",
    "print(np.exp(bart_scorer.score(a, a)))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02257406]\n",
      "[0.00128582]\n",
      "[0.82900294]\n",
      "(0.37695783376693726, 0.37695783376693726)\n"
     ]
    }
   ],
   "source": [
    "cands = [\"Both Ireland and England\"]\n",
    "a = \"The Gilbert River that is a tributary of the Multnomah Channel on Sauvie Island shares its name with the Gilbert River that is a freshwater tributary of the Cyriac River.\"\n",
    "print(np.exp(bart_scorer.score(cands, [a])))\n",
    "print(np.exp(bart_scorer.score([a], cands)))\n",
    "print(np.exp(bart_scorer.score([a], [a])))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01384408]\n",
      "[0.03432885]\n",
      "[0.72917158]\n",
      "(0.5283754467964172, 0.5283754467964172)\n"
     ]
    }
   ],
   "source": [
    "cands = [\"It was made before\"] # Correct but too short\n",
    "a = \"The Gathering directed by Randal Kleiser was made before the Dutch rock band The Gathering had formed.\"\n",
    "print(np.exp(bart_scorer.score(cands, [a])))\n",
    "print(np.exp(bart_scorer.score([a], cands)))\n",
    "print(np.exp(bart_scorer.score([a], [a])))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55254496]\n",
      "[0.22784942]\n",
      "(0.9338558912277222, 0.9338558912277222)\n"
     ]
    }
   ],
   "source": [
    "# Another human reference\n",
    "cands = [\"The movie The Gathering directed by Randal Kleiser was made before the Dutch rock band The Gathering had formed\"]\n",
    "a = \"The Gathering directed by Randal Kleiser was made before the Dutch rock band The Gathering had formed.\"\n",
    "print(np.exp(bart_scorer.score(cands, [a])))\n",
    "print(np.exp(bart_scorer.score([a], cands)))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00817325]\n",
      "[0.00033844]\n",
      "(0.4296928644180298, 0.4296928644180298)\n"
     ]
    }
   ],
   "source": [
    "cands = [\"before\"]\n",
    "a = \"The Gathering directed by Randal Kleiser was made before the Dutch rock band The Gathering had formed.\"\n",
    "print(np.exp(bart_scorer.score(cands, [a])))\n",
    "print(np.exp(bart_scorer.score([a], cands)))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05339534]\n",
      "[0.0007564]\n",
      "(0.5756980776786804, 0.5756980776786804)\n"
     ]
    }
   ],
   "source": [
    "# Same sentence, disordered\n",
    "cands = [\"Dutch The by formed directed band before made was Randalthe rock Kleiser had The Gathering Gathering.\"]\n",
    "a = \"The Gathering directed by Randal Kleiser was made before the Dutch rock band The Gathering had formed.\"\n",
    "print(np.exp(bart_scorer.score(cands, [a])))\n",
    "print(np.exp(bart_scorer.score([a], cands)))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00566049]\n",
      "[0.00252041]\n",
      "(0.39895495772361755, 0.39895495772361755)\n"
     ]
    }
   ],
   "source": [
    "# An irrelevant candidate\n",
    "cands = [\"Both basketball and football\"]\n",
    "a = \"The Gathering directed by Randal Kleiser was made before the Dutch rock band The Gathering had formed.\"\n",
    "print(np.exp(bart_scorer.score(cands, [a])))\n",
    "print(np.exp(bart_scorer.score([a], cands)))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01736348]\n",
      "[0.12752726]\n",
      "(0.6037829518318176, 0.6037829518318176)\n"
     ]
    }
   ],
   "source": [
    "cands = ['Yamata No Orochi']\n",
    "a = \"Vampires have more power than Yamata No Orochi\"\n",
    "print(np.exp(bart_scorer.score(cands, [a])))\n",
    "print(np.exp(bart_scorer.score([a], cands)))\n",
    "print(compute_bertscore(cands, a, \"microsoft/deberta-xlarge-mnli\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/yingshac/CYS/WebQnA/VLP/BARTScore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bart_score import BARTScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_scorer = BARTScorer(device='cuda:0', checkpoint='facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8b4284f478e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbart_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'This is interesting.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'This is fun.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/yingshac/CYS/WebQnA/VLP/BARTScore/bart_score.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, srcs, tgts, batch_size)\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     )\n\u001b[0;32m---> 62\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "bart_scorer.score(['This is interesting.'], ['This is fun.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BARTScore",
   "language": "python",
   "name": "bartscore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
