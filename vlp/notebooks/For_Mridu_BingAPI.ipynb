{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict \n",
    "from pytz import timezone\n",
    "import json\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import os.path\n",
    "import urllib.parse\n",
    "from urllib.parse import quote\n",
    "import urllib.request\n",
    "from IPython import display\n",
    "from azure.cognitiveservices.search.visualsearch import VisualSearchClient\n",
    "from azure.cognitiveservices.search.visualsearch.models import (\n",
    "    VisualSearchRequest,\n",
    "    CropArea,\n",
    "    ImageInfo,\n",
    "    Filters,\n",
    "    KnowledgeRequest,\n",
    ")\n",
    "from msrest.authentication import CognitiveServicesCredentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Pricing: https://azure.microsoft.com/en-us/pricing/details/cognitive-services/search-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Insights API\n",
    "subscription_key = \"0a71d4ad9ae84586bf712a4204288dbe\" # S9 pricing tier,  COST: $3 per 1,000 transactions\n",
    "visual_url = \"https://api.bing.microsoft.com/v7.0/images/visualsearch\"\n",
    "headers = {\"Ocp-Apim-Subscription-Key\" : subscription_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Search API\n",
    "imgSearch_subscription_key = \"aab34a07c6724b078e275a8e2dece7f2\" # S3 pricing tierï¼ŒCOST: $4 per 1,000 transactions\n",
    "search_url = \"https://api.bing.microsoft.com/v7.0/images/search\"\n",
    "imgSearch_headers = {\"Ocp-Apim-Subscription-Key\" : imgSearch_subscription_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contentUrl_to_displayUrl(contentUrl):\n",
    "    prefix = 'https://commons.wikimedia.org/wiki/'\n",
    "    tokens = contentUrl.split('/')\n",
    "    if 'px-' in tokens[-1]:\n",
    "        return prefix + 'File:'+tokens[-2]\n",
    "    else:\n",
    "        return prefix + 'File:'+tokens[-1]\n",
    "def get_description_by_url(desurl):\n",
    "    try:\n",
    "        with urllib.request.urlopen(desurl) as f:\n",
    "            html = f.read().decode('utf-8')\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        #print(desurl)\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    result = soup.find_all('div',class_= \"description mw-content-ltr en\", limit=1)\n",
    "    des = \" \"\n",
    "    for r in result:\n",
    "        soup_short = BeautifulSoup(str(r), 'html.parser')\n",
    "        for row in soup_short.prettify().split('\\n'):\n",
    "            if not \"<\" in row:\n",
    "                des += row.strip()\n",
    "        des += '\\n'\n",
    "    return des\n",
    "\n",
    "def get_filename_and_hash_by_url(desurl):\n",
    "    filename = urllib.parse.unquote(desurl).split(\"/\")[-1].replace(\"File:\", \"\").replace(\".jpg\", \"\")\n",
    "    _hash = hash(filename)\n",
    "    return (filename, _hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_imgUrl(imgUrl):\n",
    "    if not \"/thumb/\" in imgUrl:\n",
    "        filename = imgUrl.split(\"/\")[-1]\n",
    "        sep = imgUrl.find(\"wikipedia/commons/\") + len(\"wikipedia/commons/\")\n",
    "        return imgUrl[:sep] + \"thumb/\" + imgUrl[sep:] + \"/800px-\" + filename\n",
    "    else:\n",
    "        filename = imgUrl.split(\"/\")[-2]\n",
    "        sep = imgUrl.find(filename) + len(filename)\n",
    "        last = imgUrl.split(\"/\")[-1]\n",
    "        n = last[:last.find(\"px-\")]\n",
    "        try:\n",
    "            if int(n) <= 800:\n",
    "                return imgUrl\n",
    "            else: \n",
    "                return imgUrl[:sep] + \"/800px-\" + filename\n",
    "        except:\n",
    "            return imgUrl[:sep] + \"/800px-\" + filename\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayUrl_to_imgUrl(displayUrl, drop = False):\n",
    "    try:\n",
    "        with urllib.request.urlopen(displayUrl) as f:\n",
    "            html = f.read().decode('utf-8')\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        #print(\"can't open url: \", displayUrl)\n",
    "        return \"CANNOT_FOUND\"\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    result = soup.find_all('a',class_= \"mw-thumbnail-link\", limit=10)\n",
    "    idx = 0\n",
    "    default = \"\"\n",
    "    for r in result:\n",
    "        soup_short = BeautifulSoup(str(r), 'html.parser')\n",
    "        for a in soup_short.find_all('a', href=True):\n",
    "            href = a['href']\n",
    "            if idx == 0: \n",
    "                default = a['href']\n",
    "                idx += 1\n",
    "            if '800px' in href:\n",
    "                return href\n",
    "    if len(default)>0: return default\n",
    "    else:\n",
    "        if drop:\n",
    "            print(\"DROP\")\n",
    "            return \"CANNOT_FOUND\"\n",
    "        else:\n",
    "            result = soup.find_all('div',class_= \"fullImageLink\", limit=1)\n",
    "            for r in result:\n",
    "                soup_short = BeautifulSoup(str(r), 'html.parser')\n",
    "                for im in soup_short.find_all('img'):\n",
    "                    if max(int(im['width']), int(im['height']))>=600 and min(int(im['width']), int(im['height']))>=400:\n",
    "                        return im['src']\n",
    "                    return \"SIZE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter(contentUrl):\n",
    "    url_blocklist = ['seal', 'sign ', 'pdf', 'gif', 'icon', 'notice', 'cartoon', 'publish', 'menu', 'logo', 'svg', 'webm', 'cover', 'page', \\\n",
    "                     'ogg', 'album', 'flickr', 'poster', 'ogv', 'banner', 'tif', 'montage']\n",
    "    \n",
    "    \n",
    "    # Restrict to Wikimedia images\n",
    "    if not contentUrl.startswith('https://upload.wikimedia.org/wikipedia/'): return False, \"\", \"\", \"\", \"wrong prefix\"\n",
    "    \n",
    "    displayUrl = contentUrl_to_displayUrl(contentUrl)\n",
    "    description = get_description_by_url(displayUrl).replace(\"English:\", \"\").strip('\\n')\n",
    "    concat_url_des = \" \"+displayUrl+description+\" \"\n",
    "    \n",
    "    # Avoid images with bad keywords\n",
    "    if any(b in concat_url_des for b in url_blocklist): return False, \"\", \"\", \"\", \"keyword\"\n",
    "    \n",
    "    # Avoid images with \"18xx, 17xx, 16xx\", which probably indicates the image is old\n",
    "    #regex = re.compile('.*\\D(18|17|16)\\d{2}\\D.*')\n",
    "    #if not re.match(regex, concat_url_des)==None: return False, \"\", \"\", \"\", \"year\"\n",
    "    imgUrl = displayUrl_to_imgUrl(displayUrl, drop=False)\n",
    "    if imgUrl == 'CANNOT_FOUND' or imgUrl=='SIZE': return False, \"\", \"\", \"\", imgUrl\n",
    "    \n",
    "    imgUrl = update_imgUrl(imgUrl) \n",
    "    # This is kind of tedious since both \"displayUrl_to_imgUrl\" and \"update_imgUrl\" are updating the image src\n",
    "    # I used \"displayUrl_to_imgUrl()\" at first and find that it can return image sizes but does not process src urls correctly. \n",
    "    # So I added \"update_imgUrl()\" later\n",
    "    return True, displayUrl, description, imgUrl, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_querySuggestion(imgUrl, PRINT=False):\n",
    "    data_dict = {\n",
    "       \"imageInfo\" : {\n",
    "            \"url\" : \"{}\".format(imgUrl),\n",
    "            \n",
    "        },\n",
    "        \"knowledgeRequest\": {\n",
    "            \"filters\" : {\n",
    "              \"site\" : \"wikimedia.org\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    data_json = json.dumps(data_dict, indent = 4)\n",
    "    files = {'knowledgeRequest': ('imageInfo', data_json)}\n",
    "    try:\n",
    "        response = requests.post(visual_url, headers=headers, files=files)\n",
    "        # COST: $3 per 1,000 transactions\n",
    "        if PRINT: print_json(response.json())\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        ## Print related queries\n",
    "        expansion = {'RelatedSearches': [], 'DocumentLevelSuggestions': [], 'BestRepresentativeQuery': []}\n",
    "        for actn in response.json()['tags'][0]['actions']:\n",
    "            if 'RelatedSearches' in actn['actionType']:\n",
    "                for rs in actn['data']['value']:\n",
    "                    expansion['RelatedSearches'].append(rs['displayText'])\n",
    "            if 'DocumentLevelSuggestions' in actn['actionType']:\n",
    "                for rs in actn['data']['value']:\n",
    "                    expansion['DocumentLevelSuggestions'].append(rs['displayText'])\n",
    "            if 'BestRepresentativeQuery' in actn['actionType']:\n",
    "                expansion['BestRepresentativeQuery'].append(actn['displayName'])\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        return {'RelatedSearches': [], 'DocumentLevelSuggestions': [], 'BestRepresentativeQuery': []}\n",
    "    return expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Args:\n",
    "    search_term (str)\n",
    "Return:\n",
    "    new_queries (list)\n",
    "'''\n",
    "def expand_query(search_term, PRINT=False):\n",
    "    if PRINT: print(search_term)\n",
    "    \n",
    "    params  = {\"q\": search_term, \"license\": \"ModifyCommercially\", \"imageType\": \"photo\"}\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=imgSearch_headers, params=params)\n",
    "        # COST: $4 per 1,000 transactions\n",
    "    except:\n",
    "        print(\"Error when search using: \", search_term)\n",
    "        raise\n",
    "    while response.status_code == 429 or response.status_code == 403:\n",
    "        time.sleep(2)\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "    \n",
    "    new_queries = set([])\n",
    "    \n",
    "    # Avoid queries with bad keywords\n",
    "    q_blocklist = ['flickr', 'logo', 'wikimedia', \"quote\", \"clip art\", \"map\", \"card\", \"illustration\", \"drawing\", \"worksheet\", \"symbol\",\\\n",
    "                   \"icon\", \"paper\", \"tv\", \"cloth\", \"cartoon\", \"gif\", \"album\", \"sign\"]\n",
    "        \n",
    "    if 'queryExpansions' in list(search_results.keys()):\n",
    "        for qe in search_results['queryExpansions']:\n",
    "            if any(b in qe['text'].lower() for b in q_blocklist): continue\n",
    "            if not qe['text'] in new_queries:\n",
    "                new_queries.add(qe['text'])\n",
    "        \n",
    "    if 'pivotSuggestions' in list(search_results.keys()):\n",
    "        for pivot in search_results['pivotSuggestions']:\n",
    "            for sug in pivot['suggestions']:\n",
    "                if any(b in sug['text'].lower() for b in q_blocklist): continue\n",
    "                if not sug['text'] in new_queries:\n",
    "                    new_queries.add(sug['text'])\n",
    "    if 'relatedSearches' in list(search_results.keys()):\n",
    "        for rs in search_results[\"relatedSearches\"]:\n",
    "            if any(b in rs['text'].lower() for b in q_blocklist): continue\n",
    "            if not rs['text'] in new_queries:\n",
    "                new_queries.add(rs['text'])\n",
    "    \n",
    "    if PRINT: print(len(new_queries))\n",
    "    new_queries - set('search_term')\n",
    "    return new_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Args:\n",
    "    imgUrl: src url of the anchor image\n",
    "    count: number of visually similar images to return\n",
    "    last: The returned list of the API call arrange images by visual similarity. \n",
    "        However, we don't want the distrator to be too similar to the gold img. So a bunch of top ones should be skipped.\n",
    "        E.g. count = 10, last = 20, this function will return visually similar images with rank 11-20.\n",
    "\n",
    "Return:\n",
    "    similar_images.keys(): a list of src urls\n",
    "    similar_images: a dict where keys are src urls and values are wikimedia page urls\n",
    "    \n",
    "'''\n",
    "def search_visually_similar_late(imgUrl, count, last = 20, PRINT = False):\n",
    "    data_dict = {\n",
    "       \"imageInfo\" : {\n",
    "            \"url\" : \"{}\".format(imgUrl),\n",
    "            \n",
    "        },\n",
    "        \"knowledgeRequest\": {\n",
    "            \"filters\" : {\n",
    "              \"site\" : \"wikimedia.org\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    data_json = json.dumps(data_dict, indent = 4)\n",
    "    #pprint(data_json)\n",
    "    files = {'knowledgeRequest': ('imageInfo', data_json)}\n",
    "    similar_images = {}\n",
    "    try:\n",
    "        response = requests.post(visual_url, headers=headers, files=files)\n",
    "        # COST: $3 per 1,000 transactions\n",
    "        if PRINT: print_json(response.json())\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        for actn in response.json()['tags'][0]['actions']:\n",
    "            if 'VisualSearch' in actn['actionType']:\n",
    "                length = len(actn['data']['value'])\n",
    "                if length < count-1:\n",
    "                    #print(length, imgUrl)\n",
    "                    for i in range(length):\n",
    "                        similar_images[actn['data']['value'][i]['contentUrl']] = actn['data']['value'][i]['hostPageUrl']\n",
    "                elif length<last:\n",
    "                    for i in range(length-count, length):\n",
    "                        similar_images[actn['data']['value'][i]['contentUrl']] = actn['data']['value'][i]['hostPageUrl']\n",
    "                else:\n",
    "                    for i in range(last-count, last):\n",
    "                        similar_images[actn['data']['value'][i]['contentUrl']] = actn['data']['value'][i]['hostPageUrl']\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        print(\"Error in when searching visually similar images: \", imgUrl)\n",
    "        return [], {}\n",
    "    return list(similar_images.keys()), similar_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Args:\n",
    "    query (str): search term\n",
    "    num_results_api: number of images returned by API \n",
    "        (should be greater than 'max_search_result_per_query' since some images will be filtered out)\n",
    "Return:\n",
    "    d (dict): key is img filename, values are imgUrl, Wikimedia page url, and description\n",
    "    bad_img_statistics (Counter): Store the reason why some bad images are dropped. \n",
    "        E.g. not from Wikimedia; img size too small; bad keywords; etc\n",
    "    bad_query_statistics (Counter): Store the reason why a search term is bad\n",
    "        I used bad_query_statistics to flag bad topics that won't yield interesting images when I was mining image prompts for MTurk\n",
    "'''\n",
    "\n",
    "def seed_to_img(query, max_search_result_per_query, min_search_result_per_query, num_results_api=35, site = \"\", print_error_detail=False):\n",
    "    d = {}\n",
    "    params  = {\"q\": query+site, \"license\": \"ModifyCommercially\", \"imageType\": \"photo\", \"count\": num_results_api}\n",
    "\n",
    "    response = requests.get(search_url, headers=imgSearch_headers, params=params)\n",
    "    # COST: $4 per 1,000 transactions\n",
    "    while response.status_code == 429 or response.status_code == 403:\n",
    "        print(\"sleep 2 seconds\")\n",
    "        time.sleep(2)\n",
    "        response = requests.get(search_url, headers=imgSearch_headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "    \n",
    "    url_blocklist = ['seal', 'sign', 'pdf', 'gif', 'icon', 'notice', 'cartoon', 'publish', 'menu', 'logo', 'svg', 'webm', 'cover', 'page', \\\n",
    "                     'ogg', 'album', 'flickr', 'poster', 'ogv', 'banner', 'tif']\n",
    "    \n",
    "    search_result = 0\n",
    "    conse_fail = 0\n",
    "    fail = 0\n",
    "    bad_img_statistics = Counter()\n",
    "    bad_query_statistics = Counter()\n",
    "    for img in search_results[\"value\"]:\n",
    "        \n",
    "        contentUrl = img['contentUrl']\n",
    "        page = img['hostPageUrl']\n",
    "        #print(\"returned by api: \",contentUrl)\n",
    "        if contentUrl.startswith('http://'):\n",
    "            contentUrl = contentUrl[:4]+\"s\"+contentUrl[4:]\n",
    "        \n",
    "        # Filter out bad images, get filename, description, update imgUrl\n",
    "        valid, displayUrl, description, imgUrl, drop_reason= img_filter(contentUrl)\n",
    "        \n",
    "        if not valid: \n",
    "            if print_error_detail: print(drop_reason+\" \"+page)\n",
    "            bad_img_statistics[drop_reason] += 1\n",
    "            continue\n",
    "        conse_fail = 0\n",
    "        key, _hash = get_filename_and_hash_by_url(displayUrl)\n",
    "        d[key] = {}\n",
    "        d[key]['displayUrl'] = displayUrl\n",
    "        d[key]['imgUrl'] = imgUrl\n",
    "        # I tried to use hash(filename) or timestamp as img unique identifier but it turned out to be a bad idea\n",
    "        #d[key]['_hash'] = _hash\n",
    "        #d[key]['timestamp'] = datetime.now(tz=timezone('US/Eastern')).strftime(\"%y%m%d%H%M%S%f\")\n",
    "        d[key]['des'] = description\n",
    "        \n",
    "        if len(d) >= max_search_result_per_query: break\n",
    "    \n",
    "    if len(d) < min_search_result_per_query: \n",
    "        bad_query_statistics['too_few_survivors'] += 1\n",
    "        return {}, bad_img_statistics, bad_query_statistics\n",
    "    #print(\"Finish search for \", query)\n",
    "    return d, bad_img_statistics, bad_query_statistics  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Term --> Imgs (via image search API)\n",
    "https://docs.microsoft.com/en-us/bing/search-apis/bing-image-search/quickstarts/rest/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong prefix http://wiki.minetest.net/Flint_and_Steel\n",
      "wrong prefix http://flickr.com/photos/schwuk/3195851605\n",
      "wrong prefix http://wiki.minetest.net/Flint_and_Steel\n",
      "wrong prefix http://skyquazatheairrider.deviantart.com/art/Terraria-1-2-honey-fountain-3-405074790\n",
      "CANNOT_FOUND https://en.wikipedia.org/wiki/Tinderbox\n",
      "wrong prefix https://www.flickr.com/photos/22616984@N07/7785234602/\n",
      "wrong prefix http://mineblocks.com/1/wiki/index?title=File:Flint.png\n",
      "wrong prefix https://mineblocks.com/1/wiki/index.php?title=Flint\n",
      "wrong prefix https://www.vitantica.net/2018/01/16/acciarino-antico-moderno/\n",
      "wrong prefix http://wiki.minetest.net/Flint\n",
      "wrong prefix https://klexikon.zum.de/wiki/Datei:Flint_wall,_West_Winterslow_-_geograph.org.uk_-_889238.jpg\n",
      "wrong prefix https://www.flickr.com/photos/martin7d2/29851186244\n",
      "wrong prefix http://j1nzo.deviantart.com/art/Charizard-Sprite-205307739\n",
      "wrong prefix http://gaming.stackexchange.com/questions/29789/through-what-ways-can-tnt-be-ignited\n",
      "wrong prefix https://www.geograph.org.uk/photo/2614598\n",
      "dict_keys(['Flint_&_Steel_Guesthouse_entrance.JPG', 'Flint_and_tinder_box_(AM_1965.78.196-6)', 'Old_tinderboxes', 'Flint_spark_lighter_striking', 'Briquets', 'Firesteels_assorted', 'Brick_and_flint,_Piddletrenthide_-_geograph.org.uk_-_1066406', 'Tinder_box_with_striker_and_flint,_Ludlow_Museum_-_DSCF2123.JPG', 'Camp_Fire_for_making_Char_cloth', 'Eldslagning_-_Nordiska_museet_-_NMA.0051717'])\n",
      "{'Flint_&_Steel_Guesthouse_entrance.JPG': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Flint_%26_Steel_Guesthouse_entrance.JPG', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Flint_%26_Steel_Guesthouse_entrance.JPG/800px-Flint_%26_Steel_Guesthouse_entrance.JPG', 'des': ' Flint&amp;Steel Guesthouse entrance, Ku-ring-gai Chase National Park, NSW, Australia.'}, 'Flint_and_tinder_box_(AM_1965.78.196-6)': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Flint_and_tinder_box_%28AM_1965.78.196-6%29.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Flint_and_tinder_box_%28AM_1965.78.196-6%29.jpg/706px-Flint_and_tinder_box_%28AM_1965.78.196-6%29.jpg', 'des': ' Flint and tinder box brought to new Zealand in \"the early days\" round metal tinder box containing flint metal cylinder with lid and handle; lid with possible candle holder; top and middle part lifts off'}, 'Old_tinderboxes': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Old_tinderboxes.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Old_tinderboxes.jpg/800px-Old_tinderboxes.jpg', 'des': ' Old tinderboxesOther informationFrom a private collection'}, 'Flint_spark_lighter_striking': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Flint_spark_lighter_striking.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Flint_spark_lighter_striking.jpg/645px-Flint_spark_lighter_striking.jpg', 'des': ' '}, 'Briquets': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Briquets.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Briquets.jpg/569px-Briquets.jpg', 'des': ' Firesteels, Britanny, late 18th century'}, 'Firesteels_assorted': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Firesteels_assorted.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Firesteels_assorted.jpg/450px-Firesteels_assorted.jpg', 'des': ' Four firesteels. Reproductions. Typical of Roman through medival period.'}, 'Brick_and_flint,_Piddletrenthide_-_geograph.org.uk_-_1066406': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Brick_and_flint%2C_Piddletrenthide_-_geograph.org.uk_-_1066406.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Brick_and_flint%2C_Piddletrenthide_-_geograph.org.uk_-_1066406.jpg/800px-Brick_and_flint%2C_Piddletrenthide_-_geograph.org.uk_-_1066406.jpg', 'des': ' Brick and flint, Piddletrenthide A range of brick, flint and thatched cottages opposite the Piddle Inn.'}, 'Tinder_box_with_striker_and_flint,_Ludlow_Museum_-_DSCF2123.JPG': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Tinder_box_with_striker_and_flint%2C_Ludlow_Museum_-_DSCF2123.JPG', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Tinder_box_with_striker_and_flint%2C_Ludlow_Museum_-_DSCF2123.JPG/450px-Tinder_box_with_striker_and_flint%2C_Ludlow_Museum_-_DSCF2123.JPG', 'des': ' '}, 'Camp_Fire_for_making_Char_cloth': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Camp_Fire_for_making_Char_cloth.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Camp_Fire_for_making_Char_cloth.jpg/450px-Camp_Fire_for_making_Char_cloth.jpg', 'des': ' Camp Fire for making Char cloth'}, 'Eldslagning_-_Nordiska_museet_-_NMA.0051717': {'displayUrl': 'https://commons.wikimedia.org/wiki/File:Eldslagning_-_Nordiska_museet_-_NMA.0051717.jpg', 'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Eldslagning_-_Nordiska_museet_-_NMA.0051717.jpg/442px-Eldslagning_-_Nordiska_museet_-_NMA.0051717.jpg', 'des': ' '}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d, _, __ = seed_to_img(\"flint and steel\", 10, 5, print_error_detail=True)\n",
    "print(d.keys())\n",
    "print(d)\n",
    "print()\n",
    "#pprint(list(d.items())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Term --> More related queries (via image search API)\n",
    "https://docs.microsoft.com/en-us/bing/search-apis/bing-image-search/quickstarts/rest/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Best Seattle Skyline Space Needle',\n",
       " 'Big Ben',\n",
       " 'CN Tower',\n",
       " 'Diagram of Seattle Space Needle',\n",
       " 'Empire State Building',\n",
       " 'Gateway Arch',\n",
       " 'Golden Gate Bridge',\n",
       " 'Hoover Dam',\n",
       " 'Liberty Bell',\n",
       " 'Mount Rainier',\n",
       " 'Mount Rushmore National Memorial',\n",
       " 'One World Trade Center',\n",
       " 'Seattle Center',\n",
       " 'Seattle Great Wheel',\n",
       " 'Seattle Seahawks Space Needle',\n",
       " 'Seattle Space Needle Art',\n",
       " 'Seattle Space Needle Construction',\n",
       " 'Seattle Space Needle Fire',\n",
       " 'Seattle Space Needle History',\n",
       " 'Seattle Space Needle Night',\n",
       " 'Seattle Space Needle Outline',\n",
       " 'Seattle Space Needle Paintings',\n",
       " 'Seattle Space Needle Restaurant Menu',\n",
       " 'Seattle Space Needle Silhouette',\n",
       " 'Seattle Space Needle Skyline',\n",
       " 'Seattle Space Needle Top',\n",
       " 'Seattle Space Needle Tour',\n",
       " 'Seattle Tower Space Needle',\n",
       " 'Space Needle Building',\n",
       " 'Space Needle Dimensions',\n",
       " 'Space Needle Fireworks',\n",
       " 'Space Needle Height',\n",
       " 'Space Needle Observation Deck',\n",
       " 'Space Needle Seattle United States',\n",
       " 'Space Needle Seattle WA',\n",
       " 'Space Needle Seattle Washington',\n",
       " 'Space Needle Sketch',\n",
       " 'Space Needle Sunset',\n",
       " 'Space Needle Tower',\n",
       " 'Starbucks',\n",
       " 'Stratosphere Las Vegas',\n",
       " 'Sydney Opera House',\n",
       " 'TOKYO SKYTREE',\n",
       " 'Tower Of The Americas',\n",
       " 'View From Seattle Space Needle',\n",
       " 'Visit Seattle Space Needle',\n",
       " 'Washington Monument',\n",
       " 'Washington Space Needle',\n",
       " 'Willis Tower'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_query(\"Seattle Space Needle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Img --> Related searches (via image insights API)\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/bing-image-search/quickstarts/python\n",
    "\n",
    "Not every image have RelatedSearches. More than 60% of the imgs actually get empty fields from this API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BestRepresentativeQuery': [],\n",
       " 'DocumentLevelSuggestions': [],\n",
       " 'RelatedSearches': ['Carnegie Mellon Campus',\n",
       "  'Carnegie Mellon Campus Map',\n",
       "  'Carnegie Mellon University Map',\n",
       "  'Carnegie Mellon University Dorms',\n",
       "  'Carnegie Mellon Logo',\n",
       "  'Carnegie Mellon Robotics',\n",
       "  'Carnegie Mellon University Computer Science',\n",
       "  'Carnegie Mellon Students',\n",
       "  'Carnegie Mellon University Qatar',\n",
       "  'Carnegie Mellon Buildings',\n",
       "  'Carnegie Mellon University Mascot',\n",
       "  'Carnegie Mellon University Engineering',\n",
       "  'Carnegie Mellon University Tepper',\n",
       "  'Carnegie Mellon University Location',\n",
       "  'Carnegie Mellon Seal',\n",
       "  'Carnegie Mellon University School of Computer Science',\n",
       "  'CMU Pittsburgh',\n",
       "  'Carnegie Mellon University Library',\n",
       "  'Carnegie Mellon University Australia',\n",
       "  'Pittsburgh PA Carnegie Mellon',\n",
       "  'Robotics Institute Carnegie Mellon University',\n",
       "  'Tepper School of Business',\n",
       "  'Carnegie Mellon University Symbol',\n",
       "  'Carnegie Mellon College',\n",
       "  'Carnegie Mellon Wallpaper',\n",
       "  'Pennsylvania Carnegie Mellon',\n",
       "  'Carnegie Tech']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_querySuggestion(\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/CMU_from_36th_floor.jpg/834px-CMU_from_36th_floor.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Img --> Visually Similar Images (via image insights API)\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/bing-image-search/quickstarts/python\n",
    "\n",
    "\n",
    "Apply **img_filter()** to the imgUrls of visually similar images if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "http://commons.wikimedia.org/wiki/file:kelvingrove_art_gallery_and_museum_from_the_university_of_glasgow_tower.jpg\n"
     ]
    }
   ],
   "source": [
    "imgUrl = \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/CMU_from_36th_floor.jpg/834px-CMU_from_36th_floor.jpg\"\n",
    "similar_urls, similar_images = search_visually_similar_late(imgUrl, 10, 20)\n",
    "print(type(similar_images))\n",
    "print(similar_images[similar_urls[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which occurred first: the Debra Dean character appearing on East Enders or the airing of the first episode from the 22nd season of Home and Away?\"\n",
    "fact = \"As the series progresses, it is revealed that Diva has five chevaliers to aid her: Amshel Goldsmith, Solomon Goldsmith, Karl Fei-Ong, James Ironside, and Nathan Mahler. They have formed their own organization, Cinq Fl\\u00e8ches, which they use to create additional chiropterans from Diva's blood.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = ['NN', 'NNP', 'NNS', 'NNPS']# 'VB', 'VBD', 'VBG', 'VBP', 'VBZ', 'JJ','JJR', 'JJS', 'RB', 'RBR', 'RBS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series progresses, Diva chevaliers her: Amshel Goldsmith, Solomon Goldsmith, Karl Fei-Ong, James Ironside, Nathan Mahler. organization, Cinq FlÃ¨ches, chiropterans Diva's blood.\n",
      "Debra Dean character East Enders airing episode season Home Away?\n"
     ]
    }
   ],
   "source": [
    "s = \" \".join([x[0] for x in nltk.pos_tag(fact.split()) if x[1] in pos_tags])\n",
    "print(s)\n",
    "s = \" \".join([x[0] for x in nltk.pos_tag(question.split()) if x[1] in pos_tags])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned by api:  https://upload.wikimedia.org/wikipedia/it/thumb/5/54/Amshel_Goldsmith.jpg/260px-Amshel_Goldsmith.jpg\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:Amshel_Goldsmith.jpg\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/it/5/54/Amshel_Goldsmith.jpg\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:Amshel_Goldsmith.jpg\n",
      "returned by api:  https://static.miraheze.org/allthetropeswiki/3/3b/Amshel01_1253.png\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/en/thumb/e/e1/All_Diva's_Chevaliers.png/220px-All_Diva's_Chevaliers.png\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:All_Diva's_Chevaliers.png\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/en/thumb/e/e1/All_Diva's_Chevaliers.png/330px-All_Diva's_Chevaliers.png\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:All_Diva's_Chevaliers.png\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/it/thumb/f/f0/David_Blood.jpg/220px-David_Blood.jpg\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:David_Blood.jpg\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/en/thumb/4/42/Sannin_Schiff.png/330px-Sannin_Schiff.png\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:Sannin_Schiff.png\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/en/thumb/4/42/Sannin_Schiff.png/220px-Sannin_Schiff.png\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:Sannin_Schiff.png\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/hu/thumb/3/39/Saya_to_Tomodachi.png/350px-Saya_to_Tomodachi.png\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:Saya_to_Tomodachi.png\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/hu/thumb/8/88/Blood_plus_004.jpg/375px-Blood_plus_004.jpg\n",
      "can't open url:  https://commons.wikimedia.org/wiki/File:Blood_plus_004.jpg\n",
      "returned by api:  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Oded_Goldreich.jpg/220px-Oded_Goldreich.jpg\n",
      "returned by api:  https://static.miraheze.org/allthetropeswiki/3/3b/Saya02_4087.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({},\n",
       " Counter({'CANNOT_FOUND': 9, 'SIZE': 1, 'wrong prefix': 2}),\n",
       " Counter({'too_few_survivors': 1}))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_to_img(\"Amshel Goldsmith\", 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
