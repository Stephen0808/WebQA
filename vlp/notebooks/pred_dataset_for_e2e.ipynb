{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json, random, os, copy, time\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'train': 17812, 'test': 4076, 'val': 2455})\n",
      "24343\n",
      "Counter({'train': 18954, 'test': 3464, 'val': 2511})\n",
      "Counter({'YesNo': 8255, 'Others': 6470, 'choose': 5201, 'number': 2318, 'color': 2058, 'shape': 627})\n",
      "24929\n"
     ]
    }
   ],
   "source": [
    "txt_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0904_clean_fields.json\", \"r\"))\n",
    "img_dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0904_clean_fields.json\", \"r\"))\n",
    "\n",
    "print(Counter([txt_dataset[k]['split'] for k in txt_dataset]))\n",
    "print(len(set([txt_dataset[k]['Guid'] for k in txt_dataset])))\n",
    "\n",
    "print(Counter([img_dataset[k]['split'] for k in img_dataset]))\n",
    "print(Counter([img_dataset[k]['Qcate'] for k in img_dataset]))\n",
    "print(len(set([img_dataset[k]['Guid'] for k in img_dataset])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24929 24343\n"
     ]
    }
   ],
   "source": [
    "img_guid2k = dict([(img_dataset[k]['Guid'], k) for k in img_dataset])\n",
    "txt_guid2k = dict([(txt_dataset[k]['Guid'], k) for k in txt_dataset])\n",
    "print(len(img_guid2k), len(txt_guid2k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_dataset(TH, output_dir, filename, guid2k, dataset):\n",
    "    pred_dataset = {}\n",
    "    count = 0\n",
    "    filter_pred_json = json.load(open(os.path.join(output_dir, filename), \"r\"))\n",
    "    for guid in filter_pred_json:\n",
    "        num_choices = len(filter_pred_json[guid]['choices'])\n",
    "        pred_scores = np.array(filter_pred_json[guid]['pred_scores'][:num_choices], dtype=float) # > th\n",
    "\n",
    "        assert len(pred_scores) == num_choices\n",
    "\n",
    "        pred_choices = [(filter_pred_json[guid]['choices'][i], pred_scores[i]) for i in range(num_choices) if pred_scores[i] >= TH]\n",
    "        #pprint(pred_choices)\n",
    "        pred_choices = sorted(pred_choices, key=lambda x: x[1], reverse=True)\n",
    "        #pprint(pred_choices)\n",
    "        try: k = guid2k[guid]\n",
    "        except: k = guid\n",
    "        pred_dataset[k] = copy.deepcopy(dataset[k])\n",
    "        \n",
    "        try: imgFacts = copy.deepcopy(dataset[k]['img_posFacts'] + dataset[k]['img_negFacts'])\n",
    "        except: imgFacts = copy.deepcopy(dataset[k]['img_negFacts'])\n",
    "        try: txtFacts = copy.deepcopy(dataset[k]['txt_posFacts'] + dataset[k]['txt_negFacts'])\n",
    "        except: txtFacts = copy.deepcopy(dataset[k]['txt_negFacts'])\n",
    "        img_id2f = dict([(str(f['image_id']), copy.deepcopy(f)) for f in imgFacts])\n",
    "        #print(img_id2f.keys())\n",
    "        txt_fact2f = dict([(\"\".join(f['snippet_id'].split()), copy.deepcopy(f)) for f in txtFacts])\n",
    "        #print(txt_fact2f)\n",
    "        pred_dataset[k]['img_posFacts'] = []\n",
    "        pred_dataset[k]['txt_posFacts'] = []\n",
    "        for c in pred_choices:\n",
    "            try: \n",
    "                image_id = str(int(c[0]))\n",
    "                if len(image_id)<8: image_id = \"0\"*(8-len(image_id)) + image_id\n",
    "                f = copy.deepcopy(img_id2f[image_id])\n",
    "                f['filter_conf'] = c[1]\n",
    "                pred_dataset[k]['img_posFacts'].append(f)\n",
    "            except:\n",
    "                f = copy.deepcopy(txt_fact2f[\"\".join(c[0].split())])\n",
    "                f['filter_conf'] = c[1]\n",
    "                pred_dataset[k]['txt_posFacts'].append(f)\n",
    "        count += 1\n",
    "    print(count)\n",
    "    print(len(pred_dataset))\n",
    "    return pred_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4076\n",
      "4076\n"
     ]
    }
   ],
   "source": [
    "# TXT\n",
    "output_dir = \"/home/yingshac/CYS/WebQnA/VLP/vlp/light_output/filter_both_x_detectron_upd/\"\n",
    "filename = \"test_-1_step3_txt_20_True_txt_dataset_0904_clean_fields_UNknown_modality.json\"\n",
    "TH=0.2 # _upd version\n",
    "pred_dataset = create_pred_dataset(TH, output_dir, filename, txt_guid2k, txt_dataset)\n",
    "json.dump(pred_dataset, open(os.path.join(output_dir, \"{}_th{}_{}\".format(\"pred_dataset\", str(TH).split(\".\")[-1], filename)), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3464\n",
      "3464\n"
     ]
    }
   ],
   "source": [
    "# IMG\n",
    "output_dir = \"/home/yingshac/CYS/WebQnA/VLP/vlp/light_output/filter_both_x_detectron_upd/\"\n",
    "filename = \"test_-1_step3_img_20_True_True_img_dataset_0904_clean_fields_UNknown_modality.json\"\n",
    "TH=0.2 # _upd version\n",
    "pred_dataset = create_pred_dataset(TH, output_dir, filename, img_guid2k, img_dataset)\n",
    "json.dump(pred_dataset, open(os.path.join(output_dir, \"{}_th{}_{}\".format(\"pred_dataset\", str(TH).split(\".\")[-1], filename)), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/yingshac/CYS/WebQnA/VLP/vlp/light_output/filter_both_x_vinvl/\"\n",
    "filename = \"test_-1_step3_img_16_True_True_img_dataset_0823_clean_te_UNknown_modality.json\"\n",
    "tmp = json.load(open(os.path.join(output_dir, filename), \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2962\n",
      "[{'caption': 'Taksim Square',\n",
      "  'image_id': '00005887',\n",
      "  'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Taksim_Square.jpg/800px-Taksim_Square.jpg',\n",
      "  'title': 'Taksim Square',\n",
      "  'url': 'https://commons.wikimedia.org/wiki/File:Taksim_Square.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "print(k)\n",
    "k = random.choice(list(img_dataset.keys()))\n",
    "pprint(img_dataset[k]['img_posFacts'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18553\n",
      "[{'caption': 'The Juilliard School photo D Ramey Logan',\n",
      "  'filter_conf': 0.6538,\n",
      "  'image_id': '00003462',\n",
      "  'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/The_Juilliard_School_photo_D_Ramey_Logan.jpg/757px-The_Juilliard_School_photo_D_Ramey_Logan.jpg',\n",
      "  'title': 'The Juilliard School photo D Ramey Logan',\n",
      "  'url': 'https://commons.wikimedia.org/wiki/File:The_Juilliard_School_photo_D_Ramey_Logan.jpg'},\n",
      " {'caption': 'UF Phillips Center',\n",
      "  'filter_conf': 0.4924,\n",
      "  'image_id': '00003206',\n",
      "  'imgUrl': 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/UF_Phillips_Center.JPG/800px-UF_Phillips_Center.JPG',\n",
      "  'title': 'UF Phillips Center',\n",
      "  'url': 'https://commons.wikimedia.org/wiki/File:UF_Phillips_Center.JPG'}]\n"
     ]
    }
   ],
   "source": [
    "print(k)\n",
    "k = random.choice(list(pred_dataset.keys()))\n",
    "pprint(pred_dataset[k]['img_posFacts'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24343\n",
      "['b3822446-76c0-477e-82c2-68fa399af3bf', '66a2a99c-30cd-4b87-9e53-506fa6be9f31', '061397e3-f946-4e2d-afa5-9b8b29a35e49']\n"
     ]
    }
   ],
   "source": [
    "tmp = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0904_clean_fields.json\", \"r\"))\n",
    "print(len(tmp))\n",
    "print(list(tmp.keys())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
