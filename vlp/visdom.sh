#img qa full-sentence val_loss
#CUDA_VISIBLE_DEVICES=2 python run_webqa_vinvl.py --new_segment_ids --val_loss --train_batch_size 128 --split val --answer_provided_by 'img' --task_to_learn 'qa' --num_workers 8 --max_pred 50 --mask_prob 0.5 --learning_rate 1e-4 --gradient_accumulation_steps 2 --save_loss_curve --num_train_epochs 5 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json" --recover_step 2 &&

#img qa full-sentence decode
CUDA_VISIBLE_DEVICES=2 python decode_webqa_vinvl.py --new_segment_ids --batch_size 32 --answer_provided_by "img" --beam_size 5 --split "val" --num_workers 8 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json"  --recover_step 8 &&
CUDA_VISIBLE_DEVICES=2 python decode_webqa_vinvl.py --new_segment_ids --batch_size 32 --answer_provided_by "img" --beam_size 5 --split "val" --num_workers 8 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json"  --recover_step 10 &&
CUDA_VISIBLE_DEVICES=2 python decode_webqa_vinvl.py --new_segment_ids --batch_size 32 --answer_provided_by "img" --beam_size 5 --split "val" --num_workers 8 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json"  --recover_step 11 &&
CUDA_VISIBLE_DEVICES=2 python decode_webqa_vinvl.py --new_segment_ids --batch_size 32 --answer_provided_by "img" --beam_size 5 --split "val" --num_workers 8 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json"  --recover_step 12 &&
CUDA_VISIBLE_DEVICES=2 python decode_webqa_vinvl.py --new_segment_ids --batch_size 32 --answer_provided_by "img" --beam_size 5 --split "val" --num_workers 8 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json"  --recover_step 13 &&
CUDA_VISIBLE_DEVICES=2 python decode_webqa_vinvl.py --new_segment_ids --batch_size 32 --answer_provided_by "img" --beam_size 5 --split "val" --num_workers 8 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json"  --recover_step 14 &&
CUDA_VISIBLE_DEVICES=2 python decode_webqa_vinvl.py --new_segment_ids --batch_size 3 --answer_provided_by "img" --beam_size 5 --split "val" --num_workers 8 --output_dir light_output/vinvl_img_qa_sentence --ckpts_dir /data/yingshac/MMMHQA/ckpts/vinvl_img_qa_sentence --img_dataset_json_path "/home/yingshac/CYS/WebQnA/WebQnA_data_new/img_dataset_0812.json"  --recover_step 15

#CUDA_VISIBLE_DEVICES=1 python decode_webqa.py --new_segment_ids --batch_size 32 --answer_provided_by "img" --beam_size 5 --split "val" --output_dir light_output/qa_img_split_update0721 --ckpts_dir /data/yingshac/MMMHQA/ckpts/qa_img_split_update0721 --num_workers 8 --recover_step 13 &&

#CUDA_VISIBLE_DEVICES=0 python run_webqa.py --new_segment_ids --val_loss --train_batch_size 128 --split val --answer_provided_by 'txt' --task_to_learn 'filter' --num_workers 8 --max_pred 50 --mask_prob 1.0 --learning_rate 3e-5 --gradient_accumulation_steps 2 --save_loss_curve --num_train_epochs 5 --output_dir light_output/filter_txt_neg_ranked_by_RE_16 --ckpts_dir /data/yingshac/MMMHQA/ckpts/filter_txt_neg_ranked_by_RE_16 --recover_step 4 --txt_filter_max_choices 16 --txt_dataset_json_path /home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0725_ranked_by_RE.json &&
#CUDA_VISIBLE_DEVICES=0 python run_webqa.py --new_segment_ids --val_loss --train_batch_size 128 --split val --answer_provided_by 'txt' --task_to_learn 'filter' --num_workers 8 --max_pred 50 --mask_prob 1.0 --learning_rate 3e-5 --gradient_accumulation_steps 2 --save_loss_curve --num_train_epochs 5 --output_dir light_output/filter_txt_neg_ranked_by_RE_16 --ckpts_dir /data/yingshac/MMMHQA/ckpts/filter_txt_neg_ranked_by_RE_16 --recover_step 5 --txt_filter_max_choices 16 --txt_dataset_json_path /home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0725_ranked_by_RE.json &&
#CUDA_VISIBLE_DEVICES=0 python run_webqa.py --new_segment_ids --val_loss --train_batch_size 128 --split val --answer_provided_by 'txt' --task_to_learn 'filter' --num_workers 8 --max_pred 50 --mask_prob 1.0 --learning_rate 3e-5 --gradient_accumulation_steps 2 --save_loss_curve --num_train_epochs 5 --output_dir light_output/filter_txt_neg_ranked_by_RE_16 --ckpts_dir /data/yingshac/MMMHQA/ckpts/filter_txt_neg_ranked_by_RE_16 --recover_step 6 --txt_filter_max_choices 16 --txt_dataset_json_path /home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0725_ranked_by_RE.json &&
#CUDA_VISIBLE_DEVICES=0 python run_webqa.py --new_segment_ids --val_loss --train_batch_size 128 --split val --answer_provided_by 'txt' --task_to_learn 'filter' --num_workers 8 --max_pred 50 --mask_prob 1.0 --learning_rate 3e-5 --gradient_accumulation_steps 2 --save_loss_curve --num_train_epochs 5 --output_dir light_output/filter_txt_neg_ranked_by_RE_16 --ckpts_dir /data/yingshac/MMMHQA/ckpts/filter_txt_neg_ranked_by_RE_16 --recover_step 7 --txt_filter_max_choices 16 --txt_dataset_json_path /home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0725_ranked_by_RE.json &&
#CUDA_VISIBLE_DEVICES=0 python run_webqa.py --new_segment_ids --val_loss --train_batch_size 128 --split val --answer_provided_by 'txt' --task_to_learn 'filter' --num_workers 8 --max_pred 50 --mask_prob 1.0 --learning_rate 3e-5 --gradient_accumulation_steps 2 --save_loss_curve --num_train_epochs 5 --output_dir light_output/filter_txt_neg_ranked_by_RE_16 --ckpts_dir /data/yingshac/MMMHQA/ckpts/filter_txt_neg_ranked_by_RE_16 --recover_step 8 --txt_filter_max_choices 16 --txt_dataset_json_path /home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0725_ranked_by_RE.json

#CUDA_VISIBLE_DEVICES=2 python run_webqa.py --new_segment_ids --train_batch_size 128 --split val --answer_provided_by 'txt' --task_to_learn 'filter' --num_workers 8 --max_pred 10 --mask_prob 1.0 --learning_rate 3e-5 --gradient_accumulation_steps 2 --save_loss_curve --output_dir light_output/filter_txt_neg_ranked_by_RE_16 --ckpts_dir /data/yingshac/MMMHQA/ckpts/filter_txt_neg_ranked_by_RE_16 --recover_step 6 --txt_filter_max_choices 16 --txt_dataset_json_path /home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0725_ranked_by_RE.json && CUDA_VISIBLE_DEVICES=2 python run_webqa.py --new_segment_ids --train_batch_size 128 --split val --answer_provided_by 'txt' --task_to_learn 'filter' --num_workers 8 --max_pred 10 --mask_prob 1.0 --learning_rate 3e-5 --gradient_accumulation_steps 2 --save_loss_curve --output_dir light_output/filter_txt_neg_ranked_by_RE_16 --ckpts_dir /data/yingshac/MMMHQA/ckpts/filter_txt_neg_ranked_by_RE_16 --recover_step 7 --txt_filter_max_choices 16 --txt_dataset_json_path /home/yingshac/CYS/WebQnA/WebQnA_data_new/txt_dataset_0725_ranked_by_RE.json